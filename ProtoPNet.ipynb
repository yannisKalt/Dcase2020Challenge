{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ProtoPNet.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "z7_JLXXW7ftt",
        "colab_type": "code",
        "outputId": "0a17cac4-4195-4c35-f679-396c86807bd2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import sys\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import roc_auc_score, roc_curve, f1_score\n",
        "import seaborn as sns\n",
        "from joblib import load\n",
        "sns.set(context = 'talk')\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "else:\n",
        "    device = torch.device('cpu')\n",
        "\n",
        "\n",
        "os.chdir('/content/drive/My Drive/DCASE/src')\n",
        "from utils import *"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pEfXRXtgNE22",
        "colab_type": "text"
      },
      "source": [
        "# Define Prototype Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gbm3Rggr7vyu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ProtoLayer(nn.Module):\n",
        "    def __init__(self, n_proto, proto_channels, proto_h, proto_w):\n",
        "        super(ProtoLayer,self).__init__()\n",
        "        self.prototypes = nn.Parameter(\n",
        "                          torch.rand(n_proto, proto_channels, proto_h, proto_w))\n",
        "\n",
        "        self.n_proto = n_proto\n",
        "        self.n_channels = proto_channels\n",
        "        self.hp = proto_h\n",
        "        self.wp = proto_w\n",
        "\n",
        "    def forward(self, x):\n",
        "        ones = torch.ones(self.prototypes.shape).to(device)\n",
        "        x2 = x ** 2\n",
        "        x2_patch_sum = F.conv2d(x2, ones)\n",
        "\n",
        "        p2 = self.prototypes ** 2\n",
        "        p2 = torch.sum(p2, dim = (1,2,3))\n",
        "\n",
        "        p2_reshape = p2.view(-1, 1, 1)               \n",
        "\n",
        "        xp = F.conv2d(x, self.prototypes)\n",
        "\n",
        "        return x2_patch_sum - 2 * xp + p2_reshape\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p8CY05gwNIJN",
        "colab_type": "text"
      },
      "source": [
        "# Define Prototype Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E9exJsl8ufXQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AProtoPNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(AProtoPNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 8, 5, padding = 2, bias = False)\n",
        "        self.conv2 = nn.Conv2d(8, 8, 5, padding = 2, bias = False)\n",
        "        self.conv3 = nn.Conv2d(8, 16, 5, padding = 2, bias = False)\n",
        "        self.conv4 = nn.Conv2d(16, 16, 5, padding = 2, bias = False)\n",
        "        self.proto_layer = ProtoLayer(3, 16, 6,6)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x -> (batch, C, H, W), C = 1, H = 128, W = 157\n",
        "        x = F.max_pool2d(F.relu(self.conv1(x)), 2)  # x -> (batch, 8, 64, 78)\n",
        "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)  # x -> (batch, 8, 32, 39)\n",
        "        x = F.max_pool2d(F.relu(self.conv3(x)), 2)  # x -> (batch, 16, 16, 19)\n",
        "        x = F.max_pool2d(F.relu(self.conv4(x)), 2)  # x -> (batch, 16, 8, 9)\n",
        "        x = self.proto_layer(x) # x -> (batch, n_proto, 8 - hp + 1, 9 - hp + 1)\n",
        "        x = (-F.max_pool2d(-x, (x.shape[-2],x.shape[-1]))).view(-1,x.shape[1])\n",
        "        # x -> (batch, n_proto)\n",
        "        return x\n",
        "\n",
        "    def project_prototypes(self, x):\n",
        "        with torch.no_grad():\n",
        "            x = F.max_pool2d(F.relu(self.conv1(x)), 2)  # x -> (batch, 8, 64, 78)\n",
        "            x = F.max_pool2d(F.relu(self.conv2(x)), 2)  # x -> (batch, 8, 32, 39)\n",
        "            x = F.max_pool2d(F.relu(self.conv3(x)), 2)  # x -> (batch, 16, 16, 19)\n",
        "            x = F.max_pool2d(F.relu(self.conv4(x)), 2)  # x -> (batch, 16, 8, 9)\n",
        "            proto_out = self.proto_layer(x) # proto_out -> (batch, n_proto, 8 - hp + 1, 9 - hp + 1)\n",
        "        \n",
        "            n_samples, n_proto, ho, wo = proto_out.shape \n",
        "\n",
        "            for indx_proto in range(n_proto):\n",
        "                min_dist = np.inf\n",
        "                for indx_sample in range(n_samples):\n",
        "                    for h in range(ho):\n",
        "                        for w in range(wo):\n",
        "                            if proto_out[indx_sample,indx_proto, h, w].item() < min_dist:\n",
        "                                h_min = h\n",
        "                                w_min = w\n",
        "                                indx_sample_min = indx_sample\n",
        "                                min_dist = proto_out[indx_sample, indx_proto, h, w].item()\n",
        "                hp, wp = self.proto_layer.prototypes.shape[-2], self.proto_layer.prototypes.shape[-1]\n",
        "                self.proto_layer.prototypes.data[indx_proto] = x[indx_sample_min, :, h_min: h_min + hp, w_min: w_min + wp]\n",
        " \n",
        "    def prototype_visualize(self, x):\n",
        "        with torch.no_grad():\n",
        "            y = F.max_pool2d(F.relu(self.conv1(x)), 2)  \n",
        "            y = F.max_pool2d(F.relu(self.conv2(y)), 2)  \n",
        "            y = F.max_pool2d(F.relu(self.conv3(y)), 2)  \n",
        "            y = F.max_pool2d(F.relu(self.conv4(y)), 2)  \n",
        "            y = self.proto_layer(y) \n",
        "\n",
        "            y = torch.log10((y + 1) / (y + sys.float_info.epsilon))\n",
        "            return F.interpolate(y, x.shape[2:])\n",
        "\n",
        "    def train_m(self, X_train, batch_size = 32, n_epochs = 100):\n",
        "        optimizer = optim.Adam(self.parameters(), weight_decay= 0.0001)\n",
        "\n",
        "        # Training/Validation Indices #\n",
        "        training_indices = torch.randperm(X_train.shape[0])\n",
        "        n = np.int(np.floor(0.1 * training_indices.shape[0]))\n",
        "        val_indices = training_indices[:n]\n",
        "        training_indices = training_indices[n:]\n",
        "\n",
        "        min_val_loss = np.inf\n",
        "        # N: Number Of Training Samples #\n",
        "        N = training_indices.shape[0]\n",
        "\n",
        "        # r: Prototype Projection Every r Epochs #\n",
        "        r = 5\n",
        "\n",
        "        for epoch in range(n_epochs):\n",
        "        # Shuffle Training Indices\n",
        "            np.random.shuffle(training_indices.numpy())\n",
        "            running_loss = 0.0\n",
        "\n",
        "            if not divmod(epoch, r)[-1] and epoch !=0:\n",
        "                self.project_prototypes(X_train[training_indices])\n",
        "\n",
        "            for i in range(N // batch_size):\n",
        "                optimizer.zero_grad()\n",
        "                X = X_train[i * batch_size: (i + 1) * batch_size]\n",
        "                Y = model(X)\n",
        "                loss = Y.min(dim = 1)[0].mean()  #Y.min(dim = 1)[0].mean()        ##################\n",
        "                running_loss += loss.item()\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "            # Compute Validation Loss #\n",
        "            with torch.no_grad():\n",
        "                Y_val = model(X_train[val_indices])\n",
        "                val_loss = Y_val.min(dim = 1)[0].mean()                           ########################3\n",
        "                print('Epoch [%s] Train_Loss %.4e, Val_Loss %.4e'\n",
        "                      % (epoch, running_loss / (N // batch_size), val_loss.item()))\n",
        "                \n",
        "            if val_loss.item() < min_val_loss:\n",
        "                min_val_loss = val_loss.item()\n",
        "                print('Saving Model\\n')\n",
        "                torch.save(model.state_dict(), 'proto_weights.pt')\n",
        "\n",
        "        # Restore Weights\n",
        "        mk = self.load_state_dict(torch.load('proto_weights.pt'))\n",
        "        print(mk)\n",
        "\n",
        "    def evaluate_m(self, X_train, X_test, test_audiopaths):\n",
        "        with torch.no_grad():\n",
        "            # Compute Threshold for Hard Classification\n",
        "            Y_pred = model(X_train)\n",
        "            y_score = Y_pred.min(dim = 1)[0].cpu().numpy()                         ########################\n",
        "            thr = y_score.mean()\n",
        "\n",
        "            # Evaluate On X_test\n",
        "            Y_pred = model(X_test)\n",
        "            y_score = Y_pred.min(dim = 1)[0].cpu().numpy()                            #########################\n",
        "\n",
        "            labels = [fn.split('.')[0].split('/')[-1].split('_')[0] for fn in test_audiopaths]\n",
        "            y_true = [1 if label == 'anomaly' else 0 for label in labels] \n",
        "            y_pred = [1 if score >= thr else 0 for score in y_score]\n",
        "            \n",
        "            auc = roc_auc_score(y_true, y_score)\n",
        "            pauc = roc_auc_score(y_true, y_score, max_fpr = 0.1)\n",
        "            fpr, tpr, _ = roc_curve(y_true, y_score)\n",
        "            f1 = f1_score(y_true, y_pred)\n",
        "            return auc, pauc, fpr, tpr, f1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EOGWhiBizshc",
        "colab_type": "text"
      },
      "source": [
        "# Development Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "srgZlrQVM2An",
        "colab_type": "code",
        "outputId": "1a4e2738-dc2c-4c79-8cac-285a8f871c40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "base_path = '/content/drive/My Drive/DCASE/Development_Dataset'\n",
        "machine_type = 'ToyConveyor'\n",
        "machine_ids = ['01', '02', '03']\n",
        "\n",
        "\n",
        "cross_pauc_list = []\n",
        "cross_auc_list = []\n",
        "cross_f1_list = []\n",
        "n_mels = 128\n",
        "\n",
        "for i in range(5):\n",
        "    auc_list = []\n",
        "    pauc_list = []\n",
        "    fpr_list = []\n",
        "    tpr_list = []\n",
        "    f1_list = []\n",
        "\n",
        "\n",
        "\n",
        "    for machine_id in machine_ids:\n",
        "        train_audiopaths = get_audiopaths(machine_type, machine_id, base_path, mode = 'train')\n",
        "        test_audiopaths =  get_audiopaths(machine_type, machine_id, base_path, mode = 'test')\n",
        "\n",
        "        # Load S_train, S_test #\n",
        "        try:\n",
        "            S_train = np.load('S%s_%s_%s_train.npy' % (n_mels, machine_type, machine_id))\n",
        "            S_test = np.load('S%s_%s_%s_test.npy' % (n_mels, machine_type, machine_id))\n",
        "        except:\n",
        "            exit()\n",
        "\n",
        "        \"\"\"\n",
        "        # Preprocessing A\n",
        "        for i in range(S_train.shape[0]):\n",
        "            S_train[i] = 10 * np.log10(S_train[i] / S_train[i].max() + 0.01)\n",
        "    \n",
        "        for i in range(S_test.shape[0]):\n",
        "            S_test[i] = 10 * np.log10(S_test[i] / S_test[i].max() + 0.01)\n",
        "\n",
        "        X_train = torch.tensor(S_train, dtype = torch.float)\n",
        "        X_train = X_train.view(X_train.shape[0], 1, *X_train.shape[1:]).to(device)\n",
        "        X_test = torch.tensor(S_test, dtype = torch.float)\n",
        "        X_test = X_test.view(X_test.shape[0], 1, *X_test.shape[1:]).to(device)\n",
        "        \"\"\"\n",
        "\n",
        "        # Preprocess (S_train, S_test) -> (X_train, X_test) #\n",
        "        X_train = torch.tensor(10 * np.log10(S_train + sys.float_info.epsilon), dtype = torch.float)\n",
        "        X_train = X_train.view(X_train.shape[0], 1, *X_train.shape[1:]).to(device)\n",
        "\n",
        "        X_test = torch.tensor(10 * np.log10(S_test + sys.float_info.epsilon), dtype = torch.float)\n",
        "        X_test = X_test.view(X_test.shape[0], 1, *X_test.shape[1:]).to(device)\n",
        "    \n",
        "        # initialize model #\n",
        "        model = AProtoPNet().to(device)\n",
        "    \n",
        "        # Train Model \n",
        "        print('-' * 25)\n",
        "        print('Training Model [ID = %s]' % machine_id)\n",
        "        print('-' * 25)\n",
        "        model.train_m(X_train) \n",
        "        auc, pauc, fpr, tpr, f1 = model.evaluate_m(X_train, X_test, test_audiopaths)\n",
        "        auc_list.append(auc)\n",
        "        cross_auc_list.append(auc_list)\n",
        "        pauc_list.append(pauc)\n",
        "        cross_pauc_list.append(pauc_list)\n",
        "        fpr_list.append(fpr)\n",
        "        tpr_list.append(tpr)\n",
        "        f1_list.append(f1)\n",
        "        cross_f1_list.append(f1_list)\n",
        "    print('-'*47)\n",
        "    for i, machine_id in enumerate(machine_ids):\n",
        "        print('ID_%s: AUC = %.4f, PAUC = %.4f, F1 = %.4f' % (machine_id, auc_list[i], pauc_list[i], f1_list[i]))\n",
        "\n",
        "    print('-' * 47)\n",
        "    print('Avg:  AUC = %.4f, PAUC = %.4f, F1 = %.4f' % (np.mean(auc_list), np.mean(pauc_list), np.mean(f1_list)))\n",
        "\n",
        "for i, machine_id in enumerate(machine_ids):\n",
        "    mean_auc = np.mean(cross_auc_list, axis = 0)\n",
        "    std_auc = np.std(cross_auc_list, axis = 0)\n",
        "    mean_pauc = np.mean(cross_pauc_list, axis = 0)\n",
        "    std_pauc = np.std(cross_pauc_list, axis = 0)\n",
        "    mean_f1 = np.mean(cross_f1_list, axis = 0)\n",
        "    std_f1 = np.std(cross_f1_list, axis = 0)\n",
        "    print('ID_%s: AUC = %.4f ~ %.4f, PAUC = %.4f ~ %.4f, F1 = %.4f ~ %.4f' % \n",
        "          (machine_id, mean_auc[i], std_auc[i], \n",
        "           mean_pauc[i], std_pauc[i], \n",
        "           mean_f1[i], std_f1[i]))\n",
        "print('Avg:  AUC = %.4f ~ %.4f, PAUC = %.4f, ~ %.4f, F1 = %.4f ~ %.4f' % \n",
        "      (np.mean(cross_auc_list), np.std(cross_auc_list),\n",
        "       np.mean(cross_pauc_list), np.std(cross_pauc_list),\n",
        "       np.mean(cross_f1_list), np.std(cross_f1_list)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-------------------------\n",
            "Training Model [ID = 01]\n",
            "-------------------------\n",
            "Epoch [0] Train_Loss 7.1603e+00, Val_Loss 2.3504e+00\n",
            "Saving Model\n",
            "\n",
            "Epoch [1] Train_Loss 1.3186e+00, Val_Loss 6.9449e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [2] Train_Loss 5.0043e-01, Val_Loss 3.9203e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [3] Train_Loss 3.2727e-01, Val_Loss 2.8357e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [4] Train_Loss 2.6758e-01, Val_Loss 2.5084e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [5] Train_Loss 2.5522e-01, Val_Loss 2.3208e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [6] Train_Loss 2.1740e-01, Val_Loss 1.8452e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [7] Train_Loss 1.8601e-01, Val_Loss 1.5869e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [8] Train_Loss 1.6088e-01, Val_Loss 1.5423e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [9] Train_Loss 1.5348e-01, Val_Loss 1.3335e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [10] Train_Loss 1.5155e-01, Val_Loss 1.3579e-01\n",
            "Epoch [11] Train_Loss 1.3247e-01, Val_Loss 1.2244e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [12] Train_Loss 1.2269e-01, Val_Loss 1.1936e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [13] Train_Loss 1.1852e-01, Val_Loss 1.0878e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [14] Train_Loss 1.0939e-01, Val_Loss 1.0076e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [15] Train_Loss 1.1154e-01, Val_Loss 1.0816e-01\n",
            "Epoch [16] Train_Loss 9.8971e-02, Val_Loss 1.0125e-01\n",
            "Epoch [17] Train_Loss 9.6043e-02, Val_Loss 1.0265e-01\n",
            "Epoch [18] Train_Loss 9.5143e-02, Val_Loss 8.8528e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [19] Train_Loss 9.5917e-02, Val_Loss 8.3259e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [20] Train_Loss 8.8919e-02, Val_Loss 8.1609e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [21] Train_Loss 8.2053e-02, Val_Loss 7.1282e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [22] Train_Loss 7.7315e-02, Val_Loss 7.2004e-02\n",
            "Epoch [23] Train_Loss 7.4652e-02, Val_Loss 6.8477e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [24] Train_Loss 7.2964e-02, Val_Loss 6.9842e-02\n",
            "Epoch [25] Train_Loss 6.8597e-02, Val_Loss 5.9063e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [26] Train_Loss 6.2854e-02, Val_Loss 6.0838e-02\n",
            "Epoch [27] Train_Loss 6.2739e-02, Val_Loss 5.6211e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [28] Train_Loss 5.6628e-02, Val_Loss 5.4449e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [29] Train_Loss 5.4246e-02, Val_Loss 5.0098e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [30] Train_Loss 5.7410e-02, Val_Loss 5.0273e-02\n",
            "Epoch [31] Train_Loss 5.4774e-02, Val_Loss 4.8626e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [32] Train_Loss 5.3893e-02, Val_Loss 5.0556e-02\n",
            "Epoch [33] Train_Loss 5.1695e-02, Val_Loss 5.3095e-02\n",
            "Epoch [34] Train_Loss 4.9700e-02, Val_Loss 4.9130e-02\n",
            "Epoch [35] Train_Loss 5.0319e-02, Val_Loss 4.6518e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [36] Train_Loss 4.4708e-02, Val_Loss 4.2075e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [37] Train_Loss 4.3951e-02, Val_Loss 4.2308e-02\n",
            "Epoch [38] Train_Loss 4.1960e-02, Val_Loss 3.9752e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [39] Train_Loss 4.2650e-02, Val_Loss 3.7801e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [40] Train_Loss 4.2804e-02, Val_Loss 3.8807e-02\n",
            "Epoch [41] Train_Loss 3.9242e-02, Val_Loss 3.5487e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [42] Train_Loss 3.7617e-02, Val_Loss 3.5589e-02\n",
            "Epoch [43] Train_Loss 3.7269e-02, Val_Loss 3.3927e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [44] Train_Loss 3.6849e-02, Val_Loss 3.3812e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [45] Train_Loss 3.7598e-02, Val_Loss 3.3613e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [46] Train_Loss 3.6208e-02, Val_Loss 3.3311e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [47] Train_Loss 3.5282e-02, Val_Loss 3.3084e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [48] Train_Loss 3.4299e-02, Val_Loss 3.4268e-02\n",
            "Epoch [49] Train_Loss 3.3997e-02, Val_Loss 3.5086e-02\n",
            "Epoch [50] Train_Loss 3.3758e-02, Val_Loss 3.2926e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [51] Train_Loss 3.1931e-02, Val_Loss 3.9309e-02\n",
            "Epoch [52] Train_Loss 3.1780e-02, Val_Loss 3.1108e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [53] Train_Loss 3.0595e-02, Val_Loss 2.8966e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [54] Train_Loss 2.8643e-02, Val_Loss 2.7381e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [55] Train_Loss 2.9350e-02, Val_Loss 2.7137e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [56] Train_Loss 2.7457e-02, Val_Loss 2.8171e-02\n",
            "Epoch [57] Train_Loss 2.7695e-02, Val_Loss 2.6908e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [58] Train_Loss 2.7012e-02, Val_Loss 2.9375e-02\n",
            "Epoch [59] Train_Loss 2.5667e-02, Val_Loss 2.7454e-02\n",
            "Epoch [60] Train_Loss 2.7499e-02, Val_Loss 2.5816e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [61] Train_Loss 2.5185e-02, Val_Loss 2.5761e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [62] Train_Loss 2.5110e-02, Val_Loss 2.6070e-02\n",
            "Epoch [63] Train_Loss 2.4452e-02, Val_Loss 2.3892e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [64] Train_Loss 2.4831e-02, Val_Loss 2.7653e-02\n",
            "Epoch [65] Train_Loss 2.6715e-02, Val_Loss 2.2577e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [66] Train_Loss 2.9797e-02, Val_Loss 2.9612e-02\n",
            "Epoch [67] Train_Loss 2.4172e-02, Val_Loss 2.7420e-02\n",
            "Epoch [68] Train_Loss 2.4649e-02, Val_Loss 2.2875e-02\n",
            "Epoch [69] Train_Loss 2.4575e-02, Val_Loss 2.6345e-02\n",
            "Epoch [70] Train_Loss 2.6103e-02, Val_Loss 2.3719e-02\n",
            "Epoch [71] Train_Loss 2.5871e-02, Val_Loss 3.0240e-02\n",
            "Epoch [72] Train_Loss 2.5610e-02, Val_Loss 2.3491e-02\n",
            "Epoch [73] Train_Loss 3.0842e-02, Val_Loss 2.8266e-02\n",
            "Epoch [74] Train_Loss 3.4718e-02, Val_Loss 2.9595e-02\n",
            "Epoch [75] Train_Loss 2.9631e-02, Val_Loss 2.2780e-02\n",
            "Epoch [76] Train_Loss 3.2789e-02, Val_Loss 2.4142e-02\n",
            "Epoch [77] Train_Loss 2.6791e-02, Val_Loss 2.1788e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [78] Train_Loss 2.5766e-02, Val_Loss 2.0493e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [79] Train_Loss 2.1026e-02, Val_Loss 1.9186e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [80] Train_Loss 2.5275e-02, Val_Loss 2.1736e-02\n",
            "Epoch [81] Train_Loss 2.3885e-02, Val_Loss 2.1329e-02\n",
            "Epoch [82] Train_Loss 2.2663e-02, Val_Loss 1.9151e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [83] Train_Loss 2.1240e-02, Val_Loss 2.5607e-02\n",
            "Epoch [84] Train_Loss 2.1568e-02, Val_Loss 2.1375e-02\n",
            "Epoch [85] Train_Loss 2.1564e-02, Val_Loss 2.5434e-02\n",
            "Epoch [86] Train_Loss 2.1264e-02, Val_Loss 2.2680e-02\n",
            "Epoch [87] Train_Loss 2.1612e-02, Val_Loss 2.4730e-02\n",
            "Epoch [88] Train_Loss 2.0231e-02, Val_Loss 3.1833e-02\n",
            "Epoch [89] Train_Loss 2.2208e-02, Val_Loss 1.8688e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [90] Train_Loss 2.3145e-02, Val_Loss 1.7416e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [91] Train_Loss 2.3821e-02, Val_Loss 1.6279e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [92] Train_Loss 2.1654e-02, Val_Loss 1.6818e-02\n",
            "Epoch [93] Train_Loss 2.1504e-02, Val_Loss 2.2721e-02\n",
            "Epoch [94] Train_Loss 2.3199e-02, Val_Loss 1.5694e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [95] Train_Loss 1.9949e-02, Val_Loss 1.9027e-02\n",
            "Epoch [96] Train_Loss 2.2930e-02, Val_Loss 1.6681e-02\n",
            "Epoch [97] Train_Loss 2.0209e-02, Val_Loss 1.6287e-02\n",
            "Epoch [98] Train_Loss 1.9716e-02, Val_Loss 2.1166e-02\n",
            "Epoch [99] Train_Loss 1.8998e-02, Val_Loss 1.4635e-02\n",
            "Saving Model\n",
            "\n",
            "<All keys matched successfully>\n",
            "-------------------------\n",
            "Training Model [ID = 02]\n",
            "-------------------------\n",
            "Epoch [0] Train_Loss 6.9794e+00, Val_Loss 4.1973e+00\n",
            "Saving Model\n",
            "\n",
            "Epoch [1] Train_Loss 2.5897e+00, Val_Loss 1.3728e+00\n",
            "Saving Model\n",
            "\n",
            "Epoch [2] Train_Loss 8.5469e-01, Val_Loss 5.3021e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [3] Train_Loss 4.2502e-01, Val_Loss 3.5913e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [4] Train_Loss 3.1690e-01, Val_Loss 2.7785e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [5] Train_Loss 2.9025e-01, Val_Loss 2.4396e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [6] Train_Loss 2.3155e-01, Val_Loss 2.0599e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [7] Train_Loss 2.0088e-01, Val_Loss 1.7938e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [8] Train_Loss 1.7774e-01, Val_Loss 1.5805e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [9] Train_Loss 1.6004e-01, Val_Loss 1.4235e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [10] Train_Loss 1.5766e-01, Val_Loss 1.3511e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [11] Train_Loss 1.3273e-01, Val_Loss 1.1871e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [12] Train_Loss 1.1993e-01, Val_Loss 1.0934e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [13] Train_Loss 1.1126e-01, Val_Loss 1.0196e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [14] Train_Loss 1.0473e-01, Val_Loss 9.6416e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [15] Train_Loss 1.0176e-01, Val_Loss 8.7673e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [16] Train_Loss 8.9216e-02, Val_Loss 8.6909e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [17] Train_Loss 8.6915e-02, Val_Loss 8.2956e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [18] Train_Loss 8.5730e-02, Val_Loss 7.5556e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [19] Train_Loss 7.9958e-02, Val_Loss 7.0304e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [20] Train_Loss 7.7075e-02, Val_Loss 7.0208e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [21] Train_Loss 7.3718e-02, Val_Loss 6.3379e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [22] Train_Loss 6.6172e-02, Val_Loss 6.1791e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [23] Train_Loss 6.2730e-02, Val_Loss 5.9624e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [24] Train_Loss 6.0756e-02, Val_Loss 5.9221e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [25] Train_Loss 6.3261e-02, Val_Loss 5.5347e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [26] Train_Loss 5.6727e-02, Val_Loss 5.7460e-02\n",
            "Epoch [27] Train_Loss 5.6019e-02, Val_Loss 5.1769e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [28] Train_Loss 5.3497e-02, Val_Loss 4.8995e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [29] Train_Loss 5.1719e-02, Val_Loss 5.0607e-02\n",
            "Epoch [30] Train_Loss 5.6713e-02, Val_Loss 5.0176e-02\n",
            "Epoch [31] Train_Loss 5.2554e-02, Val_Loss 4.5781e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [32] Train_Loss 4.9266e-02, Val_Loss 4.5296e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [33] Train_Loss 5.0525e-02, Val_Loss 4.5573e-02\n",
            "Epoch [34] Train_Loss 4.7009e-02, Val_Loss 4.5550e-02\n",
            "Epoch [35] Train_Loss 5.5147e-02, Val_Loss 4.8525e-02\n",
            "Epoch [36] Train_Loss 5.6835e-02, Val_Loss 4.6159e-02\n",
            "Epoch [37] Train_Loss 4.8341e-02, Val_Loss 5.1602e-02\n",
            "Epoch [38] Train_Loss 4.3836e-02, Val_Loss 4.1494e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [39] Train_Loss 4.5180e-02, Val_Loss 4.3207e-02\n",
            "Epoch [40] Train_Loss 4.2226e-02, Val_Loss 3.8303e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [41] Train_Loss 4.8966e-02, Val_Loss 3.9348e-02\n",
            "Epoch [42] Train_Loss 4.1593e-02, Val_Loss 4.3204e-02\n",
            "Epoch [43] Train_Loss 3.9578e-02, Val_Loss 3.5602e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [44] Train_Loss 3.8627e-02, Val_Loss 3.6082e-02\n",
            "Epoch [45] Train_Loss 3.8705e-02, Val_Loss 3.4606e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [46] Train_Loss 3.6039e-02, Val_Loss 3.4496e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [47] Train_Loss 3.6462e-02, Val_Loss 3.3142e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [48] Train_Loss 3.5815e-02, Val_Loss 3.3631e-02\n",
            "Epoch [49] Train_Loss 3.6919e-02, Val_Loss 3.4800e-02\n",
            "Epoch [50] Train_Loss 3.5938e-02, Val_Loss 3.2860e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [51] Train_Loss 3.4776e-02, Val_Loss 3.0644e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [52] Train_Loss 3.3211e-02, Val_Loss 3.0026e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [53] Train_Loss 3.3461e-02, Val_Loss 3.3258e-02\n",
            "Epoch [54] Train_Loss 3.4749e-02, Val_Loss 3.4782e-02\n",
            "Epoch [55] Train_Loss 3.9062e-02, Val_Loss 3.0712e-02\n",
            "Epoch [56] Train_Loss 3.6287e-02, Val_Loss 2.9222e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [57] Train_Loss 3.8782e-02, Val_Loss 3.2597e-02\n",
            "Epoch [58] Train_Loss 4.4004e-02, Val_Loss 5.2568e-02\n",
            "Epoch [59] Train_Loss 5.0197e-02, Val_Loss 4.8915e-02\n",
            "Epoch [60] Train_Loss 4.2937e-02, Val_Loss 3.0994e-02\n",
            "Epoch [61] Train_Loss 3.0213e-02, Val_Loss 2.8147e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [62] Train_Loss 2.7548e-02, Val_Loss 3.3509e-02\n",
            "Epoch [63] Train_Loss 2.8549e-02, Val_Loss 3.4619e-02\n",
            "Epoch [64] Train_Loss 2.6659e-02, Val_Loss 3.0726e-02\n",
            "Epoch [65] Train_Loss 2.7015e-02, Val_Loss 2.7873e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [66] Train_Loss 2.5102e-02, Val_Loss 2.6673e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [67] Train_Loss 2.4257e-02, Val_Loss 2.6132e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [68] Train_Loss 2.4796e-02, Val_Loss 2.4210e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [69] Train_Loss 2.4501e-02, Val_Loss 2.6268e-02\n",
            "Epoch [70] Train_Loss 2.7055e-02, Val_Loss 2.8434e-02\n",
            "Epoch [71] Train_Loss 2.4720e-02, Val_Loss 2.6220e-02\n",
            "Epoch [72] Train_Loss 2.4170e-02, Val_Loss 2.6515e-02\n",
            "Epoch [73] Train_Loss 2.3846e-02, Val_Loss 3.0041e-02\n",
            "Epoch [74] Train_Loss 2.4276e-02, Val_Loss 3.1466e-02\n",
            "Epoch [75] Train_Loss 2.6253e-02, Val_Loss 3.1657e-02\n",
            "Epoch [76] Train_Loss 2.7630e-02, Val_Loss 3.9963e-02\n",
            "Epoch [77] Train_Loss 2.4390e-02, Val_Loss 3.9322e-02\n",
            "Epoch [78] Train_Loss 2.7814e-02, Val_Loss 4.4984e-02\n",
            "Epoch [79] Train_Loss 2.6967e-02, Val_Loss 3.1525e-02\n",
            "Epoch [80] Train_Loss 2.9764e-02, Val_Loss 2.3727e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [81] Train_Loss 2.8571e-02, Val_Loss 2.4343e-02\n",
            "Epoch [82] Train_Loss 2.3503e-02, Val_Loss 2.5088e-02\n",
            "Epoch [83] Train_Loss 1.9716e-02, Val_Loss 2.2203e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [84] Train_Loss 1.9813e-02, Val_Loss 2.1225e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [85] Train_Loss 2.0988e-02, Val_Loss 2.8422e-02\n",
            "Epoch [86] Train_Loss 2.1379e-02, Val_Loss 2.2193e-02\n",
            "Epoch [87] Train_Loss 1.8912e-02, Val_Loss 2.2411e-02\n",
            "Epoch [88] Train_Loss 1.8876e-02, Val_Loss 2.5233e-02\n",
            "Epoch [89] Train_Loss 1.8736e-02, Val_Loss 2.5888e-02\n",
            "Epoch [90] Train_Loss 1.9521e-02, Val_Loss 2.3067e-02\n",
            "Epoch [91] Train_Loss 1.7905e-02, Val_Loss 2.3627e-02\n",
            "Epoch [92] Train_Loss 1.8228e-02, Val_Loss 2.3739e-02\n",
            "Epoch [93] Train_Loss 1.7273e-02, Val_Loss 2.2089e-02\n",
            "Epoch [94] Train_Loss 1.6520e-02, Val_Loss 2.1494e-02\n",
            "Epoch [95] Train_Loss 1.8839e-02, Val_Loss 3.0298e-02\n",
            "Epoch [96] Train_Loss 1.7980e-02, Val_Loss 2.0685e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [97] Train_Loss 1.7483e-02, Val_Loss 2.4068e-02\n",
            "Epoch [98] Train_Loss 1.6981e-02, Val_Loss 2.4563e-02\n",
            "Epoch [99] Train_Loss 1.7269e-02, Val_Loss 2.3922e-02\n",
            "<All keys matched successfully>\n",
            "-------------------------\n",
            "Training Model [ID = 03]\n",
            "-------------------------\n",
            "Epoch [0] Train_Loss 6.3142e+00, Val_Loss 2.4381e+00\n",
            "Saving Model\n",
            "\n",
            "Epoch [1] Train_Loss 1.4133e+00, Val_Loss 8.0486e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [2] Train_Loss 6.5118e-01, Val_Loss 4.5233e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [3] Train_Loss 4.4093e-01, Val_Loss 3.5121e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [4] Train_Loss 3.5515e-01, Val_Loss 2.9949e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [5] Train_Loss 3.0792e-01, Val_Loss 2.7683e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [6] Train_Loss 2.6167e-01, Val_Loss 2.4722e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [7] Train_Loss 2.3396e-01, Val_Loss 2.1429e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [8] Train_Loss 2.1711e-01, Val_Loss 1.9926e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [9] Train_Loss 2.0320e-01, Val_Loss 2.0219e-01\n",
            "Epoch [10] Train_Loss 1.9011e-01, Val_Loss 1.8840e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [11] Train_Loss 1.7264e-01, Val_Loss 1.7875e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [12] Train_Loss 1.6293e-01, Val_Loss 1.4749e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [13] Train_Loss 1.4671e-01, Val_Loss 1.3435e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [14] Train_Loss 1.3647e-01, Val_Loss 1.2859e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [15] Train_Loss 1.3571e-01, Val_Loss 1.3447e-01\n",
            "Epoch [16] Train_Loss 1.2692e-01, Val_Loss 1.2877e-01\n",
            "Epoch [17] Train_Loss 1.1947e-01, Val_Loss 1.3323e-01\n",
            "Epoch [18] Train_Loss 1.1793e-01, Val_Loss 1.1596e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [19] Train_Loss 1.0909e-01, Val_Loss 1.3194e-01\n",
            "Epoch [20] Train_Loss 1.0903e-01, Val_Loss 1.1163e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [21] Train_Loss 1.0180e-01, Val_Loss 1.0626e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [22] Train_Loss 9.5952e-02, Val_Loss 9.4627e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [23] Train_Loss 9.6327e-02, Val_Loss 8.8062e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [24] Train_Loss 9.7392e-02, Val_Loss 1.0231e-01\n",
            "Epoch [25] Train_Loss 1.0165e-01, Val_Loss 1.0312e-01\n",
            "Epoch [26] Train_Loss 9.8911e-02, Val_Loss 1.0579e-01\n",
            "Epoch [27] Train_Loss 8.9899e-02, Val_Loss 8.0270e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [28] Train_Loss 8.3289e-02, Val_Loss 8.4733e-02\n",
            "Epoch [29] Train_Loss 8.2760e-02, Val_Loss 8.0726e-02\n",
            "Epoch [30] Train_Loss 8.1949e-02, Val_Loss 7.9811e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [31] Train_Loss 7.6130e-02, Val_Loss 7.8831e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [32] Train_Loss 7.4644e-02, Val_Loss 7.7358e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [33] Train_Loss 7.8218e-02, Val_Loss 6.9597e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [34] Train_Loss 8.7631e-02, Val_Loss 9.9191e-02\n",
            "Epoch [35] Train_Loss 7.7718e-02, Val_Loss 7.0755e-02\n",
            "Epoch [36] Train_Loss 7.4041e-02, Val_Loss 8.4178e-02\n",
            "Epoch [37] Train_Loss 6.7349e-02, Val_Loss 6.5832e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [38] Train_Loss 6.6016e-02, Val_Loss 7.4102e-02\n",
            "Epoch [39] Train_Loss 6.7033e-02, Val_Loss 7.0339e-02\n",
            "Epoch [40] Train_Loss 6.4674e-02, Val_Loss 5.8900e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [41] Train_Loss 5.7698e-02, Val_Loss 5.4642e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [42] Train_Loss 5.7777e-02, Val_Loss 5.7591e-02\n",
            "Epoch [43] Train_Loss 5.9290e-02, Val_Loss 5.3055e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [44] Train_Loss 6.0164e-02, Val_Loss 5.3579e-02\n",
            "Epoch [45] Train_Loss 6.3216e-02, Val_Loss 8.1678e-02\n",
            "Epoch [46] Train_Loss 5.6196e-02, Val_Loss 5.6238e-02\n",
            "Epoch [47] Train_Loss 5.3256e-02, Val_Loss 5.3305e-02\n",
            "Epoch [48] Train_Loss 4.9449e-02, Val_Loss 4.7178e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [49] Train_Loss 4.9429e-02, Val_Loss 4.6358e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [50] Train_Loss 5.0857e-02, Val_Loss 4.3707e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [51] Train_Loss 4.8832e-02, Val_Loss 5.1339e-02\n",
            "Epoch [52] Train_Loss 4.9859e-02, Val_Loss 5.5594e-02\n",
            "Epoch [53] Train_Loss 5.2284e-02, Val_Loss 4.7338e-02\n",
            "Epoch [54] Train_Loss 5.3129e-02, Val_Loss 5.1180e-02\n",
            "Epoch [55] Train_Loss 6.4792e-02, Val_Loss 5.3805e-02\n",
            "Epoch [56] Train_Loss 5.6938e-02, Val_Loss 5.7694e-02\n",
            "Epoch [57] Train_Loss 5.4925e-02, Val_Loss 5.5072e-02\n",
            "Epoch [58] Train_Loss 4.8387e-02, Val_Loss 4.4493e-02\n",
            "Epoch [59] Train_Loss 4.4315e-02, Val_Loss 4.0456e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [60] Train_Loss 4.5263e-02, Val_Loss 3.8780e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [61] Train_Loss 4.2851e-02, Val_Loss 4.6379e-02\n",
            "Epoch [62] Train_Loss 4.7645e-02, Val_Loss 3.7524e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [63] Train_Loss 3.7109e-02, Val_Loss 3.4127e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [64] Train_Loss 4.2047e-02, Val_Loss 3.9438e-02\n",
            "Epoch [65] Train_Loss 3.9544e-02, Val_Loss 3.8325e-02\n",
            "Epoch [66] Train_Loss 4.2378e-02, Val_Loss 3.9472e-02\n",
            "Epoch [67] Train_Loss 3.8199e-02, Val_Loss 4.2213e-02\n",
            "Epoch [68] Train_Loss 4.1419e-02, Val_Loss 3.4986e-02\n",
            "Epoch [69] Train_Loss 3.4687e-02, Val_Loss 4.0327e-02\n",
            "Epoch [70] Train_Loss 4.5942e-02, Val_Loss 4.0796e-02\n",
            "Epoch [71] Train_Loss 3.6551e-02, Val_Loss 3.5281e-02\n",
            "Epoch [72] Train_Loss 3.4239e-02, Val_Loss 3.2615e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [73] Train_Loss 3.0523e-02, Val_Loss 2.8218e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [74] Train_Loss 3.1631e-02, Val_Loss 2.8881e-02\n",
            "Epoch [75] Train_Loss 3.1385e-02, Val_Loss 2.9450e-02\n",
            "Epoch [76] Train_Loss 2.9981e-02, Val_Loss 3.3732e-02\n",
            "Epoch [77] Train_Loss 3.2123e-02, Val_Loss 2.6755e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [78] Train_Loss 2.8861e-02, Val_Loss 2.8627e-02\n",
            "Epoch [79] Train_Loss 2.7203e-02, Val_Loss 2.5607e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [80] Train_Loss 2.8412e-02, Val_Loss 2.9144e-02\n",
            "Epoch [81] Train_Loss 2.6081e-02, Val_Loss 2.4641e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [82] Train_Loss 2.5764e-02, Val_Loss 2.5976e-02\n",
            "Epoch [83] Train_Loss 2.5896e-02, Val_Loss 2.7607e-02\n",
            "Epoch [84] Train_Loss 2.6329e-02, Val_Loss 2.6177e-02\n",
            "Epoch [85] Train_Loss 2.9050e-02, Val_Loss 2.6476e-02\n",
            "Epoch [86] Train_Loss 2.5297e-02, Val_Loss 2.7028e-02\n",
            "Epoch [87] Train_Loss 2.4764e-02, Val_Loss 2.3134e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [88] Train_Loss 2.5183e-02, Val_Loss 2.2470e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [89] Train_Loss 2.3694e-02, Val_Loss 2.2059e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [90] Train_Loss 2.4066e-02, Val_Loss 2.2558e-02\n",
            "Epoch [91] Train_Loss 2.3240e-02, Val_Loss 2.1872e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [92] Train_Loss 2.2953e-02, Val_Loss 2.0768e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [93] Train_Loss 2.2585e-02, Val_Loss 2.1511e-02\n",
            "Epoch [94] Train_Loss 2.2347e-02, Val_Loss 2.3753e-02\n",
            "Epoch [95] Train_Loss 2.2974e-02, Val_Loss 2.1035e-02\n",
            "Epoch [96] Train_Loss 2.1152e-02, Val_Loss 2.0028e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [97] Train_Loss 2.2496e-02, Val_Loss 2.1052e-02\n",
            "Epoch [98] Train_Loss 2.0690e-02, Val_Loss 1.9183e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [99] Train_Loss 2.1495e-02, Val_Loss 2.4028e-02\n",
            "<All keys matched successfully>\n",
            "-----------------------------------------------\n",
            "ID_01: AUC = 0.7317, PAUC = 0.6447, F1 = 0.5651\n",
            "ID_02: AUC = 0.7695, PAUC = 0.6877, F1 = 0.5441\n",
            "ID_03: AUC = 0.6812, PAUC = 0.5612, F1 = 0.5231\n",
            "-----------------------------------------------\n",
            "Avg:  AUC = 0.7275, PAUC = 0.6312, F1 = 0.5441\n",
            "-------------------------\n",
            "Training Model [ID = 01]\n",
            "-------------------------\n",
            "Epoch [0] Train_Loss 7.1899e+00, Val_Loss 2.5987e+00\n",
            "Saving Model\n",
            "\n",
            "Epoch [1] Train_Loss 1.4624e+00, Val_Loss 7.5713e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [2] Train_Loss 6.1644e-01, Val_Loss 4.4447e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [3] Train_Loss 4.3264e-01, Val_Loss 3.4428e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [4] Train_Loss 3.5284e-01, Val_Loss 3.0701e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [5] Train_Loss 3.2652e-01, Val_Loss 2.7610e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [6] Train_Loss 2.7143e-01, Val_Loss 2.3985e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [7] Train_Loss 2.4268e-01, Val_Loss 2.1886e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [8] Train_Loss 2.2396e-01, Val_Loss 1.9937e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [9] Train_Loss 2.0574e-01, Val_Loss 1.9896e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [10] Train_Loss 2.1653e-01, Val_Loss 2.0342e-01\n",
            "Epoch [11] Train_Loss 1.7137e-01, Val_Loss 1.6147e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [12] Train_Loss 1.5932e-01, Val_Loss 1.5300e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [13] Train_Loss 1.4851e-01, Val_Loss 1.4004e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [14] Train_Loss 1.3683e-01, Val_Loss 1.3133e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [15] Train_Loss 1.4099e-01, Val_Loss 1.2919e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [16] Train_Loss 1.2667e-01, Val_Loss 1.1923e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [17] Train_Loss 1.1943e-01, Val_Loss 1.1763e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [18] Train_Loss 1.1274e-01, Val_Loss 1.0619e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [19] Train_Loss 1.0747e-01, Val_Loss 1.0014e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [20] Train_Loss 1.1515e-01, Val_Loss 1.1390e-01\n",
            "Epoch [21] Train_Loss 1.0586e-01, Val_Loss 9.7172e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [22] Train_Loss 1.0042e-01, Val_Loss 1.0474e-01\n",
            "Epoch [23] Train_Loss 9.6023e-02, Val_Loss 9.0558e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [24] Train_Loss 8.7972e-02, Val_Loss 8.6871e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [25] Train_Loss 8.7801e-02, Val_Loss 8.3644e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [26] Train_Loss 8.4804e-02, Val_Loss 7.9694e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [27] Train_Loss 7.7973e-02, Val_Loss 8.1285e-02\n",
            "Epoch [28] Train_Loss 7.5575e-02, Val_Loss 7.2989e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [29] Train_Loss 7.5756e-02, Val_Loss 7.3558e-02\n",
            "Epoch [30] Train_Loss 7.8962e-02, Val_Loss 7.0077e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [31] Train_Loss 7.6815e-02, Val_Loss 7.0894e-02\n",
            "Epoch [32] Train_Loss 7.1704e-02, Val_Loss 7.8145e-02\n",
            "Epoch [33] Train_Loss 7.1750e-02, Val_Loss 6.7737e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [34] Train_Loss 8.5655e-02, Val_Loss 8.0931e-02\n",
            "Epoch [35] Train_Loss 8.4745e-02, Val_Loss 7.0302e-02\n",
            "Epoch [36] Train_Loss 6.7743e-02, Val_Loss 6.5410e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [37] Train_Loss 6.1098e-02, Val_Loss 5.9435e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [38] Train_Loss 6.4456e-02, Val_Loss 6.4568e-02\n",
            "Epoch [39] Train_Loss 5.9496e-02, Val_Loss 5.7271e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [40] Train_Loss 6.2368e-02, Val_Loss 5.8309e-02\n",
            "Epoch [41] Train_Loss 5.7824e-02, Val_Loss 6.1634e-02\n",
            "Epoch [42] Train_Loss 5.5813e-02, Val_Loss 7.1069e-02\n",
            "Epoch [43] Train_Loss 5.4132e-02, Val_Loss 5.9564e-02\n",
            "Epoch [44] Train_Loss 6.2422e-02, Val_Loss 5.9226e-02\n",
            "Epoch [45] Train_Loss 5.7477e-02, Val_Loss 5.0665e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [46] Train_Loss 5.4458e-02, Val_Loss 4.7654e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [47] Train_Loss 4.9034e-02, Val_Loss 4.7538e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [48] Train_Loss 4.8273e-02, Val_Loss 4.7916e-02\n",
            "Epoch [49] Train_Loss 4.8843e-02, Val_Loss 4.9193e-02\n",
            "Epoch [50] Train_Loss 5.2641e-02, Val_Loss 4.5717e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [51] Train_Loss 4.6243e-02, Val_Loss 4.1595e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [52] Train_Loss 4.6298e-02, Val_Loss 4.4054e-02\n",
            "Epoch [53] Train_Loss 4.3945e-02, Val_Loss 4.7547e-02\n",
            "Epoch [54] Train_Loss 4.2631e-02, Val_Loss 4.3116e-02\n",
            "Epoch [55] Train_Loss 4.3238e-02, Val_Loss 3.8699e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [56] Train_Loss 4.4316e-02, Val_Loss 3.8650e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [57] Train_Loss 4.0979e-02, Val_Loss 3.9991e-02\n",
            "Epoch [58] Train_Loss 4.4448e-02, Val_Loss 3.8131e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [59] Train_Loss 4.2306e-02, Val_Loss 4.2722e-02\n",
            "Epoch [60] Train_Loss 4.1660e-02, Val_Loss 4.6596e-02\n",
            "Epoch [61] Train_Loss 4.2608e-02, Val_Loss 5.0987e-02\n",
            "Epoch [62] Train_Loss 4.0579e-02, Val_Loss 4.1993e-02\n",
            "Epoch [63] Train_Loss 3.8791e-02, Val_Loss 3.7946e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [64] Train_Loss 3.7553e-02, Val_Loss 4.1001e-02\n",
            "Epoch [65] Train_Loss 3.8447e-02, Val_Loss 4.0867e-02\n",
            "Epoch [66] Train_Loss 3.6684e-02, Val_Loss 3.4929e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [67] Train_Loss 3.4796e-02, Val_Loss 3.6298e-02\n",
            "Epoch [68] Train_Loss 3.6121e-02, Val_Loss 4.1611e-02\n",
            "Epoch [69] Train_Loss 3.4949e-02, Val_Loss 4.4387e-02\n",
            "Epoch [70] Train_Loss 3.7326e-02, Val_Loss 3.8650e-02\n",
            "Epoch [71] Train_Loss 4.1593e-02, Val_Loss 4.3710e-02\n",
            "Epoch [72] Train_Loss 3.7015e-02, Val_Loss 3.0305e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [73] Train_Loss 3.9647e-02, Val_Loss 3.4585e-02\n",
            "Epoch [74] Train_Loss 3.8234e-02, Val_Loss 3.3702e-02\n",
            "Epoch [75] Train_Loss 3.6235e-02, Val_Loss 4.3998e-02\n",
            "Epoch [76] Train_Loss 3.3769e-02, Val_Loss 3.2105e-02\n",
            "Epoch [77] Train_Loss 2.8642e-02, Val_Loss 2.9178e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [78] Train_Loss 2.8064e-02, Val_Loss 3.0925e-02\n",
            "Epoch [79] Train_Loss 2.8174e-02, Val_Loss 2.8112e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [80] Train_Loss 3.0057e-02, Val_Loss 2.5457e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [81] Train_Loss 2.6063e-02, Val_Loss 2.5249e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [82] Train_Loss 2.6995e-02, Val_Loss 2.5442e-02\n",
            "Epoch [83] Train_Loss 2.6586e-02, Val_Loss 2.6203e-02\n",
            "Epoch [84] Train_Loss 2.6983e-02, Val_Loss 2.5828e-02\n",
            "Epoch [85] Train_Loss 2.7173e-02, Val_Loss 2.4887e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [86] Train_Loss 2.5365e-02, Val_Loss 2.5138e-02\n",
            "Epoch [87] Train_Loss 2.8357e-02, Val_Loss 2.3579e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [88] Train_Loss 3.1157e-02, Val_Loss 3.3373e-02\n",
            "Epoch [89] Train_Loss 2.6835e-02, Val_Loss 3.4323e-02\n",
            "Epoch [90] Train_Loss 2.7544e-02, Val_Loss 2.2662e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [91] Train_Loss 2.5270e-02, Val_Loss 2.4261e-02\n",
            "Epoch [92] Train_Loss 3.3835e-02, Val_Loss 2.5466e-02\n",
            "Epoch [93] Train_Loss 2.7128e-02, Val_Loss 2.7720e-02\n",
            "Epoch [94] Train_Loss 2.6043e-02, Val_Loss 2.9381e-02\n",
            "Epoch [95] Train_Loss 2.4498e-02, Val_Loss 2.8344e-02\n",
            "Epoch [96] Train_Loss 2.4729e-02, Val_Loss 2.7903e-02\n",
            "Epoch [97] Train_Loss 2.6942e-02, Val_Loss 2.0899e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [98] Train_Loss 3.1324e-02, Val_Loss 2.3666e-02\n",
            "Epoch [99] Train_Loss 2.6907e-02, Val_Loss 2.7186e-02\n",
            "<All keys matched successfully>\n",
            "-------------------------\n",
            "Training Model [ID = 02]\n",
            "-------------------------\n",
            "Epoch [0] Train_Loss 5.7784e+00, Val_Loss 2.7245e+00\n",
            "Saving Model\n",
            "\n",
            "Epoch [1] Train_Loss 1.9292e+00, Val_Loss 1.2748e+00\n",
            "Saving Model\n",
            "\n",
            "Epoch [2] Train_Loss 1.0492e+00, Val_Loss 8.6357e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [3] Train_Loss 7.5957e-01, Val_Loss 6.6403e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [4] Train_Loss 6.1181e-01, Val_Loss 5.5937e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [5] Train_Loss 5.4131e-01, Val_Loss 4.7396e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [6] Train_Loss 4.6224e-01, Val_Loss 4.1149e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [7] Train_Loss 4.1365e-01, Val_Loss 3.7832e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [8] Train_Loss 3.6783e-01, Val_Loss 3.3266e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [9] Train_Loss 3.3124e-01, Val_Loss 3.0617e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [10] Train_Loss 3.1165e-01, Val_Loss 2.8820e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [11] Train_Loss 2.7964e-01, Val_Loss 2.6803e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [12] Train_Loss 2.6110e-01, Val_Loss 2.5259e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [13] Train_Loss 2.4141e-01, Val_Loss 2.4053e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [14] Train_Loss 2.2639e-01, Val_Loss 2.3039e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [15] Train_Loss 2.2808e-01, Val_Loss 2.3475e-01\n",
            "Epoch [16] Train_Loss 2.0073e-01, Val_Loss 2.1701e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [17] Train_Loss 1.8627e-01, Val_Loss 2.0393e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [18] Train_Loss 1.7166e-01, Val_Loss 1.8055e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [19] Train_Loss 1.6029e-01, Val_Loss 1.6076e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [20] Train_Loss 1.6992e-01, Val_Loss 1.5353e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [21] Train_Loss 1.5836e-01, Val_Loss 1.4643e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [22] Train_Loss 1.5043e-01, Val_Loss 1.4319e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [23] Train_Loss 1.4190e-01, Val_Loss 1.3753e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [24] Train_Loss 1.3624e-01, Val_Loss 1.2890e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [25] Train_Loss 1.4456e-01, Val_Loss 1.2757e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [26] Train_Loss 1.3210e-01, Val_Loss 1.2136e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [27] Train_Loss 1.2672e-01, Val_Loss 1.1627e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [28] Train_Loss 1.2199e-01, Val_Loss 1.1175e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [29] Train_Loss 1.1749e-01, Val_Loss 1.0871e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [30] Train_Loss 1.1286e-01, Val_Loss 9.8212e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [31] Train_Loss 1.0301e-01, Val_Loss 9.2970e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [32] Train_Loss 9.9816e-02, Val_Loss 8.9171e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [33] Train_Loss 9.6600e-02, Val_Loss 8.6131e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [34] Train_Loss 9.3808e-02, Val_Loss 8.3502e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [35] Train_Loss 1.0360e-01, Val_Loss 8.7347e-02\n",
            "Epoch [36] Train_Loss 9.4621e-02, Val_Loss 8.9083e-02\n",
            "Epoch [37] Train_Loss 9.0829e-02, Val_Loss 9.0503e-02\n",
            "Epoch [38] Train_Loss 8.7659e-02, Val_Loss 9.0457e-02\n",
            "Epoch [39] Train_Loss 8.4762e-02, Val_Loss 8.8136e-02\n",
            "Epoch [40] Train_Loss 8.7369e-02, Val_Loss 8.1804e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [41] Train_Loss 7.9399e-02, Val_Loss 7.8355e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [42] Train_Loss 7.7158e-02, Val_Loss 7.4584e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [43] Train_Loss 7.4981e-02, Val_Loss 7.1348e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [44] Train_Loss 7.2710e-02, Val_Loss 6.8049e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [45] Train_Loss 7.7698e-02, Val_Loss 7.0024e-02\n",
            "Epoch [46] Train_Loss 7.1911e-02, Val_Loss 6.7116e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [47] Train_Loss 6.8805e-02, Val_Loss 6.4435e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [48] Train_Loss 6.5884e-02, Val_Loss 6.2462e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [49] Train_Loss 6.3500e-02, Val_Loss 6.0832e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [50] Train_Loss 6.3714e-02, Val_Loss 5.7961e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [51] Train_Loss 5.8764e-02, Val_Loss 5.6065e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [52] Train_Loss 5.7703e-02, Val_Loss 5.4843e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [53] Train_Loss 5.6700e-02, Val_Loss 5.3659e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [54] Train_Loss 5.5894e-02, Val_Loss 5.2686e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [55] Train_Loss 5.7931e-02, Val_Loss 5.2698e-02\n",
            "Epoch [56] Train_Loss 5.5872e-02, Val_Loss 5.2361e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [57] Train_Loss 5.5565e-02, Val_Loss 5.0879e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [58] Train_Loss 5.4803e-02, Val_Loss 4.8889e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [59] Train_Loss 5.3517e-02, Val_Loss 4.7571e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [60] Train_Loss 5.3820e-02, Val_Loss 4.7678e-02\n",
            "Epoch [61] Train_Loss 4.9589e-02, Val_Loss 4.5641e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [62] Train_Loss 4.8182e-02, Val_Loss 4.4030e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [63] Train_Loss 4.7374e-02, Val_Loss 4.2933e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [64] Train_Loss 4.6614e-02, Val_Loss 4.2061e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [65] Train_Loss 4.7800e-02, Val_Loss 4.1964e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [66] Train_Loss 4.4828e-02, Val_Loss 4.0992e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [67] Train_Loss 4.3722e-02, Val_Loss 3.9735e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [68] Train_Loss 4.2726e-02, Val_Loss 3.8815e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [69] Train_Loss 4.1946e-02, Val_Loss 3.7937e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [70] Train_Loss 4.3049e-02, Val_Loss 3.8130e-02\n",
            "Epoch [71] Train_Loss 4.1199e-02, Val_Loss 3.7162e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [72] Train_Loss 4.0438e-02, Val_Loss 3.6764e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [73] Train_Loss 4.0213e-02, Val_Loss 3.6162e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [74] Train_Loss 4.0048e-02, Val_Loss 3.5825e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [75] Train_Loss 4.1067e-02, Val_Loss 3.5960e-02\n",
            "Epoch [76] Train_Loss 4.0249e-02, Val_Loss 3.6094e-02\n",
            "Epoch [77] Train_Loss 3.9094e-02, Val_Loss 3.5924e-02\n",
            "Epoch [78] Train_Loss 3.8753e-02, Val_Loss 3.5964e-02\n",
            "Epoch [79] Train_Loss 3.8606e-02, Val_Loss 3.6056e-02\n",
            "Epoch [80] Train_Loss 4.0141e-02, Val_Loss 3.5662e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [81] Train_Loss 3.9849e-02, Val_Loss 3.5097e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [82] Train_Loss 4.0222e-02, Val_Loss 3.3964e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [83] Train_Loss 4.1544e-02, Val_Loss 3.3633e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [84] Train_Loss 4.3227e-02, Val_Loss 4.2145e-02\n",
            "Epoch [85] Train_Loss 4.9471e-02, Val_Loss 5.0320e-02\n",
            "Epoch [86] Train_Loss 3.8774e-02, Val_Loss 3.4273e-02\n",
            "Epoch [87] Train_Loss 3.2620e-02, Val_Loss 3.2692e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [88] Train_Loss 3.2014e-02, Val_Loss 3.2300e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [89] Train_Loss 3.1769e-02, Val_Loss 3.1526e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [90] Train_Loss 3.3087e-02, Val_Loss 3.0500e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [91] Train_Loss 3.0774e-02, Val_Loss 2.9301e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [92] Train_Loss 2.9792e-02, Val_Loss 2.8385e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [93] Train_Loss 2.8941e-02, Val_Loss 2.7607e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [94] Train_Loss 2.8226e-02, Val_Loss 2.6900e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [95] Train_Loss 2.8803e-02, Val_Loss 2.6268e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [96] Train_Loss 2.6993e-02, Val_Loss 2.5657e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [97] Train_Loss 2.6481e-02, Val_Loss 2.5119e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [98] Train_Loss 2.6073e-02, Val_Loss 2.4612e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [99] Train_Loss 2.5682e-02, Val_Loss 2.4114e-02\n",
            "Saving Model\n",
            "\n",
            "<All keys matched successfully>\n",
            "-------------------------\n",
            "Training Model [ID = 03]\n",
            "-------------------------\n",
            "Epoch [0] Train_Loss 7.1423e+00, Val_Loss 2.6435e+00\n",
            "Saving Model\n",
            "\n",
            "Epoch [1] Train_Loss 1.5391e+00, Val_Loss 6.6673e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [2] Train_Loss 5.5345e-01, Val_Loss 4.6815e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [3] Train_Loss 3.9202e-01, Val_Loss 3.3848e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [4] Train_Loss 3.2003e-01, Val_Loss 2.8846e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [5] Train_Loss 3.1883e-01, Val_Loss 2.8568e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [6] Train_Loss 2.7426e-01, Val_Loss 2.7245e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [7] Train_Loss 2.4919e-01, Val_Loss 2.4493e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [8] Train_Loss 2.3080e-01, Val_Loss 2.2759e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [9] Train_Loss 2.0686e-01, Val_Loss 2.0756e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [10] Train_Loss 2.1179e-01, Val_Loss 2.0390e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [11] Train_Loss 1.8056e-01, Val_Loss 1.7563e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [12] Train_Loss 1.7984e-01, Val_Loss 1.8816e-01\n",
            "Epoch [13] Train_Loss 1.7599e-01, Val_Loss 1.7286e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [14] Train_Loss 1.5293e-01, Val_Loss 1.5447e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [15] Train_Loss 1.6106e-01, Val_Loss 1.5655e-01\n",
            "Epoch [16] Train_Loss 1.3957e-01, Val_Loss 1.3906e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [17] Train_Loss 1.3113e-01, Val_Loss 1.5883e-01\n",
            "Epoch [18] Train_Loss 1.2684e-01, Val_Loss 1.3269e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [19] Train_Loss 1.1676e-01, Val_Loss 1.2299e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [20] Train_Loss 1.2922e-01, Val_Loss 1.4164e-01\n",
            "Epoch [21] Train_Loss 1.1313e-01, Val_Loss 1.1586e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [22] Train_Loss 1.0310e-01, Val_Loss 1.0602e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [23] Train_Loss 9.9748e-02, Val_Loss 1.0550e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [24] Train_Loss 1.0001e-01, Val_Loss 9.4788e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [25] Train_Loss 1.0209e-01, Val_Loss 9.4726e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [26] Train_Loss 1.0284e-01, Val_Loss 9.0796e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [27] Train_Loss 9.7959e-02, Val_Loss 9.5711e-02\n",
            "Epoch [28] Train_Loss 1.0565e-01, Val_Loss 1.3039e-01\n",
            "Epoch [29] Train_Loss 9.5504e-02, Val_Loss 1.0601e-01\n",
            "Epoch [30] Train_Loss 1.0419e-01, Val_Loss 1.3440e-01\n",
            "Epoch [31] Train_Loss 9.1165e-02, Val_Loss 9.2182e-02\n",
            "Epoch [32] Train_Loss 9.2189e-02, Val_Loss 9.1701e-02\n",
            "Epoch [33] Train_Loss 8.3999e-02, Val_Loss 8.7950e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [34] Train_Loss 8.7125e-02, Val_Loss 8.9856e-02\n",
            "Epoch [35] Train_Loss 8.4790e-02, Val_Loss 8.1892e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [36] Train_Loss 9.0413e-02, Val_Loss 9.0623e-02\n",
            "Epoch [37] Train_Loss 8.0840e-02, Val_Loss 7.5653e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [38] Train_Loss 8.5107e-02, Val_Loss 9.4259e-02\n",
            "Epoch [39] Train_Loss 7.4228e-02, Val_Loss 9.0514e-02\n",
            "Epoch [40] Train_Loss 7.1453e-02, Val_Loss 7.7518e-02\n",
            "Epoch [41] Train_Loss 6.4235e-02, Val_Loss 7.3610e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [42] Train_Loss 6.0812e-02, Val_Loss 6.0992e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [43] Train_Loss 6.7701e-02, Val_Loss 8.2633e-02\n",
            "Epoch [44] Train_Loss 7.9223e-02, Val_Loss 8.4607e-02\n",
            "Epoch [45] Train_Loss 6.4574e-02, Val_Loss 6.2506e-02\n",
            "Epoch [46] Train_Loss 6.1579e-02, Val_Loss 8.9854e-02\n",
            "Epoch [47] Train_Loss 6.4874e-02, Val_Loss 7.2352e-02\n",
            "Epoch [48] Train_Loss 5.5276e-02, Val_Loss 7.4161e-02\n",
            "Epoch [49] Train_Loss 6.0406e-02, Val_Loss 8.6913e-02\n",
            "Epoch [50] Train_Loss 6.2641e-02, Val_Loss 7.7723e-02\n",
            "Epoch [51] Train_Loss 5.8980e-02, Val_Loss 7.1608e-02\n",
            "Epoch [52] Train_Loss 5.1924e-02, Val_Loss 6.7224e-02\n",
            "Epoch [53] Train_Loss 5.1543e-02, Val_Loss 7.1350e-02\n",
            "Epoch [54] Train_Loss 5.1279e-02, Val_Loss 6.0461e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [55] Train_Loss 6.5638e-02, Val_Loss 6.9379e-02\n",
            "Epoch [56] Train_Loss 5.2363e-02, Val_Loss 6.4004e-02\n",
            "Epoch [57] Train_Loss 4.8227e-02, Val_Loss 6.0235e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [58] Train_Loss 4.9697e-02, Val_Loss 6.6105e-02\n",
            "Epoch [59] Train_Loss 5.1263e-02, Val_Loss 6.6722e-02\n",
            "Epoch [60] Train_Loss 5.2081e-02, Val_Loss 6.4510e-02\n",
            "Epoch [61] Train_Loss 5.2500e-02, Val_Loss 5.4999e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [62] Train_Loss 5.7622e-02, Val_Loss 4.5940e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [63] Train_Loss 6.1607e-02, Val_Loss 4.3201e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [64] Train_Loss 5.0104e-02, Val_Loss 4.5123e-02\n",
            "Epoch [65] Train_Loss 5.1260e-02, Val_Loss 4.1443e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [66] Train_Loss 4.5354e-02, Val_Loss 4.1199e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [67] Train_Loss 4.1197e-02, Val_Loss 3.6766e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [68] Train_Loss 4.1738e-02, Val_Loss 4.4720e-02\n",
            "Epoch [69] Train_Loss 3.9559e-02, Val_Loss 3.7603e-02\n",
            "Epoch [70] Train_Loss 4.0282e-02, Val_Loss 4.0035e-02\n",
            "Epoch [71] Train_Loss 4.1163e-02, Val_Loss 3.5946e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [72] Train_Loss 4.1682e-02, Val_Loss 3.8577e-02\n",
            "Epoch [73] Train_Loss 3.9585e-02, Val_Loss 4.2553e-02\n",
            "Epoch [74] Train_Loss 4.4119e-02, Val_Loss 3.3279e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [75] Train_Loss 5.1909e-02, Val_Loss 3.6641e-02\n",
            "Epoch [76] Train_Loss 4.4872e-02, Val_Loss 4.6997e-02\n",
            "Epoch [77] Train_Loss 3.7530e-02, Val_Loss 3.8016e-02\n",
            "Epoch [78] Train_Loss 3.8167e-02, Val_Loss 3.4039e-02\n",
            "Epoch [79] Train_Loss 4.1108e-02, Val_Loss 5.2624e-02\n",
            "Epoch [80] Train_Loss 3.5353e-02, Val_Loss 3.6879e-02\n",
            "Epoch [81] Train_Loss 3.6213e-02, Val_Loss 3.8834e-02\n",
            "Epoch [82] Train_Loss 3.1970e-02, Val_Loss 3.0682e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [83] Train_Loss 2.9647e-02, Val_Loss 3.0327e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [84] Train_Loss 3.2378e-02, Val_Loss 3.2287e-02\n",
            "Epoch [85] Train_Loss 3.2773e-02, Val_Loss 3.7417e-02\n",
            "Epoch [86] Train_Loss 3.2472e-02, Val_Loss 4.0092e-02\n",
            "Epoch [87] Train_Loss 3.0517e-02, Val_Loss 3.7833e-02\n",
            "Epoch [88] Train_Loss 2.8401e-02, Val_Loss 2.5121e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [89] Train_Loss 2.7676e-02, Val_Loss 2.6872e-02\n",
            "Epoch [90] Train_Loss 2.5305e-02, Val_Loss 2.4149e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [91] Train_Loss 2.6354e-02, Val_Loss 2.7079e-02\n",
            "Epoch [92] Train_Loss 2.7672e-02, Val_Loss 2.5339e-02\n",
            "Epoch [93] Train_Loss 3.0671e-02, Val_Loss 2.7482e-02\n",
            "Epoch [94] Train_Loss 2.9384e-02, Val_Loss 3.7724e-02\n",
            "Epoch [95] Train_Loss 3.0472e-02, Val_Loss 3.0802e-02\n",
            "Epoch [96] Train_Loss 2.5569e-02, Val_Loss 2.2557e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [97] Train_Loss 2.2834e-02, Val_Loss 2.2961e-02\n",
            "Epoch [98] Train_Loss 2.6376e-02, Val_Loss 3.0801e-02\n",
            "Epoch [99] Train_Loss 2.2291e-02, Val_Loss 2.3621e-02\n",
            "<All keys matched successfully>\n",
            "-----------------------------------------------\n",
            "ID_01: AUC = 0.8169, PAUC = 0.7243, F1 = 0.6235\n",
            "ID_02: AUC = 0.5423, PAUC = 0.5027, F1 = 0.4259\n",
            "ID_03: AUC = 0.6614, PAUC = 0.5276, F1 = 0.5047\n",
            "-----------------------------------------------\n",
            "Avg:  AUC = 0.6735, PAUC = 0.5849, F1 = 0.5180\n",
            "-------------------------\n",
            "Training Model [ID = 01]\n",
            "-------------------------\n",
            "Epoch [0] Train_Loss 5.4069e+00, Val_Loss 2.6751e+00\n",
            "Saving Model\n",
            "\n",
            "Epoch [1] Train_Loss 1.5956e+00, Val_Loss 7.7513e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [2] Train_Loss 4.8655e-01, Val_Loss 3.6244e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [3] Train_Loss 2.9869e-01, Val_Loss 2.6390e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [4] Train_Loss 2.4173e-01, Val_Loss 2.2597e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [5] Train_Loss 2.1469e-01, Val_Loss 1.8496e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [6] Train_Loss 1.7655e-01, Val_Loss 1.7353e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [7] Train_Loss 1.5521e-01, Val_Loss 1.4696e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [8] Train_Loss 1.4346e-01, Val_Loss 1.3226e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [9] Train_Loss 1.3216e-01, Val_Loss 1.1958e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [10] Train_Loss 1.2904e-01, Val_Loss 1.1301e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [11] Train_Loss 1.0909e-01, Val_Loss 1.0494e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [12] Train_Loss 1.0630e-01, Val_Loss 9.8022e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [13] Train_Loss 1.0083e-01, Val_Loss 9.5687e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [14] Train_Loss 9.5935e-02, Val_Loss 9.6680e-02\n",
            "Epoch [15] Train_Loss 9.7382e-02, Val_Loss 8.4091e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [16] Train_Loss 8.5987e-02, Val_Loss 8.5564e-02\n",
            "Epoch [17] Train_Loss 8.3936e-02, Val_Loss 8.7043e-02\n",
            "Epoch [18] Train_Loss 8.4191e-02, Val_Loss 7.1004e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [19] Train_Loss 7.6991e-02, Val_Loss 6.7488e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [20] Train_Loss 8.0200e-02, Val_Loss 6.7106e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [21] Train_Loss 7.0631e-02, Val_Loss 6.8797e-02\n",
            "Epoch [22] Train_Loss 6.9130e-02, Val_Loss 6.2490e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [23] Train_Loss 6.6904e-02, Val_Loss 6.4047e-02\n",
            "Epoch [24] Train_Loss 6.4969e-02, Val_Loss 7.2902e-02\n",
            "Epoch [25] Train_Loss 6.9706e-02, Val_Loss 8.4692e-02\n",
            "Epoch [26] Train_Loss 6.4729e-02, Val_Loss 6.6528e-02\n",
            "Epoch [27] Train_Loss 5.7006e-02, Val_Loss 5.2060e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [28] Train_Loss 5.2088e-02, Val_Loss 5.0841e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [29] Train_Loss 5.1242e-02, Val_Loss 4.7067e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [30] Train_Loss 5.7357e-02, Val_Loss 5.3497e-02\n",
            "Epoch [31] Train_Loss 5.2653e-02, Val_Loss 5.6055e-02\n",
            "Epoch [32] Train_Loss 5.2208e-02, Val_Loss 4.4742e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [33] Train_Loss 4.5291e-02, Val_Loss 4.3253e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [34] Train_Loss 4.4545e-02, Val_Loss 4.3974e-02\n",
            "Epoch [35] Train_Loss 4.6072e-02, Val_Loss 4.4451e-02\n",
            "Epoch [36] Train_Loss 4.4065e-02, Val_Loss 4.6033e-02\n",
            "Epoch [37] Train_Loss 4.3650e-02, Val_Loss 4.1274e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [38] Train_Loss 4.0617e-02, Val_Loss 4.1786e-02\n",
            "Epoch [39] Train_Loss 4.1515e-02, Val_Loss 3.8083e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [40] Train_Loss 4.2397e-02, Val_Loss 3.8399e-02\n",
            "Epoch [41] Train_Loss 3.8573e-02, Val_Loss 3.7710e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [42] Train_Loss 3.7230e-02, Val_Loss 3.6612e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [43] Train_Loss 3.6213e-02, Val_Loss 3.6218e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [44] Train_Loss 3.5198e-02, Val_Loss 3.4221e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [45] Train_Loss 3.9592e-02, Val_Loss 3.3962e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [46] Train_Loss 3.4819e-02, Val_Loss 3.5270e-02\n",
            "Epoch [47] Train_Loss 3.3379e-02, Val_Loss 3.6759e-02\n",
            "Epoch [48] Train_Loss 3.5457e-02, Val_Loss 4.6316e-02\n",
            "Epoch [49] Train_Loss 4.0981e-02, Val_Loss 3.3569e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [50] Train_Loss 4.6513e-02, Val_Loss 4.6182e-02\n",
            "Epoch [51] Train_Loss 4.4558e-02, Val_Loss 6.4657e-02\n",
            "Epoch [52] Train_Loss 4.9352e-02, Val_Loss 3.5696e-02\n",
            "Epoch [53] Train_Loss 3.2943e-02, Val_Loss 3.2602e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [54] Train_Loss 3.5556e-02, Val_Loss 3.2339e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [55] Train_Loss 3.6059e-02, Val_Loss 3.3131e-02\n",
            "Epoch [56] Train_Loss 3.2618e-02, Val_Loss 3.0907e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [57] Train_Loss 3.3145e-02, Val_Loss 3.2333e-02\n",
            "Epoch [58] Train_Loss 3.4784e-02, Val_Loss 3.1089e-02\n",
            "Epoch [59] Train_Loss 2.9203e-02, Val_Loss 3.1543e-02\n",
            "Epoch [60] Train_Loss 3.3266e-02, Val_Loss 3.0901e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [61] Train_Loss 2.7638e-02, Val_Loss 3.1785e-02\n",
            "Epoch [62] Train_Loss 2.8060e-02, Val_Loss 2.6662e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [63] Train_Loss 2.7362e-02, Val_Loss 2.7963e-02\n",
            "Epoch [64] Train_Loss 2.6952e-02, Val_Loss 2.5475e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [65] Train_Loss 2.7099e-02, Val_Loss 3.1332e-02\n",
            "Epoch [66] Train_Loss 2.6656e-02, Val_Loss 2.6905e-02\n",
            "Epoch [67] Train_Loss 2.4769e-02, Val_Loss 2.8322e-02\n",
            "Epoch [68] Train_Loss 2.3866e-02, Val_Loss 3.4309e-02\n",
            "Epoch [69] Train_Loss 2.4545e-02, Val_Loss 2.4272e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [70] Train_Loss 2.5441e-02, Val_Loss 3.0825e-02\n",
            "Epoch [71] Train_Loss 2.3999e-02, Val_Loss 2.9619e-02\n",
            "Epoch [72] Train_Loss 2.2526e-02, Val_Loss 2.3784e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [73] Train_Loss 2.1875e-02, Val_Loss 2.8785e-02\n",
            "Epoch [74] Train_Loss 2.2493e-02, Val_Loss 3.7680e-02\n",
            "Epoch [75] Train_Loss 2.8541e-02, Val_Loss 3.3398e-02\n",
            "Epoch [76] Train_Loss 2.3085e-02, Val_Loss 3.1810e-02\n",
            "Epoch [77] Train_Loss 2.4645e-02, Val_Loss 3.1552e-02\n",
            "Epoch [78] Train_Loss 2.5716e-02, Val_Loss 2.8376e-02\n",
            "Epoch [79] Train_Loss 2.9472e-02, Val_Loss 2.6327e-02\n",
            "Epoch [80] Train_Loss 3.9636e-02, Val_Loss 2.4805e-02\n",
            "Epoch [81] Train_Loss 2.5098e-02, Val_Loss 2.2185e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [82] Train_Loss 2.5712e-02, Val_Loss 2.3056e-02\n",
            "Epoch [83] Train_Loss 2.1280e-02, Val_Loss 2.1741e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [84] Train_Loss 2.3970e-02, Val_Loss 2.1053e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [85] Train_Loss 2.4439e-02, Val_Loss 2.2815e-02\n",
            "Epoch [86] Train_Loss 2.3310e-02, Val_Loss 1.8638e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [87] Train_Loss 2.2931e-02, Val_Loss 2.1406e-02\n",
            "Epoch [88] Train_Loss 2.2699e-02, Val_Loss 1.9796e-02\n",
            "Epoch [89] Train_Loss 2.3381e-02, Val_Loss 1.7358e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [90] Train_Loss 2.1579e-02, Val_Loss 1.7791e-02\n",
            "Epoch [91] Train_Loss 2.0816e-02, Val_Loss 1.9408e-02\n",
            "Epoch [92] Train_Loss 1.7919e-02, Val_Loss 1.9485e-02\n",
            "Epoch [93] Train_Loss 2.2438e-02, Val_Loss 1.7233e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [94] Train_Loss 2.0715e-02, Val_Loss 2.2335e-02\n",
            "Epoch [95] Train_Loss 1.8416e-02, Val_Loss 1.7623e-02\n",
            "Epoch [96] Train_Loss 1.6764e-02, Val_Loss 1.6765e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [97] Train_Loss 1.8083e-02, Val_Loss 1.6504e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [98] Train_Loss 2.5103e-02, Val_Loss 1.6880e-02\n",
            "Epoch [99] Train_Loss 2.0001e-02, Val_Loss 1.7498e-02\n",
            "<All keys matched successfully>\n",
            "-------------------------\n",
            "Training Model [ID = 02]\n",
            "-------------------------\n",
            "Epoch [0] Train_Loss 9.7384e+00, Val_Loss 3.6294e+00\n",
            "Saving Model\n",
            "\n",
            "Epoch [1] Train_Loss 2.4859e+00, Val_Loss 1.4237e+00\n",
            "Saving Model\n",
            "\n",
            "Epoch [2] Train_Loss 8.9923e-01, Val_Loss 6.1905e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [3] Train_Loss 5.5885e-01, Val_Loss 4.6345e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [4] Train_Loss 4.5007e-01, Val_Loss 3.8634e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [5] Train_Loss 4.0117e-01, Val_Loss 3.3745e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [6] Train_Loss 3.3169e-01, Val_Loss 3.0227e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [7] Train_Loss 2.9613e-01, Val_Loss 2.6704e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [8] Train_Loss 2.6915e-01, Val_Loss 2.4337e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [9] Train_Loss 2.4888e-01, Val_Loss 2.2672e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [10] Train_Loss 2.5378e-01, Val_Loss 2.1964e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [11] Train_Loss 2.2980e-01, Val_Loss 2.1038e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [12] Train_Loss 2.3083e-01, Val_Loss 1.9949e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [13] Train_Loss 2.0764e-01, Val_Loss 1.8017e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [14] Train_Loss 1.8600e-01, Val_Loss 1.7223e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [15] Train_Loss 1.8562e-01, Val_Loss 1.5790e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [16] Train_Loss 1.6412e-01, Val_Loss 1.4864e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [17] Train_Loss 1.5514e-01, Val_Loss 1.4384e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [18] Train_Loss 1.5484e-01, Val_Loss 1.3809e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [19] Train_Loss 1.4999e-01, Val_Loss 1.3042e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [20] Train_Loss 1.5329e-01, Val_Loss 1.3389e-01\n",
            "Epoch [21] Train_Loss 1.4341e-01, Val_Loss 1.3145e-01\n",
            "Epoch [22] Train_Loss 1.3551e-01, Val_Loss 1.2552e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [23] Train_Loss 1.3014e-01, Val_Loss 1.2213e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [24] Train_Loss 1.2332e-01, Val_Loss 1.1342e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [25] Train_Loss 1.2330e-01, Val_Loss 1.1065e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [26] Train_Loss 1.1312e-01, Val_Loss 1.1288e-01\n",
            "Epoch [27] Train_Loss 1.0829e-01, Val_Loss 1.1062e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [28] Train_Loss 1.0751e-01, Val_Loss 1.1642e-01\n",
            "Epoch [29] Train_Loss 1.0145e-01, Val_Loss 1.0557e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [30] Train_Loss 1.0526e-01, Val_Loss 9.6279e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [31] Train_Loss 1.0152e-01, Val_Loss 9.4024e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [32] Train_Loss 1.0234e-01, Val_Loss 8.8988e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [33] Train_Loss 9.7398e-02, Val_Loss 1.1538e-01\n",
            "Epoch [34] Train_Loss 9.3493e-02, Val_Loss 1.2452e-01\n",
            "Epoch [35] Train_Loss 9.9563e-02, Val_Loss 1.1167e-01\n",
            "Epoch [36] Train_Loss 9.0669e-02, Val_Loss 1.0552e-01\n",
            "Epoch [37] Train_Loss 8.7691e-02, Val_Loss 1.0872e-01\n",
            "Epoch [38] Train_Loss 8.4562e-02, Val_Loss 1.0447e-01\n",
            "Epoch [39] Train_Loss 8.2618e-02, Val_Loss 9.8278e-02\n",
            "Epoch [40] Train_Loss 8.6756e-02, Val_Loss 9.7384e-02\n",
            "Epoch [41] Train_Loss 7.7715e-02, Val_Loss 9.5087e-02\n",
            "Epoch [42] Train_Loss 7.7452e-02, Val_Loss 9.8926e-02\n",
            "Epoch [43] Train_Loss 7.3979e-02, Val_Loss 9.8007e-02\n",
            "Epoch [44] Train_Loss 7.2715e-02, Val_Loss 9.2666e-02\n",
            "Epoch [45] Train_Loss 7.6600e-02, Val_Loss 8.9261e-02\n",
            "Epoch [46] Train_Loss 7.0176e-02, Val_Loss 9.0141e-02\n",
            "Epoch [47] Train_Loss 6.8639e-02, Val_Loss 7.5223e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [48] Train_Loss 6.9877e-02, Val_Loss 7.4742e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [49] Train_Loss 6.9678e-02, Val_Loss 6.9050e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [50] Train_Loss 6.8866e-02, Val_Loss 6.6455e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [51] Train_Loss 6.5081e-02, Val_Loss 6.6181e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [52] Train_Loss 6.4588e-02, Val_Loss 9.1090e-02\n",
            "Epoch [53] Train_Loss 6.9022e-02, Val_Loss 9.4974e-02\n",
            "Epoch [54] Train_Loss 8.0226e-02, Val_Loss 5.4000e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [55] Train_Loss 7.0435e-02, Val_Loss 5.1936e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [56] Train_Loss 5.6640e-02, Val_Loss 4.9747e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [57] Train_Loss 5.4264e-02, Val_Loss 4.8502e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [58] Train_Loss 5.5930e-02, Val_Loss 4.9363e-02\n",
            "Epoch [59] Train_Loss 5.4298e-02, Val_Loss 5.1883e-02\n",
            "Epoch [60] Train_Loss 6.8378e-02, Val_Loss 4.6588e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [61] Train_Loss 5.8425e-02, Val_Loss 4.5782e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [62] Train_Loss 5.0640e-02, Val_Loss 4.4506e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [63] Train_Loss 4.9642e-02, Val_Loss 4.5819e-02\n",
            "Epoch [64] Train_Loss 5.2432e-02, Val_Loss 4.4056e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [65] Train_Loss 5.1134e-02, Val_Loss 4.1535e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [66] Train_Loss 4.4311e-02, Val_Loss 3.8419e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [67] Train_Loss 4.1200e-02, Val_Loss 3.9196e-02\n",
            "Epoch [68] Train_Loss 4.0488e-02, Val_Loss 3.8541e-02\n",
            "Epoch [69] Train_Loss 3.9668e-02, Val_Loss 3.7546e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [70] Train_Loss 4.1570e-02, Val_Loss 4.0060e-02\n",
            "Epoch [71] Train_Loss 3.8942e-02, Val_Loss 3.8048e-02\n",
            "Epoch [72] Train_Loss 3.8291e-02, Val_Loss 3.5600e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [73] Train_Loss 3.7297e-02, Val_Loss 3.4491e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [74] Train_Loss 3.6450e-02, Val_Loss 3.5325e-02\n",
            "Epoch [75] Train_Loss 4.0250e-02, Val_Loss 3.7196e-02\n",
            "Epoch [76] Train_Loss 3.8074e-02, Val_Loss 3.9668e-02\n",
            "Epoch [77] Train_Loss 3.9032e-02, Val_Loss 4.0118e-02\n",
            "Epoch [78] Train_Loss 4.0068e-02, Val_Loss 4.6027e-02\n",
            "Epoch [79] Train_Loss 3.8738e-02, Val_Loss 4.6864e-02\n",
            "Epoch [80] Train_Loss 3.8810e-02, Val_Loss 3.7917e-02\n",
            "Epoch [81] Train_Loss 3.5129e-02, Val_Loss 3.6800e-02\n",
            "Epoch [82] Train_Loss 3.3923e-02, Val_Loss 3.5120e-02\n",
            "Epoch [83] Train_Loss 3.3058e-02, Val_Loss 3.3253e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [84] Train_Loss 3.2620e-02, Val_Loss 3.2324e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [85] Train_Loss 3.3213e-02, Val_Loss 3.0090e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [86] Train_Loss 3.4500e-02, Val_Loss 3.6886e-02\n",
            "Epoch [87] Train_Loss 3.3920e-02, Val_Loss 3.1896e-02\n",
            "Epoch [88] Train_Loss 3.2519e-02, Val_Loss 4.9375e-02\n",
            "Epoch [89] Train_Loss 3.2403e-02, Val_Loss 3.3109e-02\n",
            "Epoch [90] Train_Loss 3.3718e-02, Val_Loss 2.9673e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [91] Train_Loss 2.9134e-02, Val_Loss 2.8608e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [92] Train_Loss 2.9965e-02, Val_Loss 2.6356e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [93] Train_Loss 2.8758e-02, Val_Loss 3.3527e-02\n",
            "Epoch [94] Train_Loss 3.0146e-02, Val_Loss 2.8191e-02\n",
            "Epoch [95] Train_Loss 2.9739e-02, Val_Loss 3.4098e-02\n",
            "Epoch [96] Train_Loss 2.7671e-02, Val_Loss 2.4587e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [97] Train_Loss 2.7335e-02, Val_Loss 2.6885e-02\n",
            "Epoch [98] Train_Loss 2.6069e-02, Val_Loss 2.5138e-02\n",
            "Epoch [99] Train_Loss 2.6369e-02, Val_Loss 2.8218e-02\n",
            "<All keys matched successfully>\n",
            "-------------------------\n",
            "Training Model [ID = 03]\n",
            "-------------------------\n",
            "Epoch [0] Train_Loss 9.9804e+00, Val_Loss 4.3341e+00\n",
            "Saving Model\n",
            "\n",
            "Epoch [1] Train_Loss 2.6398e+00, Val_Loss 1.5546e+00\n",
            "Saving Model\n",
            "\n",
            "Epoch [2] Train_Loss 1.0756e+00, Val_Loss 7.5468e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [3] Train_Loss 6.2634e-01, Val_Loss 5.5568e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [4] Train_Loss 4.9185e-01, Val_Loss 4.3912e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [5] Train_Loss 4.4799e-01, Val_Loss 3.9849e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [6] Train_Loss 3.5962e-01, Val_Loss 3.5453e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [7] Train_Loss 3.1642e-01, Val_Loss 3.0883e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [8] Train_Loss 2.9016e-01, Val_Loss 2.8071e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [9] Train_Loss 2.6837e-01, Val_Loss 2.5900e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [10] Train_Loss 2.5964e-01, Val_Loss 2.4013e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [11] Train_Loss 2.2819e-01, Val_Loss 2.1952e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [12] Train_Loss 2.0965e-01, Val_Loss 2.0519e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [13] Train_Loss 1.9573e-01, Val_Loss 1.9591e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [14] Train_Loss 1.8544e-01, Val_Loss 1.8668e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [15] Train_Loss 1.9033e-01, Val_Loss 1.8441e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [16] Train_Loss 1.7488e-01, Val_Loss 1.7234e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [17] Train_Loss 1.6554e-01, Val_Loss 1.6549e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [18] Train_Loss 1.5794e-01, Val_Loss 1.5873e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [19] Train_Loss 1.5073e-01, Val_Loss 1.5222e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [20] Train_Loss 1.5324e-01, Val_Loss 1.4674e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [21] Train_Loss 1.4141e-01, Val_Loss 1.3608e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [22] Train_Loss 1.3406e-01, Val_Loss 1.2917e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [23] Train_Loss 1.2897e-01, Val_Loss 1.2358e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [24] Train_Loss 1.2379e-01, Val_Loss 1.1837e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [25] Train_Loss 1.3230e-01, Val_Loss 1.1999e-01\n",
            "Epoch [26] Train_Loss 1.1798e-01, Val_Loss 1.1237e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [27] Train_Loss 1.1454e-01, Val_Loss 1.0839e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [28] Train_Loss 1.1032e-01, Val_Loss 1.0404e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [29] Train_Loss 1.0682e-01, Val_Loss 9.9833e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [30] Train_Loss 1.0727e-01, Val_Loss 9.6427e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [31] Train_Loss 9.9313e-02, Val_Loss 9.1677e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [32] Train_Loss 9.6530e-02, Val_Loss 8.8954e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [33] Train_Loss 9.3184e-02, Val_Loss 8.6058e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [34] Train_Loss 8.9914e-02, Val_Loss 8.3697e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [35] Train_Loss 9.5868e-02, Val_Loss 8.6152e-02\n",
            "Epoch [36] Train_Loss 8.7850e-02, Val_Loss 8.2400e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [37] Train_Loss 8.4466e-02, Val_Loss 7.9590e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [38] Train_Loss 8.2153e-02, Val_Loss 7.7276e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [39] Train_Loss 8.0195e-02, Val_Loss 7.4809e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [40] Train_Loss 8.6238e-02, Val_Loss 7.7121e-02\n",
            "Epoch [41] Train_Loss 7.9056e-02, Val_Loss 7.3853e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [42] Train_Loss 7.6232e-02, Val_Loss 7.1348e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [43] Train_Loss 7.4485e-02, Val_Loss 6.9238e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [44] Train_Loss 7.3115e-02, Val_Loss 6.7679e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [45] Train_Loss 7.4476e-02, Val_Loss 6.7641e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [46] Train_Loss 6.7721e-02, Val_Loss 6.4423e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [47] Train_Loss 6.5640e-02, Val_Loss 6.2416e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [48] Train_Loss 6.4479e-02, Val_Loss 6.0818e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [49] Train_Loss 6.3361e-02, Val_Loss 5.9483e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [50] Train_Loss 6.6034e-02, Val_Loss 5.9174e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [51] Train_Loss 6.0240e-02, Val_Loss 5.6901e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [52] Train_Loss 5.8710e-02, Val_Loss 5.5675e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [53] Train_Loss 5.7549e-02, Val_Loss 5.4471e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [54] Train_Loss 5.6462e-02, Val_Loss 5.3543e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [55] Train_Loss 5.9949e-02, Val_Loss 5.4026e-02\n",
            "Epoch [56] Train_Loss 5.4671e-02, Val_Loss 5.2313e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [57] Train_Loss 5.2563e-02, Val_Loss 5.0663e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [58] Train_Loss 5.0717e-02, Val_Loss 4.9446e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [59] Train_Loss 5.0417e-02, Val_Loss 4.8668e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [60] Train_Loss 5.4670e-02, Val_Loss 4.8506e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [61] Train_Loss 4.9856e-02, Val_Loss 4.7601e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [62] Train_Loss 4.8359e-02, Val_Loss 4.6959e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [63] Train_Loss 4.7068e-02, Val_Loss 4.5724e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [64] Train_Loss 4.5799e-02, Val_Loss 4.4418e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [65] Train_Loss 4.8865e-02, Val_Loss 4.4496e-02\n",
            "Epoch [66] Train_Loss 4.5051e-02, Val_Loss 4.3090e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [67] Train_Loss 4.3756e-02, Val_Loss 4.2190e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [68] Train_Loss 4.3011e-02, Val_Loss 4.1888e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [69] Train_Loss 4.2061e-02, Val_Loss 4.1287e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [70] Train_Loss 4.2988e-02, Val_Loss 4.0751e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [71] Train_Loss 4.1312e-02, Val_Loss 3.9994e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [72] Train_Loss 4.0675e-02, Val_Loss 3.9190e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [73] Train_Loss 4.0242e-02, Val_Loss 3.8534e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [74] Train_Loss 4.0150e-02, Val_Loss 3.7916e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [75] Train_Loss 4.0803e-02, Val_Loss 3.9037e-02\n",
            "Epoch [76] Train_Loss 4.0836e-02, Val_Loss 4.1926e-02\n",
            "Epoch [77] Train_Loss 4.0646e-02, Val_Loss 4.5514e-02\n",
            "Epoch [78] Train_Loss 3.8655e-02, Val_Loss 4.3071e-02\n",
            "Epoch [79] Train_Loss 3.6551e-02, Val_Loss 4.0241e-02\n",
            "Epoch [80] Train_Loss 3.5956e-02, Val_Loss 3.6278e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [81] Train_Loss 3.4836e-02, Val_Loss 3.5315e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [82] Train_Loss 3.3406e-02, Val_Loss 3.4323e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [83] Train_Loss 3.2559e-02, Val_Loss 3.3662e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [84] Train_Loss 3.2083e-02, Val_Loss 3.3099e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [85] Train_Loss 3.3467e-02, Val_Loss 3.2627e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [86] Train_Loss 3.1590e-02, Val_Loss 3.2249e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [87] Train_Loss 3.1006e-02, Val_Loss 3.1851e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [88] Train_Loss 3.0572e-02, Val_Loss 3.1369e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [89] Train_Loss 3.0231e-02, Val_Loss 3.0998e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [90] Train_Loss 3.1417e-02, Val_Loss 3.1198e-02\n",
            "Epoch [91] Train_Loss 2.9606e-02, Val_Loss 3.0050e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [92] Train_Loss 2.9062e-02, Val_Loss 2.9452e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [93] Train_Loss 2.8703e-02, Val_Loss 2.8963e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [94] Train_Loss 2.8247e-02, Val_Loss 2.8552e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [95] Train_Loss 2.9891e-02, Val_Loss 2.8936e-02\n",
            "Epoch [96] Train_Loss 2.7936e-02, Val_Loss 2.8126e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [97] Train_Loss 2.7434e-02, Val_Loss 2.7677e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [98] Train_Loss 2.6991e-02, Val_Loss 2.7458e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [99] Train_Loss 2.6679e-02, Val_Loss 2.7102e-02\n",
            "Saving Model\n",
            "\n",
            "<All keys matched successfully>\n",
            "-----------------------------------------------\n",
            "ID_01: AUC = 0.7912, PAUC = 0.6757, F1 = 0.5833\n",
            "ID_02: AUC = 0.6693, PAUC = 0.5676, F1 = 0.5069\n",
            "ID_03: AUC = 0.6115, PAUC = 0.5252, F1 = 0.4736\n",
            "-----------------------------------------------\n",
            "Avg:  AUC = 0.6907, PAUC = 0.5895, F1 = 0.5213\n",
            "-------------------------\n",
            "Training Model [ID = 01]\n",
            "-------------------------\n",
            "Epoch [0] Train_Loss 1.0407e+01, Val_Loss 4.2201e+00\n",
            "Saving Model\n",
            "\n",
            "Epoch [1] Train_Loss 3.1173e+00, Val_Loss 2.2100e+00\n",
            "Saving Model\n",
            "\n",
            "Epoch [2] Train_Loss 1.7343e+00, Val_Loss 1.4879e+00\n",
            "Saving Model\n",
            "\n",
            "Epoch [3] Train_Loss 1.3564e+00, Val_Loss 1.2732e+00\n",
            "Saving Model\n",
            "\n",
            "Epoch [4] Train_Loss 1.1833e+00, Val_Loss 1.1208e+00\n",
            "Saving Model\n",
            "\n",
            "Epoch [5] Train_Loss 2.6593e-01, Val_Loss 2.3322e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [6] Train_Loss 2.1741e-01, Val_Loss 2.0861e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [7] Train_Loss 1.9742e-01, Val_Loss 1.9111e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [8] Train_Loss 1.8119e-01, Val_Loss 1.6730e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [9] Train_Loss 1.6156e-01, Val_Loss 1.5207e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [10] Train_Loss 1.6409e-01, Val_Loss 1.6037e-01\n",
            "Epoch [11] Train_Loss 1.4683e-01, Val_Loss 1.3421e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [12] Train_Loss 1.3147e-01, Val_Loss 1.2543e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [13] Train_Loss 1.2168e-01, Val_Loss 1.2325e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [14] Train_Loss 1.1657e-01, Val_Loss 1.1601e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [15] Train_Loss 1.1681e-01, Val_Loss 1.0526e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [16] Train_Loss 1.0451e-01, Val_Loss 1.0671e-01\n",
            "Epoch [17] Train_Loss 9.8787e-02, Val_Loss 9.6937e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [18] Train_Loss 9.4342e-02, Val_Loss 9.7335e-02\n",
            "Epoch [19] Train_Loss 9.0257e-02, Val_Loss 9.0790e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [20] Train_Loss 9.8432e-02, Val_Loss 9.9382e-02\n",
            "Epoch [21] Train_Loss 9.0217e-02, Val_Loss 9.4585e-02\n",
            "Epoch [22] Train_Loss 8.6047e-02, Val_Loss 8.8944e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [23] Train_Loss 8.2340e-02, Val_Loss 7.1172e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [24] Train_Loss 7.6786e-02, Val_Loss 7.6506e-02\n",
            "Epoch [25] Train_Loss 7.9658e-02, Val_Loss 8.1232e-02\n",
            "Epoch [26] Train_Loss 7.4444e-02, Val_Loss 7.5903e-02\n",
            "Epoch [27] Train_Loss 7.0672e-02, Val_Loss 6.8226e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [28] Train_Loss 6.9951e-02, Val_Loss 6.9432e-02\n",
            "Epoch [29] Train_Loss 7.1945e-02, Val_Loss 7.1339e-02\n",
            "Epoch [30] Train_Loss 7.6813e-02, Val_Loss 6.2864e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [31] Train_Loss 6.4036e-02, Val_Loss 6.2937e-02\n",
            "Epoch [32] Train_Loss 6.1904e-02, Val_Loss 6.0297e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [33] Train_Loss 6.1038e-02, Val_Loss 5.7528e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [34] Train_Loss 5.8839e-02, Val_Loss 5.6154e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [35] Train_Loss 6.2534e-02, Val_Loss 5.4886e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [36] Train_Loss 5.8805e-02, Val_Loss 5.5117e-02\n",
            "Epoch [37] Train_Loss 5.5471e-02, Val_Loss 5.5230e-02\n",
            "Epoch [38] Train_Loss 5.4810e-02, Val_Loss 5.1461e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [39] Train_Loss 5.2702e-02, Val_Loss 5.0024e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [40] Train_Loss 5.5730e-02, Val_Loss 5.0958e-02\n",
            "Epoch [41] Train_Loss 4.9706e-02, Val_Loss 4.9518e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [42] Train_Loss 5.1624e-02, Val_Loss 4.9312e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [43] Train_Loss 5.2162e-02, Val_Loss 4.6827e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [44] Train_Loss 4.9893e-02, Val_Loss 4.2884e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [45] Train_Loss 5.0720e-02, Val_Loss 4.2697e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [46] Train_Loss 4.6265e-02, Val_Loss 4.1531e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [47] Train_Loss 4.3527e-02, Val_Loss 3.9923e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [48] Train_Loss 4.4048e-02, Val_Loss 4.3580e-02\n",
            "Epoch [49] Train_Loss 4.3653e-02, Val_Loss 3.8651e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [50] Train_Loss 4.4275e-02, Val_Loss 3.9767e-02\n",
            "Epoch [51] Train_Loss 4.1730e-02, Val_Loss 4.0338e-02\n",
            "Epoch [52] Train_Loss 4.0315e-02, Val_Loss 3.5365e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [53] Train_Loss 4.0827e-02, Val_Loss 3.6853e-02\n",
            "Epoch [54] Train_Loss 3.8643e-02, Val_Loss 3.8270e-02\n",
            "Epoch [55] Train_Loss 4.8225e-02, Val_Loss 3.6736e-02\n",
            "Epoch [56] Train_Loss 3.9650e-02, Val_Loss 3.5280e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [57] Train_Loss 3.7775e-02, Val_Loss 3.8737e-02\n",
            "Epoch [58] Train_Loss 3.7192e-02, Val_Loss 3.5831e-02\n",
            "Epoch [59] Train_Loss 3.5812e-02, Val_Loss 3.2017e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [60] Train_Loss 3.9080e-02, Val_Loss 3.3219e-02\n",
            "Epoch [61] Train_Loss 4.4393e-02, Val_Loss 3.9073e-02\n",
            "Epoch [62] Train_Loss 4.4438e-02, Val_Loss 3.6373e-02\n",
            "Epoch [63] Train_Loss 3.9876e-02, Val_Loss 3.8454e-02\n",
            "Epoch [64] Train_Loss 3.7808e-02, Val_Loss 4.0169e-02\n",
            "Epoch [65] Train_Loss 4.1860e-02, Val_Loss 4.1253e-02\n",
            "Epoch [66] Train_Loss 3.4526e-02, Val_Loss 3.0602e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [67] Train_Loss 3.3767e-02, Val_Loss 2.8896e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [68] Train_Loss 3.6103e-02, Val_Loss 3.2586e-02\n",
            "Epoch [69] Train_Loss 3.4673e-02, Val_Loss 3.2806e-02\n",
            "Epoch [70] Train_Loss 3.5631e-02, Val_Loss 3.4711e-02\n",
            "Epoch [71] Train_Loss 3.7256e-02, Val_Loss 4.0208e-02\n",
            "Epoch [72] Train_Loss 3.5560e-02, Val_Loss 4.0804e-02\n",
            "Epoch [73] Train_Loss 3.2678e-02, Val_Loss 4.6112e-02\n",
            "Epoch [74] Train_Loss 3.3300e-02, Val_Loss 3.0644e-02\n",
            "Epoch [75] Train_Loss 3.1807e-02, Val_Loss 3.0794e-02\n",
            "Epoch [76] Train_Loss 2.9783e-02, Val_Loss 2.8819e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [77] Train_Loss 2.7949e-02, Val_Loss 2.8785e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [78] Train_Loss 2.7977e-02, Val_Loss 3.1953e-02\n",
            "Epoch [79] Train_Loss 2.9466e-02, Val_Loss 2.9814e-02\n",
            "Epoch [80] Train_Loss 3.0052e-02, Val_Loss 2.7766e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [81] Train_Loss 2.9626e-02, Val_Loss 2.4137e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [82] Train_Loss 3.0552e-02, Val_Loss 2.3522e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [83] Train_Loss 3.0276e-02, Val_Loss 2.2640e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [84] Train_Loss 2.8413e-02, Val_Loss 2.3020e-02\n",
            "Epoch [85] Train_Loss 3.0361e-02, Val_Loss 2.3534e-02\n",
            "Epoch [86] Train_Loss 3.1692e-02, Val_Loss 2.7718e-02\n",
            "Epoch [87] Train_Loss 3.1169e-02, Val_Loss 2.3142e-02\n",
            "Epoch [88] Train_Loss 3.5275e-02, Val_Loss 2.6417e-02\n",
            "Epoch [89] Train_Loss 3.1877e-02, Val_Loss 2.3789e-02\n",
            "Epoch [90] Train_Loss 3.1048e-02, Val_Loss 2.8089e-02\n",
            "Epoch [91] Train_Loss 2.6380e-02, Val_Loss 1.9488e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [92] Train_Loss 2.5624e-02, Val_Loss 2.3349e-02\n",
            "Epoch [93] Train_Loss 2.3911e-02, Val_Loss 1.8924e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [94] Train_Loss 2.2111e-02, Val_Loss 1.8812e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [95] Train_Loss 2.1918e-02, Val_Loss 1.7593e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [96] Train_Loss 2.3535e-02, Val_Loss 2.2207e-02\n",
            "Epoch [97] Train_Loss 2.7000e-02, Val_Loss 3.7438e-02\n",
            "Epoch [98] Train_Loss 2.5194e-02, Val_Loss 1.8258e-02\n",
            "Epoch [99] Train_Loss 2.1148e-02, Val_Loss 1.8763e-02\n",
            "<All keys matched successfully>\n",
            "-------------------------\n",
            "Training Model [ID = 02]\n",
            "-------------------------\n",
            "Epoch [0] Train_Loss 6.3945e+00, Val_Loss 2.3248e+00\n",
            "Saving Model\n",
            "\n",
            "Epoch [1] Train_Loss 1.2733e+00, Val_Loss 6.6948e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [2] Train_Loss 5.0112e-01, Val_Loss 3.8850e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [3] Train_Loss 3.6277e-01, Val_Loss 3.1813e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [4] Train_Loss 3.0620e-01, Val_Loss 2.6928e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [5] Train_Loss 2.7112e-01, Val_Loss 2.3033e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [6] Train_Loss 2.2647e-01, Val_Loss 2.0553e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [7] Train_Loss 2.0696e-01, Val_Loss 1.9109e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [8] Train_Loss 1.8889e-01, Val_Loss 1.7894e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [9] Train_Loss 1.7458e-01, Val_Loss 1.7156e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [10] Train_Loss 1.7370e-01, Val_Loss 1.5739e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [11] Train_Loss 1.5415e-01, Val_Loss 1.4643e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [12] Train_Loss 1.4399e-01, Val_Loss 1.3681e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [13] Train_Loss 1.3646e-01, Val_Loss 1.2930e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [14] Train_Loss 1.2828e-01, Val_Loss 1.2519e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [15] Train_Loss 1.2109e-01, Val_Loss 1.1122e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [16] Train_Loss 1.1025e-01, Val_Loss 1.0728e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [17] Train_Loss 1.0599e-01, Val_Loss 1.0066e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [18] Train_Loss 1.0106e-01, Val_Loss 9.4866e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [19] Train_Loss 9.7219e-02, Val_Loss 9.1405e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [20] Train_Loss 1.0752e-01, Val_Loss 9.0358e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [21] Train_Loss 9.6073e-02, Val_Loss 8.4962e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [22] Train_Loss 9.7746e-02, Val_Loss 8.1165e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [23] Train_Loss 8.4721e-02, Val_Loss 7.9167e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [24] Train_Loss 7.9088e-02, Val_Loss 7.7878e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [25] Train_Loss 8.1162e-02, Val_Loss 7.2533e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [26] Train_Loss 7.6797e-02, Val_Loss 6.8645e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [27] Train_Loss 7.6219e-02, Val_Loss 6.8622e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [28] Train_Loss 7.5872e-02, Val_Loss 6.4880e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [29] Train_Loss 6.7599e-02, Val_Loss 6.8744e-02\n",
            "Epoch [30] Train_Loss 7.0358e-02, Val_Loss 6.3037e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [31] Train_Loss 6.6344e-02, Val_Loss 6.1008e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [32] Train_Loss 6.3557e-02, Val_Loss 5.9857e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [33] Train_Loss 6.4583e-02, Val_Loss 6.5301e-02\n",
            "Epoch [34] Train_Loss 6.0455e-02, Val_Loss 7.4195e-02\n",
            "Epoch [35] Train_Loss 5.9541e-02, Val_Loss 5.6821e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [36] Train_Loss 5.2769e-02, Val_Loss 5.2385e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [37] Train_Loss 5.0726e-02, Val_Loss 4.9800e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [38] Train_Loss 4.8715e-02, Val_Loss 4.8089e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [39] Train_Loss 4.7927e-02, Val_Loss 4.8056e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [40] Train_Loss 4.9792e-02, Val_Loss 4.8655e-02\n",
            "Epoch [41] Train_Loss 4.6932e-02, Val_Loss 4.4460e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [42] Train_Loss 4.6124e-02, Val_Loss 4.4825e-02\n",
            "Epoch [43] Train_Loss 4.4000e-02, Val_Loss 4.5046e-02\n",
            "Epoch [44] Train_Loss 4.2464e-02, Val_Loss 4.3700e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [45] Train_Loss 4.3719e-02, Val_Loss 4.1777e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [46] Train_Loss 4.1934e-02, Val_Loss 4.0949e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [47] Train_Loss 3.9595e-02, Val_Loss 4.0695e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [48] Train_Loss 3.8647e-02, Val_Loss 3.8114e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [49] Train_Loss 3.6474e-02, Val_Loss 3.6074e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [50] Train_Loss 3.8844e-02, Val_Loss 4.3954e-02\n",
            "Epoch [51] Train_Loss 3.8044e-02, Val_Loss 3.9576e-02\n",
            "Epoch [52] Train_Loss 3.9028e-02, Val_Loss 3.8166e-02\n",
            "Epoch [53] Train_Loss 3.7445e-02, Val_Loss 3.8512e-02\n",
            "Epoch [54] Train_Loss 3.7929e-02, Val_Loss 3.5205e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [55] Train_Loss 3.6500e-02, Val_Loss 3.8044e-02\n",
            "Epoch [56] Train_Loss 4.0740e-02, Val_Loss 3.2252e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [57] Train_Loss 4.6877e-02, Val_Loss 3.4548e-02\n",
            "Epoch [58] Train_Loss 3.8427e-02, Val_Loss 4.1498e-02\n",
            "Epoch [59] Train_Loss 4.0267e-02, Val_Loss 4.1799e-02\n",
            "Epoch [60] Train_Loss 3.6285e-02, Val_Loss 3.6387e-02\n",
            "Epoch [61] Train_Loss 3.9434e-02, Val_Loss 3.7419e-02\n",
            "Epoch [62] Train_Loss 3.6388e-02, Val_Loss 3.2596e-02\n",
            "Epoch [63] Train_Loss 3.7806e-02, Val_Loss 2.9305e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [64] Train_Loss 2.9890e-02, Val_Loss 3.3241e-02\n",
            "Epoch [65] Train_Loss 3.0344e-02, Val_Loss 3.5470e-02\n",
            "Epoch [66] Train_Loss 3.1127e-02, Val_Loss 3.4124e-02\n",
            "Epoch [67] Train_Loss 3.3334e-02, Val_Loss 3.1091e-02\n",
            "Epoch [68] Train_Loss 3.1291e-02, Val_Loss 3.1840e-02\n",
            "Epoch [69] Train_Loss 2.9630e-02, Val_Loss 2.7630e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [70] Train_Loss 2.8089e-02, Val_Loss 2.6489e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [71] Train_Loss 2.6236e-02, Val_Loss 2.5699e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [72] Train_Loss 2.5472e-02, Val_Loss 2.4315e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [73] Train_Loss 2.5251e-02, Val_Loss 2.6392e-02\n",
            "Epoch [74] Train_Loss 2.4837e-02, Val_Loss 2.4481e-02\n",
            "Epoch [75] Train_Loss 2.4923e-02, Val_Loss 2.6262e-02\n",
            "Epoch [76] Train_Loss 2.3443e-02, Val_Loss 2.5692e-02\n",
            "Epoch [77] Train_Loss 2.3032e-02, Val_Loss 2.5232e-02\n",
            "Epoch [78] Train_Loss 2.4195e-02, Val_Loss 2.9980e-02\n",
            "Epoch [79] Train_Loss 2.3629e-02, Val_Loss 2.7119e-02\n",
            "Epoch [80] Train_Loss 2.6346e-02, Val_Loss 2.2094e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [81] Train_Loss 2.2456e-02, Val_Loss 2.6736e-02\n",
            "Epoch [82] Train_Loss 2.1007e-02, Val_Loss 2.6660e-02\n",
            "Epoch [83] Train_Loss 2.1550e-02, Val_Loss 1.9951e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [84] Train_Loss 2.0104e-02, Val_Loss 2.7082e-02\n",
            "Epoch [85] Train_Loss 2.1735e-02, Val_Loss 2.5555e-02\n",
            "Epoch [86] Train_Loss 1.9588e-02, Val_Loss 2.9074e-02\n",
            "Epoch [87] Train_Loss 2.0706e-02, Val_Loss 2.0211e-02\n",
            "Epoch [88] Train_Loss 1.9073e-02, Val_Loss 4.3702e-02\n",
            "Epoch [89] Train_Loss 2.8768e-02, Val_Loss 3.7641e-02\n",
            "Epoch [90] Train_Loss 3.1821e-02, Val_Loss 2.5407e-02\n",
            "Epoch [91] Train_Loss 2.3210e-02, Val_Loss 2.0487e-02\n",
            "Epoch [92] Train_Loss 2.0404e-02, Val_Loss 1.9422e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [93] Train_Loss 1.9327e-02, Val_Loss 2.0807e-02\n",
            "Epoch [94] Train_Loss 1.8798e-02, Val_Loss 1.9517e-02\n",
            "Epoch [95] Train_Loss 2.1401e-02, Val_Loss 2.3297e-02\n",
            "Epoch [96] Train_Loss 1.9061e-02, Val_Loss 2.0899e-02\n",
            "Epoch [97] Train_Loss 1.7966e-02, Val_Loss 1.6772e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [98] Train_Loss 1.7883e-02, Val_Loss 1.7613e-02\n",
            "Epoch [99] Train_Loss 2.0381e-02, Val_Loss 1.6500e-02\n",
            "Saving Model\n",
            "\n",
            "<All keys matched successfully>\n",
            "-------------------------\n",
            "Training Model [ID = 03]\n",
            "-------------------------\n",
            "Epoch [0] Train_Loss 5.0436e+00, Val_Loss 1.6515e+00\n",
            "Saving Model\n",
            "\n",
            "Epoch [1] Train_Loss 1.0359e+00, Val_Loss 6.3698e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [2] Train_Loss 5.5352e-01, Val_Loss 4.5455e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [3] Train_Loss 4.1308e-01, Val_Loss 3.6149e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [4] Train_Loss 3.3726e-01, Val_Loss 3.0911e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [5] Train_Loss 3.2389e-01, Val_Loss 2.9701e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [6] Train_Loss 2.6533e-01, Val_Loss 2.5847e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [7] Train_Loss 2.3560e-01, Val_Loss 2.2011e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [8] Train_Loss 2.1340e-01, Val_Loss 1.9473e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [9] Train_Loss 1.9502e-01, Val_Loss 1.8837e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [10] Train_Loss 1.9092e-01, Val_Loss 1.8584e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [11] Train_Loss 1.7271e-01, Val_Loss 1.5334e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [12] Train_Loss 1.5452e-01, Val_Loss 1.3725e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [13] Train_Loss 1.4636e-01, Val_Loss 1.4558e-01\n",
            "Epoch [14] Train_Loss 1.4119e-01, Val_Loss 1.2709e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [15] Train_Loss 1.4029e-01, Val_Loss 1.3301e-01\n",
            "Epoch [16] Train_Loss 1.2413e-01, Val_Loss 1.1334e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [17] Train_Loss 1.1589e-01, Val_Loss 1.1876e-01\n",
            "Epoch [18] Train_Loss 1.1200e-01, Val_Loss 1.1728e-01\n",
            "Epoch [19] Train_Loss 1.0801e-01, Val_Loss 1.0166e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [20] Train_Loss 1.0743e-01, Val_Loss 1.0337e-01\n",
            "Epoch [21] Train_Loss 9.9547e-02, Val_Loss 9.3548e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [22] Train_Loss 9.0229e-02, Val_Loss 8.3983e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [23] Train_Loss 8.7254e-02, Val_Loss 8.0851e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [24] Train_Loss 8.2064e-02, Val_Loss 7.8475e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [25] Train_Loss 8.5288e-02, Val_Loss 7.7831e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [26] Train_Loss 7.8884e-02, Val_Loss 7.5434e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [27] Train_Loss 7.6009e-02, Val_Loss 7.0582e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [28] Train_Loss 7.4810e-02, Val_Loss 6.9246e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [29] Train_Loss 7.0632e-02, Val_Loss 6.8127e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [30] Train_Loss 7.4747e-02, Val_Loss 7.0379e-02\n",
            "Epoch [31] Train_Loss 7.3903e-02, Val_Loss 7.1295e-02\n",
            "Epoch [32] Train_Loss 6.9613e-02, Val_Loss 6.5133e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [33] Train_Loss 6.7999e-02, Val_Loss 6.6149e-02\n",
            "Epoch [34] Train_Loss 6.5835e-02, Val_Loss 6.6405e-02\n",
            "Epoch [35] Train_Loss 6.6310e-02, Val_Loss 6.0344e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [36] Train_Loss 6.1786e-02, Val_Loss 5.6542e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [37] Train_Loss 6.0546e-02, Val_Loss 6.2329e-02\n",
            "Epoch [38] Train_Loss 5.8244e-02, Val_Loss 6.6122e-02\n",
            "Epoch [39] Train_Loss 5.7980e-02, Val_Loss 7.1528e-02\n",
            "Epoch [40] Train_Loss 6.1117e-02, Val_Loss 6.1443e-02\n",
            "Epoch [41] Train_Loss 8.2364e-02, Val_Loss 6.3068e-02\n",
            "Epoch [42] Train_Loss 6.0531e-02, Val_Loss 6.0157e-02\n",
            "Epoch [43] Train_Loss 5.8458e-02, Val_Loss 5.1471e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [44] Train_Loss 5.3291e-02, Val_Loss 4.6866e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [45] Train_Loss 5.0850e-02, Val_Loss 4.2931e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [46] Train_Loss 4.6649e-02, Val_Loss 4.3131e-02\n",
            "Epoch [47] Train_Loss 4.4879e-02, Val_Loss 4.2008e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [48] Train_Loss 4.1985e-02, Val_Loss 4.0150e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [49] Train_Loss 4.4864e-02, Val_Loss 4.1021e-02\n",
            "Epoch [50] Train_Loss 5.0510e-02, Val_Loss 4.5131e-02\n",
            "Epoch [51] Train_Loss 4.6571e-02, Val_Loss 3.6224e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [52] Train_Loss 4.7968e-02, Val_Loss 5.5959e-02\n",
            "Epoch [53] Train_Loss 5.2936e-02, Val_Loss 5.1789e-02\n",
            "Epoch [54] Train_Loss 4.9879e-02, Val_Loss 3.8956e-02\n",
            "Epoch [55] Train_Loss 4.1852e-02, Val_Loss 3.4513e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [56] Train_Loss 4.0210e-02, Val_Loss 3.7339e-02\n",
            "Epoch [57] Train_Loss 3.8988e-02, Val_Loss 3.7962e-02\n",
            "Epoch [58] Train_Loss 4.2172e-02, Val_Loss 3.5623e-02\n",
            "Epoch [59] Train_Loss 4.0996e-02, Val_Loss 4.7294e-02\n",
            "Epoch [60] Train_Loss 5.5728e-02, Val_Loss 5.9828e-02\n",
            "Epoch [61] Train_Loss 4.8856e-02, Val_Loss 3.4378e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [62] Train_Loss 3.7402e-02, Val_Loss 3.3877e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [63] Train_Loss 3.8112e-02, Val_Loss 3.7837e-02\n",
            "Epoch [64] Train_Loss 3.8372e-02, Val_Loss 4.2079e-02\n",
            "Epoch [65] Train_Loss 3.7730e-02, Val_Loss 4.4937e-02\n",
            "Epoch [66] Train_Loss 3.7769e-02, Val_Loss 3.6335e-02\n",
            "Epoch [67] Train_Loss 3.5063e-02, Val_Loss 2.9419e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [68] Train_Loss 3.4185e-02, Val_Loss 3.0253e-02\n",
            "Epoch [69] Train_Loss 3.4159e-02, Val_Loss 3.3945e-02\n",
            "Epoch [70] Train_Loss 3.2516e-02, Val_Loss 3.0562e-02\n",
            "Epoch [71] Train_Loss 2.7819e-02, Val_Loss 3.0463e-02\n",
            "Epoch [72] Train_Loss 2.8112e-02, Val_Loss 3.0118e-02\n",
            "Epoch [73] Train_Loss 2.9511e-02, Val_Loss 2.5898e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [74] Train_Loss 3.4328e-02, Val_Loss 2.8822e-02\n",
            "Epoch [75] Train_Loss 2.7039e-02, Val_Loss 2.5480e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [76] Train_Loss 2.6347e-02, Val_Loss 2.5497e-02\n",
            "Epoch [77] Train_Loss 2.8756e-02, Val_Loss 4.1073e-02\n",
            "Epoch [78] Train_Loss 3.7876e-02, Val_Loss 2.8080e-02\n",
            "Epoch [79] Train_Loss 3.1830e-02, Val_Loss 2.9812e-02\n",
            "Epoch [80] Train_Loss 2.9936e-02, Val_Loss 2.4170e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [81] Train_Loss 2.6654e-02, Val_Loss 2.4418e-02\n",
            "Epoch [82] Train_Loss 2.5033e-02, Val_Loss 2.3763e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [83] Train_Loss 2.6655e-02, Val_Loss 3.1547e-02\n",
            "Epoch [84] Train_Loss 3.5943e-02, Val_Loss 2.7422e-02\n",
            "Epoch [85] Train_Loss 3.0382e-02, Val_Loss 2.3566e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [86] Train_Loss 2.9477e-02, Val_Loss 2.5547e-02\n",
            "Epoch [87] Train_Loss 2.6694e-02, Val_Loss 2.6162e-02\n",
            "Epoch [88] Train_Loss 2.3585e-02, Val_Loss 2.6159e-02\n",
            "Epoch [89] Train_Loss 2.1657e-02, Val_Loss 2.3156e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [90] Train_Loss 2.5098e-02, Val_Loss 2.1703e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [91] Train_Loss 2.5380e-02, Val_Loss 2.6437e-02\n",
            "Epoch [92] Train_Loss 2.1937e-02, Val_Loss 2.0100e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [93] Train_Loss 2.1110e-02, Val_Loss 1.9823e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [94] Train_Loss 2.0316e-02, Val_Loss 2.3405e-02\n",
            "Epoch [95] Train_Loss 2.4048e-02, Val_Loss 2.3316e-02\n",
            "Epoch [96] Train_Loss 2.0020e-02, Val_Loss 2.2152e-02\n",
            "Epoch [97] Train_Loss 2.0414e-02, Val_Loss 2.2318e-02\n",
            "Epoch [98] Train_Loss 2.0083e-02, Val_Loss 1.7691e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [99] Train_Loss 2.0194e-02, Val_Loss 1.7814e-02\n",
            "<All keys matched successfully>\n",
            "-----------------------------------------------\n",
            "ID_01: AUC = 0.8288, PAUC = 0.7115, F1 = 0.6189\n",
            "ID_02: AUC = 0.6053, PAUC = 0.5232, F1 = 0.4557\n",
            "ID_03: AUC = 0.6471, PAUC = 0.5616, F1 = 0.4932\n",
            "-----------------------------------------------\n",
            "Avg:  AUC = 0.6937, PAUC = 0.5988, F1 = 0.5226\n",
            "-------------------------\n",
            "Training Model [ID = 01]\n",
            "-------------------------\n",
            "Epoch [0] Train_Loss 4.9033e+00, Val_Loss 2.3615e+00\n",
            "Saving Model\n",
            "\n",
            "Epoch [1] Train_Loss 1.7895e+00, Val_Loss 1.1840e+00\n",
            "Saving Model\n",
            "\n",
            "Epoch [2] Train_Loss 7.4702e-01, Val_Loss 4.5423e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [3] Train_Loss 3.5525e-01, Val_Loss 2.9396e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [4] Train_Loss 2.5318e-01, Val_Loss 2.2222e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [5] Train_Loss 2.2690e-01, Val_Loss 1.9821e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [6] Train_Loss 1.8296e-01, Val_Loss 1.7571e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [7] Train_Loss 1.6384e-01, Val_Loss 1.6133e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [8] Train_Loss 1.5588e-01, Val_Loss 1.4668e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [9] Train_Loss 1.4076e-01, Val_Loss 1.3305e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [10] Train_Loss 1.3103e-01, Val_Loss 1.1820e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [11] Train_Loss 1.1194e-01, Val_Loss 1.0702e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [12] Train_Loss 1.0262e-01, Val_Loss 1.0062e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [13] Train_Loss 1.0022e-01, Val_Loss 9.8434e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [14] Train_Loss 9.1402e-02, Val_Loss 9.4863e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [15] Train_Loss 1.0113e-01, Val_Loss 9.1322e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [16] Train_Loss 8.8026e-02, Val_Loss 8.8138e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [17] Train_Loss 8.2149e-02, Val_Loss 8.3845e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [18] Train_Loss 8.1167e-02, Val_Loss 8.1025e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [19] Train_Loss 7.9169e-02, Val_Loss 7.5149e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [20] Train_Loss 8.3696e-02, Val_Loss 7.9241e-02\n",
            "Epoch [21] Train_Loss 7.6670e-02, Val_Loss 7.4406e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [22] Train_Loss 7.1538e-02, Val_Loss 7.7613e-02\n",
            "Epoch [23] Train_Loss 6.9175e-02, Val_Loss 7.5218e-02\n",
            "Epoch [24] Train_Loss 6.6184e-02, Val_Loss 6.7073e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [25] Train_Loss 6.6011e-02, Val_Loss 6.9282e-02\n",
            "Epoch [26] Train_Loss 5.9331e-02, Val_Loss 5.7750e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [27] Train_Loss 5.7222e-02, Val_Loss 5.6402e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [28] Train_Loss 5.5355e-02, Val_Loss 5.6643e-02\n",
            "Epoch [29] Train_Loss 5.7509e-02, Val_Loss 5.8009e-02\n",
            "Epoch [30] Train_Loss 5.5986e-02, Val_Loss 5.4418e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [31] Train_Loss 5.3544e-02, Val_Loss 5.0507e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [32] Train_Loss 5.1518e-02, Val_Loss 5.0992e-02\n",
            "Epoch [33] Train_Loss 5.2777e-02, Val_Loss 5.0667e-02\n",
            "Epoch [34] Train_Loss 5.1581e-02, Val_Loss 4.6534e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [35] Train_Loss 4.9557e-02, Val_Loss 4.9028e-02\n",
            "Epoch [36] Train_Loss 4.5021e-02, Val_Loss 4.3853e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [37] Train_Loss 4.3263e-02, Val_Loss 4.5580e-02\n",
            "Epoch [38] Train_Loss 4.2999e-02, Val_Loss 4.3928e-02\n",
            "Epoch [39] Train_Loss 4.1187e-02, Val_Loss 4.1927e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [40] Train_Loss 4.5736e-02, Val_Loss 4.9957e-02\n",
            "Epoch [41] Train_Loss 4.5253e-02, Val_Loss 4.1903e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [42] Train_Loss 4.0827e-02, Val_Loss 4.1403e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [43] Train_Loss 3.7886e-02, Val_Loss 4.3804e-02\n",
            "Epoch [44] Train_Loss 3.9649e-02, Val_Loss 3.6490e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [45] Train_Loss 3.9426e-02, Val_Loss 3.7228e-02\n",
            "Epoch [46] Train_Loss 3.5922e-02, Val_Loss 4.0142e-02\n",
            "Epoch [47] Train_Loss 4.5001e-02, Val_Loss 5.9598e-02\n",
            "Epoch [48] Train_Loss 3.7825e-02, Val_Loss 4.5359e-02\n",
            "Epoch [49] Train_Loss 4.1824e-02, Val_Loss 3.4668e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [50] Train_Loss 3.9640e-02, Val_Loss 4.1022e-02\n",
            "Epoch [51] Train_Loss 4.3741e-02, Val_Loss 4.4792e-02\n",
            "Epoch [52] Train_Loss 3.9873e-02, Val_Loss 4.5385e-02\n",
            "Epoch [53] Train_Loss 3.4186e-02, Val_Loss 3.4307e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [54] Train_Loss 3.2523e-02, Val_Loss 3.6353e-02\n",
            "Epoch [55] Train_Loss 3.5841e-02, Val_Loss 3.7423e-02\n",
            "Epoch [56] Train_Loss 3.2916e-02, Val_Loss 3.3765e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [57] Train_Loss 3.4902e-02, Val_Loss 3.6621e-02\n",
            "Epoch [58] Train_Loss 3.4042e-02, Val_Loss 4.3664e-02\n",
            "Epoch [59] Train_Loss 3.5841e-02, Val_Loss 4.2361e-02\n",
            "Epoch [60] Train_Loss 3.5650e-02, Val_Loss 3.5050e-02\n",
            "Epoch [61] Train_Loss 3.1955e-02, Val_Loss 2.8962e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [62] Train_Loss 3.0571e-02, Val_Loss 2.8252e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [63] Train_Loss 3.0520e-02, Val_Loss 2.8806e-02\n",
            "Epoch [64] Train_Loss 2.7336e-02, Val_Loss 2.9531e-02\n",
            "Epoch [65] Train_Loss 2.9097e-02, Val_Loss 2.8198e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [66] Train_Loss 2.8414e-02, Val_Loss 2.6484e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [67] Train_Loss 3.2216e-02, Val_Loss 2.9277e-02\n",
            "Epoch [68] Train_Loss 3.1309e-02, Val_Loss 3.0017e-02\n",
            "Epoch [69] Train_Loss 3.2370e-02, Val_Loss 3.3026e-02\n",
            "Epoch [70] Train_Loss 3.9957e-02, Val_Loss 2.8597e-02\n",
            "Epoch [71] Train_Loss 3.9792e-02, Val_Loss 3.0234e-02\n",
            "Epoch [72] Train_Loss 2.5546e-02, Val_Loss 2.5263e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [73] Train_Loss 2.3889e-02, Val_Loss 2.9041e-02\n",
            "Epoch [74] Train_Loss 2.7336e-02, Val_Loss 2.4234e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [75] Train_Loss 2.6746e-02, Val_Loss 2.4671e-02\n",
            "Epoch [76] Train_Loss 2.4413e-02, Val_Loss 2.9442e-02\n",
            "Epoch [77] Train_Loss 2.7786e-02, Val_Loss 2.3763e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [78] Train_Loss 2.3986e-02, Val_Loss 2.1597e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [79] Train_Loss 2.2489e-02, Val_Loss 2.4106e-02\n",
            "Epoch [80] Train_Loss 2.2849e-02, Val_Loss 1.9762e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [81] Train_Loss 2.0075e-02, Val_Loss 2.3728e-02\n",
            "Epoch [82] Train_Loss 2.0690e-02, Val_Loss 2.1341e-02\n",
            "Epoch [83] Train_Loss 2.0635e-02, Val_Loss 1.9493e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [84] Train_Loss 1.8487e-02, Val_Loss 2.5236e-02\n",
            "Epoch [85] Train_Loss 2.0365e-02, Val_Loss 1.8211e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [86] Train_Loss 1.8993e-02, Val_Loss 1.9198e-02\n",
            "Epoch [87] Train_Loss 1.8228e-02, Val_Loss 1.8070e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [88] Train_Loss 1.7670e-02, Val_Loss 1.7631e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [89] Train_Loss 1.7179e-02, Val_Loss 2.3045e-02\n",
            "Epoch [90] Train_Loss 1.7985e-02, Val_Loss 1.7882e-02\n",
            "Epoch [91] Train_Loss 1.6840e-02, Val_Loss 1.7378e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [92] Train_Loss 1.6908e-02, Val_Loss 2.0829e-02\n",
            "Epoch [93] Train_Loss 1.7607e-02, Val_Loss 1.7070e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [94] Train_Loss 1.7484e-02, Val_Loss 2.3134e-02\n",
            "Epoch [95] Train_Loss 2.2094e-02, Val_Loss 2.6580e-02\n",
            "Epoch [96] Train_Loss 2.0998e-02, Val_Loss 2.0163e-02\n",
            "Epoch [97] Train_Loss 1.8428e-02, Val_Loss 2.0636e-02\n",
            "Epoch [98] Train_Loss 1.7744e-02, Val_Loss 1.6547e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [99] Train_Loss 2.0962e-02, Val_Loss 2.0939e-02\n",
            "<All keys matched successfully>\n",
            "-------------------------\n",
            "Training Model [ID = 02]\n",
            "-------------------------\n",
            "Epoch [0] Train_Loss 5.9255e+00, Val_Loss 2.7967e+00\n",
            "Saving Model\n",
            "\n",
            "Epoch [1] Train_Loss 1.7496e+00, Val_Loss 1.0981e+00\n",
            "Saving Model\n",
            "\n",
            "Epoch [2] Train_Loss 7.9377e-01, Val_Loss 6.5583e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [3] Train_Loss 5.3949e-01, Val_Loss 4.8948e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [4] Train_Loss 4.1884e-01, Val_Loss 3.9612e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [5] Train_Loss 4.0258e-01, Val_Loss 3.6739e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [6] Train_Loss 3.3213e-01, Val_Loss 3.1280e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [7] Train_Loss 3.0227e-01, Val_Loss 2.9416e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [8] Train_Loss 2.6571e-01, Val_Loss 2.5846e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [9] Train_Loss 2.3199e-01, Val_Loss 2.2820e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [10] Train_Loss 2.2686e-01, Val_Loss 2.1555e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [11] Train_Loss 1.9759e-01, Val_Loss 2.0313e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [12] Train_Loss 1.8223e-01, Val_Loss 1.8805e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [13] Train_Loss 1.6953e-01, Val_Loss 1.7623e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [14] Train_Loss 1.5816e-01, Val_Loss 1.6430e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [15] Train_Loss 1.6042e-01, Val_Loss 1.5333e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [16] Train_Loss 1.3686e-01, Val_Loss 1.4197e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [17] Train_Loss 1.3066e-01, Val_Loss 1.3308e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [18] Train_Loss 1.2263e-01, Val_Loss 1.2666e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [19] Train_Loss 1.1582e-01, Val_Loss 1.1997e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [20] Train_Loss 1.1938e-01, Val_Loss 1.1848e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [21] Train_Loss 1.0711e-01, Val_Loss 1.0941e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [22] Train_Loss 1.0338e-01, Val_Loss 1.0439e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [23] Train_Loss 9.8944e-02, Val_Loss 9.9928e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [24] Train_Loss 9.5296e-02, Val_Loss 9.5676e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [25] Train_Loss 9.8327e-02, Val_Loss 9.4752e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [26] Train_Loss 9.1689e-02, Val_Loss 9.0514e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [27] Train_Loss 8.8904e-02, Val_Loss 8.9763e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [28] Train_Loss 8.7044e-02, Val_Loss 8.8913e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [29] Train_Loss 8.1386e-02, Val_Loss 8.0690e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [30] Train_Loss 8.6260e-02, Val_Loss 8.3489e-02\n",
            "Epoch [31] Train_Loss 7.9225e-02, Val_Loss 8.1074e-02\n",
            "Epoch [32] Train_Loss 7.5854e-02, Val_Loss 7.5353e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [33] Train_Loss 7.2067e-02, Val_Loss 7.4725e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [34] Train_Loss 6.9377e-02, Val_Loss 7.8386e-02\n",
            "Epoch [35] Train_Loss 7.2288e-02, Val_Loss 8.0404e-02\n",
            "Epoch [36] Train_Loss 7.2063e-02, Val_Loss 7.0590e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [37] Train_Loss 6.7752e-02, Val_Loss 6.5956e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [38] Train_Loss 6.5156e-02, Val_Loss 6.4144e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [39] Train_Loss 6.3033e-02, Val_Loss 6.3354e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [40] Train_Loss 6.6820e-02, Val_Loss 7.2023e-02\n",
            "Epoch [41] Train_Loss 5.7992e-02, Val_Loss 5.8994e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [42] Train_Loss 5.4380e-02, Val_Loss 5.6461e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [43] Train_Loss 5.2319e-02, Val_Loss 5.4612e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [44] Train_Loss 5.0683e-02, Val_Loss 5.3338e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [45] Train_Loss 5.4720e-02, Val_Loss 6.1206e-02\n",
            "Epoch [46] Train_Loss 4.8655e-02, Val_Loss 5.2049e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [47] Train_Loss 4.5417e-02, Val_Loss 4.9289e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [48] Train_Loss 4.3887e-02, Val_Loss 4.6842e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [49] Train_Loss 4.3310e-02, Val_Loss 4.6771e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [50] Train_Loss 4.5494e-02, Val_Loss 4.5668e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [51] Train_Loss 4.1472e-02, Val_Loss 4.5216e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [52] Train_Loss 3.9628e-02, Val_Loss 4.2572e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [53] Train_Loss 3.8763e-02, Val_Loss 4.1726e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [54] Train_Loss 3.7994e-02, Val_Loss 4.1103e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [55] Train_Loss 3.9288e-02, Val_Loss 4.0853e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [56] Train_Loss 3.9807e-02, Val_Loss 4.0062e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [57] Train_Loss 3.6518e-02, Val_Loss 3.8270e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [58] Train_Loss 3.4407e-02, Val_Loss 3.7772e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [59] Train_Loss 3.3577e-02, Val_Loss 3.6870e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [60] Train_Loss 3.5163e-02, Val_Loss 3.8154e-02\n",
            "Epoch [61] Train_Loss 3.2199e-02, Val_Loss 3.6348e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [62] Train_Loss 3.1533e-02, Val_Loss 3.5126e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [63] Train_Loss 3.6969e-02, Val_Loss 3.6880e-02\n",
            "Epoch [64] Train_Loss 3.0860e-02, Val_Loss 3.4892e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [65] Train_Loss 3.1380e-02, Val_Loss 3.3468e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [66] Train_Loss 3.0407e-02, Val_Loss 3.2143e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [67] Train_Loss 3.0240e-02, Val_Loss 3.2007e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [68] Train_Loss 3.0370e-02, Val_Loss 3.8420e-02\n",
            "Epoch [69] Train_Loss 3.6948e-02, Val_Loss 4.3799e-02\n",
            "Epoch [70] Train_Loss 4.8158e-02, Val_Loss 1.0871e-01\n",
            "Epoch [71] Train_Loss 5.9869e-02, Val_Loss 3.5413e-02\n",
            "Epoch [72] Train_Loss 3.2541e-02, Val_Loss 3.0726e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [73] Train_Loss 3.2992e-02, Val_Loss 2.9621e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [74] Train_Loss 3.0367e-02, Val_Loss 3.1095e-02\n",
            "Epoch [75] Train_Loss 2.9044e-02, Val_Loss 2.8509e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [76] Train_Loss 2.6420e-02, Val_Loss 3.2915e-02\n",
            "Epoch [77] Train_Loss 2.5913e-02, Val_Loss 2.8921e-02\n",
            "Epoch [78] Train_Loss 2.5331e-02, Val_Loss 2.6993e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [79] Train_Loss 2.6164e-02, Val_Loss 2.6575e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [80] Train_Loss 2.7182e-02, Val_Loss 2.6333e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [81] Train_Loss 2.6062e-02, Val_Loss 2.5799e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [82] Train_Loss 2.4887e-02, Val_Loss 2.5413e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [83] Train_Loss 2.7311e-02, Val_Loss 2.5056e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [84] Train_Loss 3.0009e-02, Val_Loss 5.6947e-02\n",
            "Epoch [85] Train_Loss 2.8019e-02, Val_Loss 2.8474e-02\n",
            "Epoch [86] Train_Loss 2.2980e-02, Val_Loss 2.5182e-02\n",
            "Epoch [87] Train_Loss 2.1870e-02, Val_Loss 2.3383e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [88] Train_Loss 2.2039e-02, Val_Loss 2.4499e-02\n",
            "Epoch [89] Train_Loss 2.2854e-02, Val_Loss 2.2144e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [90] Train_Loss 2.3928e-02, Val_Loss 2.2374e-02\n",
            "Epoch [91] Train_Loss 2.4126e-02, Val_Loss 2.7720e-02\n",
            "Epoch [92] Train_Loss 3.2916e-02, Val_Loss 6.1470e-02\n",
            "Epoch [93] Train_Loss 2.6293e-02, Val_Loss 2.7659e-02\n",
            "Epoch [94] Train_Loss 2.1032e-02, Val_Loss 2.7377e-02\n",
            "Epoch [95] Train_Loss 2.2813e-02, Val_Loss 4.0986e-02\n",
            "Epoch [96] Train_Loss 2.2264e-02, Val_Loss 2.5161e-02\n",
            "Epoch [97] Train_Loss 1.9892e-02, Val_Loss 2.5463e-02\n",
            "Epoch [98] Train_Loss 1.8820e-02, Val_Loss 2.0990e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [99] Train_Loss 1.9486e-02, Val_Loss 2.3281e-02\n",
            "<All keys matched successfully>\n",
            "-------------------------\n",
            "Training Model [ID = 03]\n",
            "-------------------------\n",
            "Epoch [0] Train_Loss 7.9879e+00, Val_Loss 3.2695e+00\n",
            "Saving Model\n",
            "\n",
            "Epoch [1] Train_Loss 2.2029e+00, Val_Loss 1.1669e+00\n",
            "Saving Model\n",
            "\n",
            "Epoch [2] Train_Loss 6.9253e-01, Val_Loss 5.1932e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [3] Train_Loss 4.0534e-01, Val_Loss 4.0597e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [4] Train_Loss 3.0273e-01, Val_Loss 2.8728e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [5] Train_Loss 2.9536e-01, Val_Loss 2.6999e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [6] Train_Loss 2.3866e-01, Val_Loss 2.4157e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [7] Train_Loss 2.1051e-01, Val_Loss 2.1530e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [8] Train_Loss 1.8927e-01, Val_Loss 1.9807e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [9] Train_Loss 1.7506e-01, Val_Loss 1.8596e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [10] Train_Loss 1.7458e-01, Val_Loss 1.7657e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [11] Train_Loss 1.5603e-01, Val_Loss 1.6854e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [12] Train_Loss 1.4643e-01, Val_Loss 1.6339e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [13] Train_Loss 1.3854e-01, Val_Loss 1.5708e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [14] Train_Loss 1.3204e-01, Val_Loss 1.4530e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [15] Train_Loss 1.3506e-01, Val_Loss 1.3918e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [16] Train_Loss 1.2188e-01, Val_Loss 1.2819e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [17] Train_Loss 1.1406e-01, Val_Loss 1.1962e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [18] Train_Loss 1.1163e-01, Val_Loss 1.1484e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [19] Train_Loss 1.1108e-01, Val_Loss 1.1500e-01\n",
            "Epoch [20] Train_Loss 1.1501e-01, Val_Loss 1.2317e-01\n",
            "Epoch [21] Train_Loss 1.0953e-01, Val_Loss 1.1920e-01\n",
            "Epoch [22] Train_Loss 9.5332e-02, Val_Loss 1.0142e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [23] Train_Loss 9.0092e-02, Val_Loss 1.0094e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [24] Train_Loss 8.5420e-02, Val_Loss 9.3877e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [25] Train_Loss 8.8156e-02, Val_Loss 9.2830e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [26] Train_Loss 8.2213e-02, Val_Loss 8.9701e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [27] Train_Loss 8.1689e-02, Val_Loss 8.6748e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [28] Train_Loss 8.2452e-02, Val_Loss 9.0385e-02\n",
            "Epoch [29] Train_Loss 7.5921e-02, Val_Loss 9.9500e-02\n",
            "Epoch [30] Train_Loss 7.8432e-02, Val_Loss 8.2301e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [31] Train_Loss 6.9948e-02, Val_Loss 7.8807e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [32] Train_Loss 6.8402e-02, Val_Loss 7.8655e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [33] Train_Loss 6.8185e-02, Val_Loss 8.6729e-02\n",
            "Epoch [34] Train_Loss 6.6334e-02, Val_Loss 7.5780e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [35] Train_Loss 6.4856e-02, Val_Loss 7.4623e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [36] Train_Loss 6.1381e-02, Val_Loss 7.1802e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [37] Train_Loss 6.8753e-02, Val_Loss 7.1252e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [38] Train_Loss 7.0488e-02, Val_Loss 6.8799e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [39] Train_Loss 6.2148e-02, Val_Loss 6.7444e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [40] Train_Loss 6.3394e-02, Val_Loss 6.5060e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [41] Train_Loss 5.6833e-02, Val_Loss 6.4776e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [42] Train_Loss 5.6438e-02, Val_Loss 6.3795e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [43] Train_Loss 5.3923e-02, Val_Loss 5.8395e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [44] Train_Loss 5.1353e-02, Val_Loss 5.6501e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [45] Train_Loss 5.2119e-02, Val_Loss 5.6057e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [46] Train_Loss 5.0511e-02, Val_Loss 5.7240e-02\n",
            "Epoch [47] Train_Loss 5.4682e-02, Val_Loss 5.6497e-02\n",
            "Epoch [48] Train_Loss 4.8726e-02, Val_Loss 5.2279e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [49] Train_Loss 4.6241e-02, Val_Loss 5.3467e-02\n",
            "Epoch [50] Train_Loss 4.8289e-02, Val_Loss 5.3589e-02\n",
            "Epoch [51] Train_Loss 4.5222e-02, Val_Loss 5.3651e-02\n",
            "Epoch [52] Train_Loss 4.4884e-02, Val_Loss 5.4663e-02\n",
            "Epoch [53] Train_Loss 4.3680e-02, Val_Loss 5.4703e-02\n",
            "Epoch [54] Train_Loss 4.3212e-02, Val_Loss 5.6401e-02\n",
            "Epoch [55] Train_Loss 5.7862e-02, Val_Loss 5.7748e-02\n",
            "Epoch [56] Train_Loss 5.0368e-02, Val_Loss 5.1466e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [57] Train_Loss 4.8904e-02, Val_Loss 5.2709e-02\n",
            "Epoch [58] Train_Loss 5.1261e-02, Val_Loss 7.3729e-02\n",
            "Epoch [59] Train_Loss 5.7508e-02, Val_Loss 5.2143e-02\n",
            "Epoch [60] Train_Loss 5.7307e-02, Val_Loss 9.7683e-02\n",
            "Epoch [61] Train_Loss 6.0678e-02, Val_Loss 4.5677e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [62] Train_Loss 4.5011e-02, Val_Loss 4.8022e-02\n",
            "Epoch [63] Train_Loss 4.1834e-02, Val_Loss 4.9275e-02\n",
            "Epoch [64] Train_Loss 4.0318e-02, Val_Loss 4.2279e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [65] Train_Loss 4.0068e-02, Val_Loss 4.3946e-02\n",
            "Epoch [66] Train_Loss 3.8523e-02, Val_Loss 5.1561e-02\n",
            "Epoch [67] Train_Loss 4.6248e-02, Val_Loss 7.7758e-02\n",
            "Epoch [68] Train_Loss 5.1737e-02, Val_Loss 5.3206e-02\n",
            "Epoch [69] Train_Loss 3.7276e-02, Val_Loss 3.9467e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [70] Train_Loss 4.0998e-02, Val_Loss 4.3517e-02\n",
            "Epoch [71] Train_Loss 3.9295e-02, Val_Loss 4.0916e-02\n",
            "Epoch [72] Train_Loss 4.5695e-02, Val_Loss 6.5340e-02\n",
            "Epoch [73] Train_Loss 3.8519e-02, Val_Loss 3.8659e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [74] Train_Loss 3.9989e-02, Val_Loss 5.6075e-02\n",
            "Epoch [75] Train_Loss 4.0162e-02, Val_Loss 3.7612e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [76] Train_Loss 3.2712e-02, Val_Loss 3.6774e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [77] Train_Loss 3.3869e-02, Val_Loss 3.6894e-02\n",
            "Epoch [78] Train_Loss 3.0779e-02, Val_Loss 3.4604e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [79] Train_Loss 2.8868e-02, Val_Loss 3.9008e-02\n",
            "Epoch [80] Train_Loss 3.0608e-02, Val_Loss 3.4043e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [81] Train_Loss 2.9876e-02, Val_Loss 3.4016e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [82] Train_Loss 2.9788e-02, Val_Loss 3.2888e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [83] Train_Loss 3.0609e-02, Val_Loss 3.4576e-02\n",
            "Epoch [84] Train_Loss 3.3442e-02, Val_Loss 4.3331e-02\n",
            "Epoch [85] Train_Loss 3.3532e-02, Val_Loss 3.1772e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [86] Train_Loss 2.9518e-02, Val_Loss 3.4486e-02\n",
            "Epoch [87] Train_Loss 3.3973e-02, Val_Loss 3.8608e-02\n",
            "Epoch [88] Train_Loss 3.2617e-02, Val_Loss 3.1344e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [89] Train_Loss 2.7448e-02, Val_Loss 3.2356e-02\n",
            "Epoch [90] Train_Loss 2.9691e-02, Val_Loss 3.3351e-02\n",
            "Epoch [91] Train_Loss 2.9214e-02, Val_Loss 3.5782e-02\n",
            "Epoch [92] Train_Loss 3.9213e-02, Val_Loss 5.4755e-02\n",
            "Epoch [93] Train_Loss 5.5199e-02, Val_Loss 6.5288e-02\n",
            "Epoch [94] Train_Loss 3.4548e-02, Val_Loss 3.2573e-02\n",
            "Epoch [95] Train_Loss 3.3585e-02, Val_Loss 3.1864e-02\n",
            "Epoch [96] Train_Loss 3.5818e-02, Val_Loss 6.2094e-02\n",
            "Epoch [97] Train_Loss 3.0484e-02, Val_Loss 3.2825e-02\n",
            "Epoch [98] Train_Loss 2.9583e-02, Val_Loss 2.9206e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [99] Train_Loss 2.8280e-02, Val_Loss 3.2914e-02\n",
            "<All keys matched successfully>\n",
            "-----------------------------------------------\n",
            "ID_01: AUC = 0.8102, PAUC = 0.6675, F1 = 0.6040\n",
            "ID_02: AUC = 0.6770, PAUC = 0.5484, F1 = 0.5140\n",
            "ID_03: AUC = 0.7088, PAUC = 0.5590, F1 = 0.5433\n",
            "-----------------------------------------------\n",
            "Avg:  AUC = 0.7320, PAUC = 0.5917, F1 = 0.5537\n",
            "ID_01: AUC = 0.7958 ~ 0.0343, PAUC = 0.6847 ~ 0.0292, F1 = 0.5990 ~ 0.0220\n",
            "ID_02: AUC = 0.6527 ~ 0.0761, PAUC = 0.5659 ~ 0.0647, F1 = 0.4893 ~ 0.0426\n",
            "ID_03: AUC = 0.6620 ~ 0.0326, PAUC = 0.5469 ~ 0.0168, F1 = 0.5076 ~ 0.0240\n",
            "Avg:  AUC = 0.7035 ~ 0.0834, PAUC = 0.5992, ~ 0.0741, F1 = 0.5320 ~ 0.0571\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-HDVASPtUTt",
        "colab_type": "code",
        "outputId": "f469d9c8-2784-4006-b9fa-afa405b434f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 937
        }
      },
      "source": [
        "plt.figure(figsize = (19.2, 10.8), dpi = 100)\n",
        "l = np.random.randint(0,X_test.shape[0])\n",
        "plt.imshow(X_test[l,0].cpu())\n",
        "plt.title(test_audiopaths[l])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, '/content/drive/My Drive/DCASE/Development_Dataset/fan/test/anomaly_id_00_00000251.wav')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABKsAAAOHCAYAAADot8BLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAAPYQAAD2EBqD+naQAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nOydd7xnVXHAv6/XrSy7sJRd6tCkE5CiNBVFsYAVUbBii4kliUYNijGxgUaJXREDKoLRKAIKAgqINGmCQ106LGX76yV/zL387vvtmfve73Vxvvt5n7fv3ntuOXXOnDkzdcPDwwRBEARBEARBEARBEATBbKB+pl8gCIIgCIIgCIIgCIIgCHJCWRUEQRAEQRAEQRAEQRDMGkJZFQRBEARBEARBEARBEMwaQlkVBEEQBEEQBEEQBEEQzBpCWRUEQRAEQRAEQRAEQRDMGkJZFQRBEARBEARBEARBEMwaQlkVBEEQBEEQBEEQBEEQzBpCWRUEQRAEQRAEQRAEQRDMGkJZFQRBEARBEARBEARBEMwaGmf6BYLZh4gcClwGoKp1E7jPcPbfw1T18om/WTBbEJETge8B96vq8pl9myCY/UR/GAQzg4i0Ax8BjgOWA63Zqb1U9aaZeq8gmEpmy5gjIpcDzwc+qaqnTHf6IAj+upmwskpEbgL2AF6gqpdM/JWmn0w5cyiwQlXPnNGXcRjvOz4bymeqEJFNgMeBfmBTVV1fUMLkfERV/3OU+5wBvLtwaFoFg4JAUqQfWAOsAm4DbgB+rKp3T9d7zTQi8g/A6cDZqvrG7NjlmNBTZBBYh+XXncCfgF+o6pU1Pu/FwCuBg4DNgTnAWuAe4Grgh6r6xzHc57PAP2V/nqOqx4/x+ZsC7wBeDOwEzMu+6XHgXuBK4PeqenUibaoOeZQKjNOd70HgISJ7Aq8AVqvqlyb53iuAZVWHB7A2vxq4A7gR+OlUKkT+GuSX8SAip2T/PVNVV4wxzSuA/wWuUtWDC6d+DLw0+3831ieCjZOzBhFpwN5tE2AHVb17tpaviCwHTgSoRYEgIl8C3g/8u6p+bCreLQhGQ0TqgLdgdXhXoA14EPgl8FlVfdxPDSLSDLwXeD2wI9AA3Af8FPiCqq6bgnc+DPh74ABgIfAEcDlwmqreOIb0rwLeCewFzAUeBX4NfH60ucFM55eIzAE+CBwLbIPJj3cCPwK+oqp9TrotgJcDh2XfvUV26jHgGuBbqvrbkueeAvxb2btl7JDKw6yfPBjYB9g7e4c52eltxjq2/a0zIWWViCzDFCGrsQbz18qhWGW8AjhzRt/E51BqfMdZUD6a/e6agWePhZdiHeZFqrreueZEwFVWiUgr1vnOBjYA+XfUY4PRImAHTInyaRG5CDhZVe+f4LPWYOX78ATvM5W8PPv9s8S5fuDpwt9zsInnMuAFwD+JyB3Au1T1irKHiMiOwNnAvoXDg1gezQP2y37eLyKXAa9R1SedezUCbyocepWIzFfV1aO8wxHAuZgAk7MBaAJ2yX7yyVqZtWSxDnmMdn5a8j0IxsCe2Lh5PzCpyqoCPVhbB2tbc7F2uC1wNPBxEbkGeKeq3jIFzz+U2S+/jId8gnA5sGKMaTbqe0RkJyp932tV9dzJeLkp4mBMUfXnwsTnUGZn+S6nUkan1JCubHwInp08gMmLSblnuhGRFuDnwIuyQwNYP74D8I/Am0TkRap6g5N+AXAppngA6MVkvt2ynzeLyPMnQc4uPvMUKu1tGFsU2QI4HnitiLxLVb/tpK0DvgOclB0awuS45dgC5xtF5NWq+isn/YzmVzaXvTx7X7A5ZQsmc+8LHC8iR6jqqqp0W2Fjf1Hm7cr+Xp79vE5Evgu8Q1UHU8/PqJZdqxlwjp8CvLkkXTAGJuqzKh90fqWqXkEFM8eMlo+q7pT9XDvdzx4jef783Dm/AhARObDkHq8AFjB2YXoq+YKqbpb9LFbVVkxZ9RJs9WEIOAq4VUT2LbvRaKjq/2Zle8TEX3vyEZGFmODfC1yUuOTqQl5tpqodQDtmFXUaJgjsDFwmIieXPGc/4I/YgLkB+A9MQdykqpsAzdgq1L9iK+aHAVuWvPrRwGbAn4HfYttV3jDKt26NCf4LsXr4FmCBqnaq6jxgPiZknIFZ2pXxhap8Sf18oeRdpiXfg2AW8eNCfV6iqm2Ykvpw4FtYWzgAuE5EXlp2o2D8ZFZJef4Wx/TnZL+fmuWKKhhdJvmrRkR2xyaID2PW3sHfAKr6pkxe/OpMv0vG6ZhM1I9Z+3So6hxsUfEvmML4lyIy10l/NqZ4WQu8FmjPZJkXYtZKy4BfZH3ShBGR11BRVH0D2wkyH9gKk/0aga+LyHOdW3yYiqLqk8C8TDbcCbP6bwfOFZFtnPQzll/ZAu4vsH7jUWyXUC43vg6zzt8L+J/EcxswxdSlmMJoiyxtJyaX5/3sWxhd4V4tu1b/rHDSDWG7K84F/gXbjh7UyGQpq56VA+uzgCgfh8wi6oXYCsUvnMu+n/1+S8mt8nNnTs6bTS6q+pSqXqiqrweOwCwA5mADy4KZfbsp5WhsAP9tidXcCFS1W1WvVtUPArsDt2AD3VdF5JDq67NtpD/FlEGPAPur6kdV9RZVHc7uOaSqt6vqZzBLi29idc7jrdnvHwBnVR3zeCc2+PYBz1fV7xUtsVR1jar+WlXfS8UEeqqY8nwPgtmOqq5V1ctU9R3A32HbJZqBH4nIDjP7ds9aDsQWZ+5Q1bsKx9uz32Pqj2aYZ7vMln/f/+VjZBBMJ5kl/DuyPz+hqmfkW8hU9XpMhunGFg0/nEh/BOZqAcxa9lxVHcrS/wbbpgamJD9xEt63Afhc9udFqnqyqj6VPe8hTPlzG6aY+Vwi/QIg3277DVU9JZfNVFUxBf9jQAfwqUT6mc6vN1NZcDhWM3c2mWz9Y0z+BXhJ9qwiq4B9VPVIVT1LVR8ppL0d23GSL6r+QzYvnGzerqrbq+prVfWz2NbDoEbGvQ0wawDPwyZIFybON2PbWY7DtJ7zMRO6Fdn1P1DV+xLp9sLMCp8PLMEawR2YVvJrqtqbSHMiBWfPIrIP8M/AIZi1wcOY9vnUoplgtpe0+A7PT/huOUmr/ARk6f4B27ayDFP6PQBcDHxRVR+YBe84WvnsBHwcU2Dkk+0LgE9XX1uV7hQyk3RVPVREjsU6iz0xQfFTmvkvSDl3FJF/xCwoVmJa7qTFV2a2eh+Wv59Q1VOrzjcDbwNejXVkc7H69Ufg66q60TdX8QKsc75GVR9zrvk+8AngNSLy96o6YjtjZtFyBCYEn0dCMy8iR2H5PwhsnXeWzjf/HrNK+b6qnjjK+9eMql4uIm8DfoK1rQ9gdaD4DiuwPD8J+6Z/wjr05ZhCZBtVXVFdnwvpb8YUDqer6ge8dxGRw7HVjmFgeXWbGU8bq+IV2e9xCf2qer+IvBwTAjqAz2Bttcg/UbGSer2q/nmUe3YB7xSR5CKBiGyOWcENYatEazBrqL1FZA9Vvdm59Z7Z75tGyxdV7S47PwlMR74Dz/joej8mLG2LmYU/ggWHOK26PETky5i/hz+p6t7eO4hIJ2YF1w68SVV/UHV+DvAebOIl2XuuBK4Cvqyqf6jxs/P7tgInA6/BrMvasve4IvuepN+jqjZ7PvBR4FXA1pi135XAf6jjL63YTwO3YlaALweWZt/1C8xP2RPZ9cuwFcKjMN9sK7E+5RQt8TtRa3llaQ6lEOxDRLbPvu8FwGLMZ8eF2bMfrkpbHCeXJcbNaXHWq6q3iMhxmJDagY0pJxSvycbrV2Gr1ztjSuV2rPyvAv5LVa+pSrOcGmSD8Tyj6nn7Y+3nQKzcB7FtPSuAS4DvZZOn6nQ1jdUiciYjt01cJiLFS7ygHiP6noSvkeo68Mw4m1kUvAZrA9tieTOMjTm/xupnsm+VgvPn7Odt2c/OmNL9NuAMVU2t/Bfv85zs2Y9gVnjLmSb5NEu3EyYTHIqNa/VY+3oYs/I9S1X/kl27goK/tsR7eTJMcnwQkd2wucLzsvsuxaw47sHk0i+pv3U+f5eTgHOwPuaNwPbY1pwbgM+pasrSN79HA1bn3ojJL3Owun01VnaXO+kup1L2nwbeh817dsC2G10N/Fs+dos5+v8AZhGyDbaV6hLgo6p6T+L+9VidfDmm9N4S6/fWYfXqh8B3VHXMvtcyi+WvYRP5para41xXj/m6XMYE+0oZxUF6lv/vxspQMGvUW4Cvqup5432uwxsxxc564CvVJ1X1XhH5MaY4OYEqGZlK33Qv5guvOv0fsu89FKsL35ng+z6fSlv7j8Tz+kTkC9iC+cEisk3V3PqVVHwkpdKvEpGvY/OXY0XkZFXdULhkpvMrT3+ZI1v9CPh3rD29CZtX5Pdeg/mNTKKqw9kWwKOw+c3OmO/USUPLtxaOm2zufR7WTy2uVv6LyMWYQQbAc1T1tqrzH8Hk6ytV9ZDC8XHJCZM19/OYiGVVcQV9hICaDfw3YCbwLwI2xYTmuZg5/CexAYWqdP+YpTsBE7R7MOHuuZgZ4rXZhM5FRN4A/AETjNqyd9wGU4D9PpuI5AxiBZA3zP7s7+LPiMmdiByPmT2+H/MDkyv8BBPkbhORF1LCVL9jRln5HAXchG0vWpLdc3PMvPNP2buMioh8EWssR2bPGhpDsnOyb1pMZf9zilxoGcasTIrPXYZ1QGdgHdxCTDBYAhwD/EpEvjbKe4zqNyHr8C/HOvrjEpe8GWtD51Ipn2ouxgTOBkostDJBMXcI+82S954Q2cCfd1pvKrl0E6wtfhxzhjjWbaR5Wb0+ZdJbIJ+sXZFQVE2ojWWT/hdhdef/xvjeG6Fm1ntm9ufBIrJt4RmNVFZ0LlXV39VwX6+dvBmrJ5eq6sPZ6tf52bnRrKsAlmZK3hlhOvK98KwjMeea/4op69qwOroN1s5uFJHq+p3Xzb1EZNeSVzgWG5zXY5ZzxefuCdyOCX0HYGNaLzaJeC1wVSYE1ISYE9DrsHHuudi414ONgycAN4jI+0a5zYLsHv+CKZf7sHb8cuBqESmzECV71k3YOLQE69u2xhRzV4jIfLFtrzdgSrWFWH3dCpuAXei1+XGWV/U9DsPGp5OwbXb1mCD1Nkw2qLYafBzbdgA2NlWPm9NmaaO2FT73B/JqEWmruuT9wLcxmWDnwvGtMZ+IV4vI31elqVU2GM8zABCRN2Myyxuo+A0ZyNI+D1uRPzKRbjxjdR4UImdV1Tc9kXpHNh7T11NeB9YU0n4P8035Ikzu6Mbq6M5Yvt0iIkWH7SkaMOfu38Qc6Q5jE6ADgB+IyCdHSV9tdTRt8qmIvABr+2/HFC2N2b23BPbHtq68rpDkCUZuKa9+r2Le5s/YCsuXtWQK6AK/xBSLh2GKqi4s7/bE+oybpEpjmaAT+B1mXbIzVt5zs3v+yuv/RGQepjD6Tnbt/Oz5m2Ny32Ui8vlRnt2EWWichuU72Lzn5cCVIrKvmCX2lcCpwHaYInMhpiS9Wmzxs5qts3d7H1YO87J3W4i1u68Blyb6kzLOxtrGAtJybc4LsbYwyMQVLi5i/pAuAP4LM2xoxfLmecBPRKQ0wNE4eEH2+3dVSpkiuQJ9WaLe5ekvqlYQJNIfXGPZpMiftw5TFpQ9DyoKiur0t6vvQytP30ZlHlKdftrzK1PuHlR1zQiye+aK6NK5t0NRWTsp2zaniSuwMWYRFcszAESkiZHleHgifX6s2rn8eOWECc/9ypiIsippriy2Z/VizGnaKsx8cIGqLlTbK7od5tH//qp0L8U6+rrsntuq7cntxCbV6zCt3XklGbEp8F3MImbrLP0cTAnTj+1RzaNsoaoPqupmQO6DJbUn9RlNcDagn0XF3HIbrHF3YHt/f5I97yfOwDPl71jAK58tMe12C7Zysb/a3uMOzFRzECuH0dgHm6B8Fliiqguze3yvLJFaxIhfZ3+eUHJpfu73WtgLLCIdWMe0K6ZIOhRoy/JxfvZO64GTRWQjhWh2j3rgZdmfo1mAfDf7PULQyZQCJ1ZdsxFZR/qN7M+3ligT3p79vk0T0dommXzStLX4e9RPwQS9VwKdqroAm5SuHOXeZ2N1aDMqg9QIssEoN/09q+rcZLSxI7Lrr1XVR0d539G4oPD/YjS7fTHBEWyCMhnkdayYJ/lW1OMzoS5F7hNuS+ALWRuZCaYj33MLhP/D2vu3sMlBm6p2YsL1f2Nbrr4jBd9saibrt2d/jqXv+WlROMsWSi7G8vmnWB1oU9W52OT7VKzuf0YsKtmYyMaz87Excw22ktmZ9WnbYRO5euDLYhEnPf4NWwR4DeZTYh6WN1dk6b8hIq5FGfBlbJXugCwvOzHhpAsTWk7F2t/NwG7Z/edgE6lBTKg8qfqm4y2vBOdjgtXOWZ53YArCddgEd8SqcTZu5mPAg4lx0/W9NkXkdboFU2AUeQRbxNsX8+exEOv3tsXKBeA0MctzYFyyQc3PgGcmDF/BZLP/AbZX1das/Duz+32eqrFhvGO1qr4/+66cV1V9035VeUemfN4O82lybXafL4xSB4rywU2YUnbH7B0XYeW0f/YN84AfjzLxfE/2jScCc7P82YqKm4GPSfkW0BEy2zTLp1/LvvfX2Cp8czbmt2H90r9R8MuZlcGrCn9Xv1dK9jom+32hbhy56wos35apapuav8dWTAF6LaaUPsfLuIxPYX3zK6j41NkJs2isw/rPeYl038HKrQ9T6M3Nvn0pFdnuQ1LuQ/HdmGLt1VibmINZQt2b/f1lrO9bgClEc785R2KKv8WYlUM1A5hMdQywiarOKcwZTsLa9CGYZcmYyBavcyu/t5dcmp+7UFUfHOv9x8F/UFnk+hg2X1yAyZBfw3ag7Oknr5l8oeq2kmuK555Z2MoUjpslrvHS1zNywj8edst+3+FZ6ajqSipK/OqFuDx9zd9b9fdM5NfOVPQUY0m/mZjf1Fo4NPvdhy2oeewqIreJSJeIrBcRFZFvVY+X04Wapemt2Z/Vyqj9sQXXtanzYtbOuRKweuFgXHICE5z7jca4tgFmk6ajSK+gfxhbmekFjlDVESZ1qnovaWVIvtf299i+1MHs+j5sVWp19qwDsQl0yjS0HTM/fqYDVtt6c0a2Ov8BTPj+xNi/1sgUHGdgDeddqlpt/aLYdrGfYwPLBzBT7Gl7x8K7lpXPRzElxFOYo7qV2TsMARdlk6FRQ6BiA+1pqvovhe/opUoJ6XAWphh7uYjMVdW1xZOZhcZxhWuLfAATQK4AXqgF82c1k8/TxczCf4oJh2foxlsND8CEgzs1M2sv4Xys3J8nIttm9Resg9s2u8dVYqb3Ht/FBKnlmOb/4qrvbaFi5TRlVlUFitvJtmPkVoOcNuB5xfariS0e1ajqoyJyCSZ8vIm0k+1XYMJWN4V2PIltbDL9flTnVU5xQJ+w2bCIPA/rN9cx0prnMszfzVZYvqUU02dgiwJLsTx5p9iW0uswK5g/5O18DIwmlAPs5wiv05HvYFHd2rCtbR8tnshWat4jIgPYxONjVLaegK3+/Aem/PuoVlm5ZdY5h2V/Vvc9n8b6jXNU9fiq564EPiEiq7Dx7RTGHu3qOEy4AIsUmSvzcxP7V2Ir8vtj46S3xXkecKSqFs3g78j69Jux+nUqZnWbojdLn/vD6Md8LO2CWVi+F3P8/5Ksr0dtC8lXReTvMCXf67BVuSITKa8iNwGv1Iq/iz7MKewSbFX+OBF5S6K/ny1U1+lnhMREX5cvdNyH+dJoxJQh78EsyWpmAs/YDeuvN2DbzgYK6TdgfUzKWfZkjNVjJe97fqHj8IWkqhuNI9m7XJstpN6ILZYeS9qRL5gi4nBVLZbrQyLyakxpsRRTJG+kWMj6nX2w/t8No+4xkbFTRBZT6WNP1MJCQ9a+/5z9TBR3fFDVjaJlZe37UjE/NHdj2+EPVtUrnfu3AwcWZTpVVRE5BtsG2Yn55zk7Py+2tTWfPL2vmG9q7iHemim4jgVOFZEzNb1tbj5wSNW7XScib8e2vByIyTu768jw9peKyL9gCrNXiUhTVTt5CFu8qM6b9cCZInIbNs6/IxvPklv6Enwds459noiIqmrxZNan5gu6UyaTishSbLED4NOq+kzbyMbUd4vIfCYp4rbYFv58S1xZJOviuaXO/2tJP5Y5lUf+zNEibz+MGUMsrTo+anpV7crm2POL6WdBfo03fVnUvmfIFutzeffH1XPRKhZhFo2rsTn0jtnPW0XkM6r6sZK0U8VvsXHpcEZGO86VU2cAH8K2kNcX5N0DMJmsB7OYfobxygkTmfuNhfFaVh2OdfzX68Y+eHLrgG9XK6o8xCKE5NrUT6e0x6r6CyoWBGUdl+dzKR8gt89WCmsln0w+ycbCeJF8glO2xW2q3jEnWT6ZVc9rsz+/nprAqu1rHUslGsKsqsbDzzGNbyu2ElXNMdjEqyfxLvl2qNPU36f/s+z+izABsJoxT6rVfPz8CFuZO7FwKrcgKLUky+7xBJXtXO9IXPLK7F27qdryOEUUO3JvFeKisbbfBPk3vCIb7KrJLVd+piO3qE64jWV1fKxWc2PBy6tNnGvGS16vz9eCb7RskPhB1TUjyFZYDgZ+kx3qwJTVH8fawuMicr2InCiOv6wCHZiVUNlPKmLLtOR7phQ+HFtxLrOMyevIkVWWuGdjfdeWVJRSRY7HxsWHKCgTMgV6HpWxrN/Ln7tHJvCPhbxP/kNRUZWTTZrzLUS7ZZZKKa4qKqoK6bsxyxeAoxzrAoBv5YqqKorK9dM04TeycM3uxYOTUF5FPlOtXMzI61sb1n/MVsbS73rkVlmjbUWbCN4z8mANzYzs90ZjMsbqsTJljskzeTQXvMvy/6qioqqQvhenfRQ4BpMxLkpYHY2FiYyd66i4cCh1szFesj7nUGz3wK/Krx5Jppi5IvuzLP/PSy0+ZvJXPiGrzv+8730IP99yHzyLcCwGML8vKSXaFdgiQP5+dyeuyetGzf2XmrXwSmzcHrP1kZoPrTxPUjLpSdjWxoeosbxq5DgqW0698eGUSXxeUR7tcq8aeW6O8//xpB8Pefqy5xXPVz9vIulnOr+mLL8zK5+fYEruJzH3CSnuwnY7CdCqZvXZgfWhN2D99r+KyAfH8txJJh9vnlclN+Wy7S8x35DzsS3Y1ef/4MhzZZTJIuOd+43KeB2se04Sc8eI4EdYS5Gb/g9QGZRS/AYzrfW2CjztDAZgpm05Cxi94VaTm8zNAx4Rf/t8c/Z7mXN+Kt8xx3NyvA0VIbls9e63jL6ScXcN1hojUNVuETkPU2yewMb74fMK/fNsBRZ4ZvUxz9fviEiZ47rc79cyrLEWqVWw/R42oL9ZzGlrJ7bSNsjYTRm/juXpy0Rkidp2yJzcyu5cLURxm2G8vfFj4X8xAXgOlk9n5ieyCXy+r7w67yajjR2AmaHerRbtY9YjtnXasyQE2wr4UeAIEdlaE/u81fyrvVBEdsYmPs/F/D/k2z32werx60Xk5SUrsON1pDpd+Z7XkXrg9pI6kg/cHdgEO7cgfVDMmefhWD9TrdzJ+56zqxQj+2DKdYBflzy3yDJG+t7xyMezS0quuQzrbxqy629NXDNanw6Wb3uzsek3VBaDqil+w3WjXFMdYXRC5VVF0kE8I8fNWpVAs4bMsvrdmCC5HdZ/ViuXt6xONw3PuAfzg7QT8EcxH1MXA7emFhaz50zWWD0qmXXGftiWwo2UtTXc5xBMwXYAlgep7dRl+V/27nkd9ernhAJTMIGxM5PHLsUUMReJOVu+AAtEMR7FWYqXYMqPS4oyXZHMgu0ErCyXUIniWGSy8z/vey9zFOG5derD2FbEfUnPbZJ9p6oOisiTWdrR+k7YuP/Mt+y8Bdt2uRvWPzZXX0ftfcPXMTnhTSLykbyss4Wn3GLiO14bnyTy/L/es2pR1TsL+R8EEyazDjoHk+v6geMThjcAqOrZiWN9mBz4O8xP3n7AKSLyba9/myKuwOTCedi3XJstrD4XGw+vxWS9gzGZ9/osXW55lZIDJyKLjHfuNyo1W1ZVraBXb3Mo+hkYy3awnMXZ7ydH0fLl25AWO+fLNHVF8/Kmsb5YgVwJ10S51UE+2Hi+DabyHUcrn2K+lZlUjrrdi9F9F41GXlmflyk5AfKIUUdVXZNTNAldRHk55HV7hMAj5shcsvcfU9QutcgHd2AT/yOw1bh24GKvg0vc43eYv5wmCn5dxKJb5VrubySSTgVFgS1lSQETKN/MMii3JKv2DfR6bGL6GBVLoJzJaGOjOs6vES+vnnKuGQ+vw+rTA5hvlxGo6p2Y3416Ej6Bqq69Q1U/q6qvUNVl2Er5yVT64xcySsTPcTJd+Z7XkXrK68iiQprqSU/erxxbtGAVc56+W9U11c9llOcWranGah2b98tlZvo92Opf8fpqxmomX+v4OVDDNdULYJNRXsAzvlZSxyc8bk4Tbr+bbfW8HfPnuTcmfK7H+uHHqTizHrc/uvE+I5usvo5KdN7/xLY+rxWR34jIuxKW4BMeq2ugaJVU6yoxACLyWWzS8WayFXRGOnbPfdeV5f9YZLuN6me2WHFods0F1efHyETHzrdh21Q3xSyJrgHWiciVIvJhqd0PTDXu+CAi9SJyDqYEeg22qNrMyPzPF1cmO/9H7XszJmPuUXP/lW3RvB7z3fQCbDwfwsaCPG9yJVutfcO5mLXnIgr+x7CJ7HbYJLjMSm8yqDX/J0qxDMr6m+K5dc7/x5N+POTpR+sf8/PVz5tI+pnOr0nP78wC6WxsgWAAeEPKon0sZHJZ7tqgE5sfThuZYizfAZMroA7E/A/+Putbfls8n1mU5T4zN1JWTUQWmcDcb1TGY1n1d1iHeY9uHGq6Zl8Bf0XkK79/VNVq56izibLymUwmutryO2wCvQzbk5/vVX8dVi+LjthzimaOO6dMvsdA0bfFWKIX5nwP8xdzEpVoiaNuAazi65hvlbeJyGezLV5vIwtvreMMeT8O9ij8f6NwyRkTLd+zsG2Th4rIVlrxcZR3YOckVuwmo41N9nYQL6+KbWsvLET1eMm3y2wNDI1itXOSiHxKx+iXJfO78Q0R+RkWUGEx8BYR+aca6/9oTFe+53XkcR3phLkWzsHYRQkAACAASURBVMecendiW3DzlbO8bt6YsA4r9j1tNfgG+VtnMsrr2UKyTos5oT0TEzB/i/k3vDbbvplfcwTllnelTPQZqnpzttDzUmz7w4GY374js5+PiMjRqppb/E3GWD1WJtT3iDkmz4Pa/DemGBjhzFhETsX8qU1FtNUXY8qZSydgWT2hsVNVHxALvvACzArqIKy+HpT9fEREjlPV8fjTasa+EdJRYt+KTWQGMTnwB8C9xfFJRH6AyYkzFu12hjgdi/T1FOYP+MJsTH8GEXkQs3KoKW9UtUdEzsT8l70Dc3cBIx2rT5aSaFagqutEJLf8KLPUKp57xPn/eNKPh0cwpcFolmX5+ernPYItlLjps8WG+dXpZ0F+Vae/pcb0I8gUVf+DKcUHgTeqRUifCMV520aRq6eB32IWiodjC0nVUf7+gCn7DxaLEngQNt50UWWNOkmyyHjmfqMyHp9VZYJBsRP1tsGlyK04Fokf8QoqZmcTteoZD/m31fJdM0FZ+RTzbawdx5SQTbZzR6VFDWz+/x/qxs5Wx1u/ioxXsP0BpoU/DtNKP0Va8CrjLKyD2A44POs4TszOTZdVFZgwCnC/FiItTjKXY47B6zE/QIg5as73TafMQCfUxkRkR2yryhNMTHlUpOiM+vLC/6+nEp77leO9uYjshimYx8oyEiHiRyPbdprX+QXYCvqkMM35nteRRTLOqIeZD5Q8guMJ8IwQk/ukKqubMPljQN4vu9s4MtPu3F+QN/6NtU+fzvFzwuX1LCKv072Y5UrOSzCHrauAl6nqFUXhMGOiir4JP0NV+1T1p6r6TlV9DtaHnIxZZ2xFJXIpTG17eYbML0buE228Vkmvy35frKrvUdXbEsL0VCpaJ0PRP2H5VFWHVPVitWiM+2IT3OMxi98FwDmZ4qlWDsXq3o2aDsyR5/+3VfXfVPXuxELKVOX/qH1v1flp6zsz+TC3eHqvqn4voahqYKRVaq18AzMyOFREtheRRVTkmemQSfP8HKsiZjLIFxp3K7mmeO6ZhUk1n46PJa7x0g9huzImQh7pbmfPn2NmgZfLdNVGCnn6mr+36u+ZyK87qFgOjiX9Y6qa9CFbsKh6HRVFVSpg0V8buXXUQVn/PEJZlVkbX41ZQu1fOH+lbuxLcjJkkcupfe43KuNRVrl76zNfKrk558uqz5eQ76NspCpMeRX5JM3b+z1e8sZQtjKR+/DZTMrDa08VY3lHKPd9cB8VJ68p58I51WEwp4q80oqI7CdmUrJf1blnyBQr46lf+UOWYI21ixpXqTMh4UIqZtpn1+rPITPZ/GH25zuwb1iCOZf0IgxNKiJyHJWO/cypeo6jjMx/36Lm4LOaibaxvO7/cjKshrLtqSdmf15RVOxlitQ8asYRYtH8xnrfYr+bW1XdiK1elf3kWyjewvhYX/j/uLbLOExbvlOpIw1UVuvHQ9Gh92bY2LIZNulNhUi/DgttDOPoe0YhH//KTMgPpWIJ7Y1/ZX16fm6ISYheWQOTVV7jZazj5pQiFi0xXyT4UZVl3lbZb9VCcIUqyhTUY/nGiT5jI1T1KVX9BhZaHmCvbGV2wmN1Rm49WvZduVXS71V1Vcl1ZeR5k2wXmWuFKZGJMoVEXi88ZdWMyKequk5Vz6EyRi3BrHyq3yvPI4/R/HGNlv+dVKKlTjZ533uYOMFHMovCXFky2XOPMjal4ifR67MPLlxTM5mLgd9idevtWBSvZmyy6UWdnUzy/N83K+eNEJEdmKCvviryLUiHJLYv5+SuSO5XHRkpsZD+RSX1Pk9/ZWKyXyv58+ZgFq1lz4ONd6Tk6XcWka1Jk6fvxiIPp9JPe35lY9VVVdeMILtnHjAiuZ0vU1Sdg7lwyRVVP0pdOw6KlqypyOpTzZWY3612bAzfD5vn31S4prgVMJcFU/6qJiwnjHPuNyo1KauyTmNnbL+054A5d5b9NhHZayz3VdVbsD2SYCGMU9GmXkJlwPph9fkJkjv2m19yzWVY+FywkMulK0yTsMe/mlHfcbTyySrRudmfJ2erKNX32IWKs+cpJRsoczPEN1Gp0LepH4nuW9nvt45WvxJlcAxW5y8e5wDyGeCL2c8Z40gPthUQTIDLtx5Mi2N1EXk+FR8EjzEy1OlUkCsEdskE6OOrjlcz0TY2aX6TskH9/7DViEHgXxOXfY6KyfEPRWTXUe7ZJiL/TSbwZ9+Xh6U+V1XXl/0A+SrQK4vfLiJlQkR+TSeVVdr7Jrm+TVu+q+pdVCyt/l38yHb5/bx++BKs7Bqwepn3PRepRY8agapuoKLE+ucSoW+056bIhabnisgLq0+KOQP9RPbnbWoRW1McLCKHJtK3Yv4HwPq+aQviMInlNV7GMrZPKWLRG8/DJoQbgFOrLsktNHfMyqo6/Z5UrP5SjOUbx/2MUazdwSY4OUVl9UTGahjbd01G35PnzR7O+ZOZuu0dh2I+Qf6kicAZGVMqn47BWsor36JD7OS7ZRPJY7I/vTIaLf8/zsQjqnnkfe8WFMKwV/Gp7PeTTGAr7jhYS0Vhu1HeZOPCv1cfHwe5THoilciA3x3PVp1xcD42zrcBH3Ku+YRzfLycnT1zDvDe6pNiEWxza79UdO7cgnQ7EtHMRWR/KgqBcVmRVHEFFZ+jG0WsyxTe+fh+pVqwnSK50+s6J/18rI8Di0a9oeqSmc6vPP1h2bXVvJpK/7xR+oJF1Wuwxcjjx6qoGkUJn4+NeRvcwAQCfIyXbG6QK9E/gS1qXlG1cJwrpo6hEFQicbuJyiI5tc79RqVWy6pcMPhlSUf2BSzUYwtwqYi8XcyBJAAisp2IfEJEqjumfHXuEOA8Edkmu75JRI6noqC6mslz4puTC/+7ikhSc51ZUpyMVfaDgd+JyBFZR0H2rtuKyMkich3mSX9a35Gxlc9/YB3XIuA3+SqciNRlE6ULGX8UwvGQd26vozJxT3V4OV/EImG1ApeJyHvz1VywjldEXiwiZwG/r0o7IXN7Vb1GVT+U/dw5zntcj4U7baaifJ0yc2sRWZjlxzlYRzoPE4KOnupJa+anJF85+xqmtR8kbbkyoTYmZgZ9AFZ3a3bel92jVUSeKyKfx/bG744J5+9S1ZTy90ks4sVazMHtH0XkMyKyWz7IZe1qJxH5J8xPzbuorJC/nIoJ/7mMzi+wiUMLlc4f4P3AAyLyFRE5sqq/nSsir8H6zXyLyBfH8KwxMRP5DrwPsxLbEbhGRF5eHFhFZAsROUEswtVnU8/MBvK8Hr6Vyup/Wd/zUUzBtQj4Q/aMZyZRIrKpiBwrIv9LbQsq51NR2p8rIm/I63w2Dp6PRXeBioI7xRrgfBE5LpvI5FYBF2DbNAeZfMF/LEy4vCZAPm7m7WBaEJE5InKoiHwDi8izFWaZ92pVrfYT+Gusvi8EzhaLpIeINGfv/GvKncaORTaYyDNeJyJXicg7xaIE5d/YICIvwvxkgIXBLlo3TWSsLn7X8ZJQxmd1PLdKqnVLfpGLst8vFpGPS7ZdNXu/jwJfwQ9EMlHGIpNMtXx6oIjcIiL/KCI7S2ZhlI1dB2JjN5iT66LPmDupWJu+zZnY7YMpglZki9Ip8vx/u4i8QzLlmYhsJiKnY33elOS/ql5LxSHwV7I62l54/reoTLA/rtPoqzCbhObj32kicnihbHYDfoVNPKuVC7XyM2zxcjEWXGA6HKsDoKoPU1n4/biIfCQfU7Px9KvYvGDSIqxllj+5VfypYgEi8jq3DzZetmF58vlE+kupWJ19U0ReXSiXI4CfZuduZRJ2L2RzuXzcf4mI/LdkyuasH/8RJjMVryumX0UlqM7JYvPvvI/bEZMrN8fq0UbywSzIr+9n5+ow+eaILG29iLyayqLIhdmznkEqPqpeS8WZei1b/54nIpdk8skz1n1ieokjsHErn8d9KjWnyq5dlP9gc7CcBcVzxf66kH6FiAyLRbH2yBVP+btU+xa8FpPB9sGUWeuweWg1E5VFgNrnfmOhVgfrow6sag7ZjsIawC5YJf+6iKzGhJZc6PhyVbpfisgHMAHnFcArsjTtVMK03ooJe5Ot8b8cUKyjvkpEVlFZNfqQZg7YVPXSrHGchVWKS4B+EVmLOestrkBOtkJtLO84lvJ5QERejw3QewLXiTnQa8Q6nEcxh4vfneT39/gRcBo2AVyENRR3S5yqrs/q1/nYJPkrwH+JyBpM+Tq3cHm+0kjWOR+BNZhfTvI31MrXqAgDk+lY/UMikq+Q1GF5UdSOD2MCzrtKVnEnm7MwgSrX5l+iqo96F0+gjb0MK//fjNFq7kARKfp/6KASQj3nz1hepSZS+fteIyIHYHV2b+Aj2c9A9s5zGdnPXoyZ2ENle8UNidWw1LM2iMiFmIXUW7C6D2YCvAm26vVegKxN11V90xDweVUtswos1iGPq1U1t9Ka9nxX1duyPuA8TAnzM2CwMF4UI13dW/IuZ2GruTtnf6+mZNKrqo+KyJHZ83bM0g9lz21hZHSUMa/Aq4U3PxarG7tiq4DfE5EuKhYLQ8A/qmrZ1oxPAu8EfgL0ikgPFcFoGMvT673EU8Ukltd4nn23mBLsCODHIvJtKlvhv6Sqk2Fd+trs+6DS5qqVK1cD70xZxanqXWKK2n/G2varsvGsHdt2fh/m3HujENoZlzOKbDDBZ9Rh208OBBCRXkzwXUBlwfMRqrYnj3esLvB1zBnsscAxIrISm3A8pKoHYy4j5gM368R8L56FRQE8BLOi+WRWN+dl73kBtg3rYxN4hkdudVSmrLqcqZdPn4PJYacV0syjMnatxSZ6z8jeqtol5vj8rZiV8Ski8iTW15ynqh9ibMq4L2LW/DthC3dfKzy/LjvWipXRVPBWTPZ8PlZHT8/Gz/lUFpa+oKpfd9JPJf+AWdZsgS029opIH2blMoC1uVOZQJRQVR3I+sW8fk+3Y/V/xuaKR2K7F07Nyj/P/89i/UeZi5ha+UfMGudFWFCFL2fjZb749BTwUlVd66Q/HiuPvbCFxh4RGaLS79+P+fyZlLmqqp4rtuvl37AFz5OzfjSXDwaw8d2bS3wea18nYXLCJ0RkPRX5oAt4TYkcOmP5ldXPYzCFzHLgkkw2qmfkNtnjq9Ni40du9TWMKaS/krgu5/1Vyqw6THbIFWTdmFJvHhWXMEPAf6rq55x7HkTaignM/UeRw0hEBB8Dv2XkLoQRyqosD6+kspUyjxRI1XUTlUWK1DT3G40xW1aJyKaYsNKNsy80R1XvxSrlu7GMX4VV6tWYZ/qPY1EuqtOdjn3Y/2ATuvbseddgjWU/VZ1oZIXU+w5glfHbWGF0YFYIy6iaSKnqz4DtsQafayvnYz5gbs7u8UoSGuapfMcay+cCbGL9I8zBYTMWfe+rWLlN275bNQd8vyocunS0Ms7OH4xFkPk/TMGWKzVXYIrSfwCKfoRehHVsV2XPnEnOo2LePZlWVR2MDFG9AbNy/F+sI9tBVY+eRkUVmIVJ0YnfqGag42xjtVrNFUN8L8KUmPdjAv7ngINVdbcyRVXhfe9Q1X2wSFnfAf6SvfNcTMi/Duvv9lHVo1T1KRHZCou8BGOzqsrJr91TLHoT2Ba2wzGryUuxFfBmKuHX8+fvpaobmYFXUaxD3k9xy86M5HtmcbUjpmz6HTa2zM/udwc2hhyP9QPePW5l5L7+n4y2cq6qd2CrmO/E+tknsXKuwybcP8G2UtRkxZOtMO+LLRRcg/Xj7dg4+AOs7vzXKLdZhTnr/0/MKXILppj5BXCQqn6rJO2UMhnlNQGOw+r/nVj9y8fNydoa2MrIttGLKd0uwCaSe6rqQSlFVU7WLt+E9Xfd2XvejU3e9qIkwtFY5ZcJPOP/snTfw/rfNZiwvi6718eBXTUR8W+cY3We9n+wvu1KbDK1efZN+Qr3pEQgVXMy+0JsvLkTG6/qsm97F6ZQmvQtUVn/vRXwgKre5F03DfLpdVh/9TVstT3v03qw/vFzWETHVJ/8HuAUbCEZLKLtMioWw2NZQF2Nya5fwurEIDb5vhx4vaqOtngyIdR8iR6BKa0ux+p1J2Ypcj5wmKp+eCrfoeTdbsD69HOxcqnP3u9c4EBVLbMEroWfFP4/ncF+yMbcF2MW4jdh1np1mNXKa8Ygs4znmb3ZM9+O9S8bsP7wLmys2DXLey/9KkyB9iGszfRjMv1tmMJ7d1W930s/znc+BaunP8Pmbe2YX8BzgANU1bWGU9VhVX0LNhb+BpMVWjHZ61vAHqr6q5L0M5pf2WLE7tm1t2Vp+7N7fSj7/pTPwqKOoyh7ej9tVelvze5/PjY2dGP9aTfWn34VG99TbkKmk6up+KF9TDeOZg0jFVie8mxCskgVNc/9yqgbHh5TBHRE5C3YROwXqnrMaNcH00uUTzliWw1OAD6oqqfN8LsciymsuoGlOo0+ZJ6NiJntP4lNgDbXhM+hYPKJfJ8diMgKbIJ4kqqeOaMvEwTThIjcjylH9lHV6hXqWY+IfApT9H1FVf9+pt9nshHbMnoPpjBfklrJD2YHIvJBzIXLg8A2k2URFARBMBnU4rNq0pzoBlNClI9Dtm85Dxs+G/LnfdnvH4aialJ4EbYicnUoTKaVyPcgCKYdMYftW2NWSX91iqqMZ7vMln/fBaGomr1k8vG7sj+/FYqqIAhmG7X4rLoK2xc6IZPrYMqI8vHZBPNFsC7bojpjiMg7sL33Q5h/iGDibMC2PYy6ZS+YVCLfgyCYCZqwvufW0S6cjWQOin+a/fxuhl9nqngYK6NfzPSLBGkyR9efxCK1baASGTAIgmDWMOZtgEEQjI/MAfePMD8fuZ+Ur6rq+/xUQRAEoxPbAIMgCIKxIiLHYdv+FlJxkv0hVZ20SMFBEASTRa3RAP9mEJHDgA9iUVU6MUd0P8G8/k80VGzwt0UrNpkcxBzvfh9zVhcEQRDMAFmQg+tqTPagqu43Fe8TBEEwTXRiMmk/FhDmq1oeJRgRuQ4LCFAL+6nqg6NfVhsi8iHM8XUtfEFVvzDZ7zIWRORAzIqyFopRl4Pgb5pQViUQkfcBX8YiUjyEOR3cBQvZeKyIHKyqT5fcIgieQVUvpxICOQiCYNJQ1eUz/Q5/pTRgEYBqoTRaZBAEwWwns8A9s8Zkm1J7f9lQ4/VjpZPa36Vz9EumjGZqf9+Fo18SBH8bxDbAKkRkHyxkYx1wMuZwcFhElmKhl/cBfqqqx87gawZBEARBEARBEARBEDwrCWVVFSLyMyyKyVmq+uaqcztgJrP1wB6qesskPPI+YDG2YrtiEu4XBEEQBEEQBEEQBMH4WI65clkJbDOzr/K3S2wDLCAincBR2Z/frD6vqneJyG+BI4FXA5OhrFoMtGc/YfYZBEEQBEEQBEEQBDPP4pl+gb9lQlk1kr2AFqAX2wqY4veYsuqASXpmD9De1dXN3Xffx+677wLALbfcXurkqM45Ozg85KZprk8Xd1Ndelt57/CAe6/BofRzhpzntzQ0uffy6B8adM/NbWxNHl8z0J08Xl9X795ryPkWrwC8vAdocJ4zhG/BWE8ddfV17LKbAHD7bcrwkH99Y73vBqB/KF1m47GfrK9Lf2d9yfd79W/YeYOmOr8L6hvqd97LL8ta38srL4Ahx+rUS+Nklz3fbS/D1NfX85zddwbg1lvuYGhoiOaGsnzx26VHo9PGPbzyAqhzPnRgMN1evevLntNUUscHnLz0nlLWXry89Nq417+BXy/L6hhAfX0dO2dt/47blKGStl+aL867DTjf2OSMB+C3l4GSPtn7fq/4y9p+7yS2fZx2XFYvved49bV/0G+T3nOa6xupr69Hdt0BAP3zXQwNDbn9Ttnzy/r3YacsWxuaS1KlccdkJyvLvsXrE71xx0jfr7k+LV8M4bdXr/55da+s7jc47bKs7Q8MDVJfX89uz9kJgNtu/YsviwBtJeXVPdiXPN4+jjLuc+S+srL0zrU6cl+ZbOfJMF4/XvZeXl1qr/fzZcNQOi+9XShl1dVL01DXkJT5ysZd7zvLxgQvn700ZXnp4bWL+nq/7nc4+b9+sNdN44297Y0tyeMbBvx7efWyVnkA/LzsLRkTmhoa2DVr93++9S/PfJsnp5XN67w60+L0iT2D6f4NoLGkzDxqrTNlMpSbz94YWiLXznPq2MoBPz5aatzfbvvltLW3QfirnFFiG2ABEXkr8G3gLlXd0bnmeOB/sKhAW0/CY28A9p6E+wRBEARBEARBEARBMDnciPmsDmaAcSxTPqvJt+GVRfrLzy2Y4ncJgiAIgiAIgiAIgiD4myO2AY4k31uWtgM2ctvStsl88E033caLX/IGHn3E3GBtvnR3WoZ9E0dvC8eaXt/EccvOTZLHlzal9W4rep9w77XaeU5Xf9r0dpu5ftRWz1T70a5VbpojFuycPH7hk7cmj3c0pbcNAqzr87YOOqanJVu05ja3J493D/hVqqWhiba2Vv501xUA7LXD8+nu7nGfv2nzPPdeD/U8lTxetr3Ao6MpbV5dth1hTX86L/sc0+PN2nyd7/3rViaPdzanm17ZVst1vV3J43Na0uUF0DeQfuc5zvPLzPG99rKhv5f29jYeePBGALbeam+6urrZZq6/Pf6B9U8mj5dZyS5qm+ueS+FtKQNodr7zsQ2rk8dbG/0twH2OqfyS9vlumlW965PHvS03m7TOce/10Pp0e/Ha+Po+3xK8szndx3Q2+UNFfV0dbW2t3HDn5QDss+OhdHf7z9is2W8vTw+sSx5/vCtdLpt3+Pda72yhWOmUMfjtosHZWlDW9u9d+1jyeFk/7uFtO2gu2Zre4WwtGRhOb3l5ZL2/vtXk1KVlnZvS2tbK726/CIDn7XIUPd09rBvwy3882zO7nTF557lbJY+XbUV6rC9d/g3OWLXBeTbAWqdPbinpL7w+bps5afliw6Cfl0ua0n3MPd2PJ4+v6k63L4D5rZ3J43NL2v6TPWtpa2/jrvv+CMAO2+xPd1e3uxXmOXOXufe6de39yeN7OGnKNlqu6E2PL13OVkOAXke+2bFzi+TxR/t82e5Rpy0t7kiXl1e/AVob07LK3p1+Xl679t7k8Vq3JwL0OjLEvJaOpMxXJsN09afr8ubtfj/6mNf3O2nWl/Q93navJ7vXJo/PLZGt9puT9lN91eo73TTe2Lv3wu2Sx69/6i73XrIgXS892apsO+9mjqxy/1p//rR4/gLuuPcPAOy87XOfGfMXtqT7EU+uBhh0+v7tOzZPHtd1D7v3Wuj0Y2V0O7K9N1Z1lchQntzlbcvfoi09pwV4WXN6fPvSU56Hn/Tc4n8vPIvddk/PN4PpI5RVI8lbUdlG/1yK9XuPcTA0NERXV+WWXV3dDJYoqzz/U129/mt116c7iZ7m9PHuHr9T8Z7jKau6G/17eUqZYn5U09uafo6Xpq6pRAioUVk1UKKsahpId6pdJfvnhxpGCkHd3T10d3W7HXTPYHoiZWnT3+L5Bymj3suzBv9e3c6g2usMaD3DvjDvlWWD4wqgVNBz6mvjoC+2e4Jm44BTL0qE1rG2l66ubrq6ukvbi5cvZcqq7uHafJd4k3KAQa/vcd5rqNH33eApq7rxlRJeXnoCZfuQP/n13tlr42WCVv2A45+kxF1fdRu3tu8/o6dk8t3tTGa8b+yu89tetzNpKeuTvXbpKavG0/bL+nEPT1k16L0wUN+Yfo7XLsryxVNWVY/HPVnZdzt+F2F8yipvTO5pSpdxmbKqu8a2502wwW/HgyX9hdfH9TQ4MkxJe3HlHqcsu5yxFaBlKN33NzX540tXz8j7dWd9v6es8soL/PrnpSnzwePJfd0l/oR6HGWVWy4lcqrfX6XlHq9+Aww3pttFb4Ofxnv+ZCqrmgdT/X73uJRV3SXr5m5eOmm8fh/8ftRrF01lslVjbfI7+GNvT1vtY1V3S21pypRVnqxS/vxK/nd39zxzbdugM1aUKKu8vr/Hme+VvVfbUO0qAc9f3niUVZ7c5c6FStxI9Tv9Va0yzHgW+oPJJ5RVI8mXe8qi8uXn/KWhcTCvqZ2XLNnjmb9fsmQP1nalVx4BtqrvSB5/mzM4AnyuIT0Q7k/a8uCqdl8psnmnM9g5wvyDg2lrCICV/emVmcMc6ymADqfq7jRvy+TxTRrT+QXw/Lq0dv43Q2nLnkX1/opRm+Pwr7FEOPxD9wO0FVYA2xubqWsc4jmtS5PXL633hZODmtOrKYsdYfqSIX/154HetNXJq1rTK1kANzSnV/I2qU8P6H0lDnC/07hp8vgZzoB254DfJJs70mkOa0g/A2AHZyF5riMcnNXqD5x/aUjXpea6RlrbKnmzy7yt6GnuYWmTbz23S8tmyeMDJXm5uC6d/+1Off1dr7/69oLmdBtr6EjX8YcoWfl2dqIvxtfwdHek+7GnSfd9jw75/eiylkXJ431OP/aRfn8V+9ON6fZSJuhu0dBJS1ulnz2wYxt663s5eDDdx/SWmETc3pTO583bJXn84v5H3Hu9tG379AnfSI0bBtPfv11D2qpvTomD9W2b032yV49/s+Fu914v6Uy6n2T3fr+O3elMcr1vPK5jJ/deb21L90v/2tVCS3Ol7HdsXkzvYC/zW/33uqr7geTx3VrT/T7AgwNrkscPakr3I4N1/oT5iaa0aHRPf/obD+nwRamHHZlgvwZ/tfwXPWmrlxOb0pYaD7b4SrybBtMWPEfPTcsd8+b59fXeobTl7N/hW7Te0t41ou2/YMEu9Lb2sqAuXf439qXHEICPLvi75PEf9KXz6znOGALQ5+RZZ4lTcq+/fAXp8fXqTt9ydmVb+t3aHYfRDSWyVa/zXu0lfc/R83dJHt97KC13/Xevbw2027x0u9y5roOmQtm/sXMX+ht6aSr5lgv602PyQc1+WV7XmO6wPQvJvTrS1igAu9Wl7/XL5rRV37xGX05+9UC6XSxZuKeb5v6hdH/hKdcPWZwuR4A3D6ctCUseawAAIABJREFUMe9clJZt19T5CvQrux9MHj9gUXrcAdiusyJ3HDlvJ3qbbez2lJU7tfl5+YAjX72oN91e71uQnlcAnL7uT8njy9p8OXlua3pM3r8+3fevrfPl1NXDaRluD6ftrWjw57tL+9Nt6fhNfbdTv16/sRwxrqAuwaQTpTCSfNTZWkQ8iXG7qmuDIAiCIAiCIAiCIAiCSSKUVSP5E+avqgVIL1XBIdnvP0zLGwVBEARBEARBEARBEPwNEcqqAqq6Drg4+/Md1edFZAfg8OzP86brvYIgCIIgCIIgCIIgCP5WCGXVxpwKDAMniMg7RKQOQEQ2B36I5dnPVPXmGXzHIAiCIAiCIAiCIAiCZyWhrKpCVa8DPpD9+Q3gfhG5EbgP2AdQ4O0z9HpBEARBEARBEARBEATPakJZlUBVvwS8ALgQ6AB2Ae4HPgPsq6pPzuDrBUEQBEEQBEEQBEEQPGvx47f+jaOqlwKXTtfzls+Hbx5TCVv6zWOGueQHfnjfw49KhzFu2NwPef+v5/Qlj2/3hu7k8U2/74ddfsF26TC6j65Ip7lh2A99el9rOlT1nunXBWCfRWl94R0rt0ge15JQxe/+3vOSx7c84Yrk8aPkIfdeZ9ydfv6Rvf7HvLpuOxrqKmGM/7NuWwbrerm2riF5/Yc/6Jdx7xW3J4/f98d0uezc74cJ/25bOvTtv5y2m5vm9r+/Nnn8tqF06N19W9IhzwG2fG5X8vhXD06HJH775/2QuHsPdySPv/WQR9w09e3pgKBNJxyfPL79289x7/XT4XRo9aNYR31Tpey/2jSPoYFWbhlIh4kGOHqfdKjkx+/odNNs9ZJ0Xt5xXvobn25e7N7r45/cOnl8/dnpmBOdr9zDvdd1n3w0eXzXff02NueLpyaP33T4l5LHl0s6rDzATbenw34vm7c2eXy7qz7j3uvKfT+ePP7GjqfcNI88VU99fWXN6M299Qz11LPHEen+tXGrBe69+u95Onm85/H09X9YkQ4HDfD3i9OJOrfx29h7/5h+t9Nfl07z2C/T7wuw6X7pNP2Pr0ke11sXJY8DnLLHY8njP7/eD9P+z7ul8//xv6Tb5aV96b4aYPllpyePdxzwMZoL41J7XSONdYOc9ip/rHj7T9Nhx0/fOh2KHuCeu9J9/OK2dN+7YFm6rwD4zh3pPDtpMP39yzZJlxfA40+k+6vdT/TDxLf9IB1a/g27PJA8/tCffRlqZ0cm6exL172GdFR5AD51yrbJ4z//pL+uuai+g8aBSt///IEOBgYaeen26f79u/dt6d7rXf+Sbnv3fC6d5lO7ptsEwEpNl8vQUDoUPMBmO6dlyNuu700eP+kzO7n3+t5H09+/sD9dAEcf/YR7r2t/kS7/A94y6Kb5+fdbk8df9tL0cxp+taN7r86B9DsfMP9J6toqZf+6jqcYru/l3zf4Y/g5i9Jj9ZwtfBnm8j+ly//xlvS492id379/6Oh0f7Htz9OyzbwB/14v/tVrkscXvviHbpo9tutJHj/94fS3bDXk98kv3iFdx17ani6v5i38sfI9F2+ePP6RpvT7Amy+XyUvP7/fKui1a1fenK57mx+Wbl8Ad1+QltN3+c1GbpcBGLrmIvdeV52a7sdOn+9/ywWr0mPvCYel+5jeh/3xbe0j6e9fespeyePXvfcm9177fXnn5PEXn3G5m+ZFd8pGx7akJXFlMN2EZVUQBEEQBEEQBEEQBEEwawhlVRAEQRAEQRAEQRAEQTBrCGVVEARBEARBEARBEARBMGsIZVUQBEEQBEEQBEEQBEEwawhlVRAEQRAEQRAEQRAEQTBrqBseLglxEkwHNwB733LTnzn26BO56+HrANhhi/1Yih/17a6udBSttoZ0ZAiAJ7vTEa5aGtNRRloa0scBVvWsrylNc4MfjW/IqYMLW/zIKP1D6WguvUP9yeM9A34Eih060xGWdF06ItTm7X5Erke70hFThvHb2aLWubS1t3Lz/VcBsMeyg+ju6uHBdelIQks6/AhHXvn3DaUjLA0O+xFbvHt1DaQj/JQ9Z3VPOiLbZh1+XjbVp6O5zG1MRxbUtenyAvD6ubZGv7149bKhPq3jHxzy83K7znTEmnvWP0Z7exsPPn4zAFst2YOurm66S+rrvJb09w84bQL8drm+Px3lpb7Oj/w0pykdGae+Lp0vZffy6l/ZuLRTR7q9XvP0Xcnj81vSkSABegbT/cVOnemonhuG/Lr/eG86Itv8Jv/5D3c9RXt7Gw89fgsAWy7Zna6ubrfuLSjpE1udMn5oQzoa4bzmdD0CWNeXjj7UN+hHatukLR0pr84p/7L6uqglHb30qb51yeOrutPjEcD81nT+e88AWNufjog3nm/ZoSMdLeq2tQ/Q3t7G/Y9ZRKNlm+1JV1c3C1v8SKAPrEtHJNtqjh8NsbMhHWHp4e50NMaysdpjv87lyeM3bkhH6QO/jW/S7H//Q93purxdR7p/faTHjzi5ujc9Jm3alpa71vT5UUW37khHFnywy48GODA0mGz7c5126bVJ8Musq9/vrzyeM39Z8nj3kD8mtdWnx9FbV9+fPL6k3Zdhep0+2Wt7ZXjtsky2fbwr3Y8vn5OOkPtIl1/HvPzfZu4S2tpbuXHF7wHYe/khdHf1uPITlI8jHneuTUcK9GRrb2wHf6zeojktw/1lgx+lcIu2dITS29eko/SVse+CdIRQLXl+Z2O6T/Rky3vX+9Ez5zWny6Vn0G8v2y3cgivv/Q0AB2/7Anq6TQ5b3Z/uY7zxCPw6tklruh8dKpmLtNSn20XZ/KXb+c45jX5d8njMmT8taE3X16d60vIA+PKQJ1sBHLVw142OffqXX2Cb52wHcCOwj5s4mFLCsioIgiAIgiAIgiAIgiCYNYSyKgiCIAiCIAiCIAiCIJg1hLIqCIIgCIIgCIIgCIIgmDWEsioIgiAIgiAIgiAIgiCYNYSyKgiCIAiCIAiCIAiCIJg11B72JZgShoaHR0Ss6xnoo77Jj37iRjcriQboRcXyIoI91p2OzADQ3tSSfr4TXe1pJ3ogQGdzOjJHWdQGj+b6dJUeqPejNT3Yk47Y40U/KYug50XlKYui1TvYT/1gY+HvAXoH+92oc2XR+LxzDU6ktrIoVl5dai2pYx7et8wtiRjSP5x+tx2b05GvVrf50ZoeXp+OIrWhJFqSF0XMi75SFnVurhORq29ogMZCBKC+oQH6hgZKI3I91Z2OgDKn2c9LL43XjsuiSHl12Ys+018SJdHre8q4vv/e5HEvyo0X8Q/8SIWP9aUjQnkRKgGe7EpHW22b47eXhrr6EW0z/7vbyZfhFr9PXNm9JnncqxdedFiAVqcfL4vIVWsEwd0XLnfv1VSXzudNm9IR/O6p86M1eZG/5jmRnwBWrF+ZPN47kK5LZVFFr++7J3l8fksHLYV0LY3NDDUOsqrPHyu9/B/PmOAd96KxAXQ2pfuxP3enoxOXRWta3pmOruZFpAKoI/39Xtsvi67m5uVgOl/KIrTqmnQk2rKoc32DAzQW2kbf4AB9gwM8tiEtd23a7keHrnfyZdVgui6VjRVP96fTrFiXbhMAW3amo7t5bd+LIAawsCkd+Wtlb7p/KysXL//LysVry493p8cEr68EX4Ztb2ihtb4y9rbVt1DXMMzqkoiTnjzmRXsF/1sWNKfzuKztrdiQLv8tmxcmj5eN7asa03VsUWtJhNa+dES8bRvS7eLmgRXuvbzo4I1t6XGnLNLz+v70uOdFRwa4v5CX929YSVeX3cOTk8vw+jGvT/RkQYCd5qWjIK9yohSCLytu3pqOEvlojz+v9NqSF31+YNCfv7Q68nhZVNVfPnnLRsc+POBfH0wfYVkVBEEQBEEQBEEQBEEQzBpCWRUEQRAEQRAEQRAEQRDMGkJZFQRBEARBEARBEARBEMwaQlkVBEEQBEEQBEEQBEEQzBpCWRUEQRAEQRAEQRAEQRDMGkJZFQRBEARBEARBEARBEMwa/PjowbTS0tDEso5KKOdlHYt5coMfYtQLV7qhJIS1F8bZC1Xd1OBXj2bnnBcWtCxUshc+vizsdO9Q+p3nN6XDlT7a64dLnd+aTuOFt10/4Ifk9cplcZsfdrqjoZXW5kpI8EXNc+kZbGbTlnSav6x5yL2XFyp5sRP2uixMeXtDS/L4sPMMgKUt6XC1XghzLxw1QEdjOkz6ff3psuxw3hegpTEdktmrxwBLW9MhmR8YeiJ5fHWvH953sC2dZ/XUjQg7nv+927yt3Xvd351+fllI3uVz02HivfD1ZW1v284lyeOtTmjtsjL28r+hJOyzV2e9MMZbzEmXI8D6wXRb7nTq3gMb0nkPMKcl3cc9suFpN40XWnyTtjnJ41747jK89loWct17L+84wOqedP1vb0q3ywUN7e69HupL59lcJ81mTphsgEd60ve6t+txN83ClnRo99Wkv3GLjk3cey1tnp88/pcNj4wom+HhYYaHh2msT4dPB7+9lIUj98Y3r73UN6THMPDbuNdfePkIsLIn3S+sGFiZPA4wrzld/nPq/b7fY3lnuk+8Z91jyeMtDekxBPzvLyvL6nu2NDQx2DDgjuFeiHjwxzdP7ir7ls6GdN83NDzkpvH6uM7m9L3K+vcn+ta651LsNX8b99zShnT9u2r9vW6a/qF0u+gdSI87Xt4DbNWxKHn8gQ1P0D5cKZuHup6kq6ub9ka/Hj/Rk84XT04F6GxK5/9Tfen+okyG8OT0lf3p92oqqfur+9L96KKWuW6azeek+/gru1Ykj69xxiOAvRZt556rFS/PFrT6fV9zoc40NzYx2Gj9x9re9Pju9QkA+2+yQ/L4X9Y/nDy+sOS9Hu1Jy9YLmv00Q06f/HjP6uTxVd3r3Xt5cuojA+n+xZtvgd8uPHkEYJPmjeWu5vpQk8wGwrIqCIIgCIIgCIIgCIIgmDWEsioIgiAIgiAIgiAIgiCYNYSyKgiCIAiCIAiCIAiCIJg1hLIqCIIgCIIgCIIgCIIgmDWEsioIgiAIgiAIgiAIgiCYNYSb+1lC/9DAiIh1j/auog0/moYXgaKn3o8MUhYBJoUXyQVgcMiPDJOiob4kupcTZaVv0I9I5kVgGRhOR3LZqjMdlQVgQ0l0v+T1/f71XvSf+Y3piEwA92x4jHYKkWG6LTLMwfPSUT4ea/EjG3pRdg7pTEc/uXj17e69dE06msj8Fv9bFjelo7l4UTvmNPlRIr0Igl55edEDwY9gt2HQj7C0biDdxnbsXJo8fvPqFe69/rzuweTxurq6EXmT/72yrySCnhOdZP8F27tp7uxKR7gadCI87TBnc/deLfXptudFXespiThZR7pebNXmt9c71z2SvpdTx+Y1+lHn7lybvtfBm+yUPP5IvR/Zz4vYs+cCP1pV//AgrW2Veru8Ywk99T085kTlWd6RjpYDcO/6dHQ7L8JUWSQdr08ui27mRZ3z+qRN6/22f68TXe3h/qeSx8uiFXlROssitHpRMhe2pqM0PtXrR+NrddpL39AAjYXv7B8aoG9ogHW9fkQuLxpgY0N51LkUXtsvi2LlReH1InTuMWeZe68b19yXPL6kLR09EeDx7nSEqc3npt/59pI67tHqyElrnEhd4Nf9/pKoqt39fdBfaRtd/b109fcy4ESjWz7Hb/ue3LPbnPRYdeWau9x73b3+0eRxr68GWNKeLjN3rOjy+1FvrG6sS9fxdU5EV4A96tN5dk1JNEIvitjclvQ4UpYvXt+3vq+Hoca6EX939fUw14msBjA86Mv2tT7/6d50RDYveiD4/YUXWdC7HgAnuN3afr+NHdSWjpB8oRMduYwHutJpvGiEQ94LAy9ZvEfy+M1dftTuzsKY3NnYQkOj3b/Niba6yikvgLsd2c6b781p9MddL4Jfd0nd8+SLJ53olV5kcvCjRHrzRy9yJ0CHU5e9PIb09/c7fWswvYRlVRAEQRAEQRAEQRAEQTBrCGVVEARBEARBEARBEARBMGsIZVUQBEEQBEEQBEEQBEEwawhlVRAEQRAEQRAEQRAEQTBrCGVVEARBEARBEARBEARBMGsIZVUQBEEQBEEQBEEQBEEwa0jHQQ6mnYGhIVZ1V0LArupeR+9wOvQoQJMTQrwslOfgUDqUrHd8fZ8fErijKR2udH5LOoSzFyoXoN4J/ds36Id97upPhxZfumBh8vhdToh6gNbGdCjTZU6oaC98NvjvvLJvjZumpaGJ5kKY2eaGJgYbBrhm3b3J69f1+aHN5zSnw9Le1JP+/uZ6vwtoa03nS19JOO4/PH1n8ni/ky9P9fgh371w6MNOGGEvhC5AnRPC3AuVW3a/29Y8kH6vYT+8ce9A+ltaGptGhKNvbmhkoKGxNF9aGtP9wnWr73HTDDnv5r1zR6Mfwvrh7nTYcS/kdxluuQz45eKFdve+xQvtDH7I9VvWp8vYezZAj1Nf71zv9z0tDU201Vfa7KO9q+ju6S7t+zzanT7Zq0tlz6h3ysVrewDbd26ePP5Qz1PJ4796+jb3XgtaOpPHvRDa6zc86d7LC8f+ZHc6tDb4YdcHGtPlX5aX965/3D3XWEjXNzhA3+DAiP6gGq+9tJb0414/1t2Uzsuy/v2JDelxzKt7d2x42L2X17+vKemTt+pYlDz+sydvSh73xkOA21c9mDy+Sduc5PHOZr9P9GSo7n6/T6yrqxtRnvnfc1rS7/xgSR1vc2SYG4fS/di6Xl+G8OqYdxz8snx0w6rkcU9+BFg/mJY7Pdl2bV+Xe6//akw/f32/L9s2Oe3PyzNvPAZY2ZtuL8PZv+q/H+/yZUuvjHeYt9RNs24g/c6uzF+SL55sP6+pveZ7eeNonTMXAPjhEzckj3t9z7zW9PuWPefuNY8mj5e1/Tt60vLFqpI5z/q6Sr/wWNdqurqsnDZvX5C8fk6T3495/fuK/2fvXmMkS+/7vv/q1rfpmdnZXXJ3Se5yKVEsmKbspaQYchQHkZUgtmwYgUEEChAFjhFYiRMj1qvIUfwmcJwA8SvZcGAbThTIMJTASiJHBoUApmUhii1BpEiRklwUL3u/z7W769JVdU5edPdM1czz+/c+D89Wn535fgbEsk73uT2389TT1f2783Zy+/Wen1u692LR+4RZle77rr/eDvqrnY+a8nfzWkkaL9LvEd80Y5KU7vuVmQtgs/hkFQAAAAAAAFqDxSoAAAAAAAC0BotVAAAAAAAAaA0WqwAAAAAAANAaLFYBAAAAAACgNUgDbIl+t6trKyk013Yva3zkUxP6Jg2w1/HrjxOT1uVSXqIEjGtb6bSmO/P0Ne/0fGJK11yzS5iRpE8/9mxy+2O9dGqGu3dJqkzC1dWtdMqJS8qSfEphZDyfSfN7ZTCZzzSez8LkMcem7h2nE0Cic1wxKS/bQV3emqaTnK5sm8SYIHFyx6TsuPTGq/30OSTptmmXH9t7wu7jyuzJnSvJ7a7tS9JTO+nUuRcP31Znca8vTxbHmiyOw/SVZ3bSiTEueUiSbk7TyTQuSefNsU9McWllLhHNnUPyyWNRykuuWzOfLubGy9xUGslf852Zbxcf239S2yt1vd3tq+oOdGSSlF4Z+0Swj5q2/MoivU+UyPVd+08nt788fsfuM67SY992N92PDyqfSPbhravJ7a5dfuLyU/ZYLhErGvvc88L1/SiF17Wxbqej3b177enpvcc00Y5eOfR17MIYn9hJJ9hJPtnQpYu5pDBJ2hmk93Hl5eYpku8vUarr0SLdL9z9u0QoyScFuuStJ7fTdS9Jh+a6ojlMv9tLJsFe3UqnmEXpYq78n9hOl8tjUVKaS2g1z3ZJenucfva4OeQnLvn++qF+em75L279fnJ7lCDnksei/uLSU91zL5oPHpn5zaXBjvZWUkovDXbUGdThs+LZ/XQS5qe206nVkvQb828nt/e66TEpev/gnu+36nS7+PBuegyXpIN5ekyOxgs3Xruk5Si90s37XNL2R/bSKeOS9IZ5JkWJm4+bpG2XdhslLbs5lBv366WfW7m5fVSWB0GbTZ4/mNs9bdIQ3dy65D1SNF48tfvgPH0QzMWxOXyyCgAAAAAAAK3BYhUAAAAAAABag8UqAAAAAAAAtAaLVQAAAAAAAGgNFqsAAAAAAADQGvyZ+5ZYVpVur6St3J4eaRCkFjhR6t1j2+kEGJeAEaU2uHQGl4YXpwKlEx1c6pvkU7Feqn1alTMx1/zq4fXk9ij9xSUb3jGpNNJJYlBv2V97PVvObdKFO4ckVd10nRXVsUn5iJLaXNm4lJFZ16cl5aarRQl6rvxfM3UsSbWJ3ro0SCccuVQWSRov81Ii3bklnxjj0nokn5ri+muU4Hdjkk5L2jfpWtGY5BKWouSrj15KJ/m8dPB2cnvUxt0Q6645KmOXsORSxyTp9aMb2qvvff2No5sajye2H4UpVia90o29UcLQ6M5r9mvOrU46FcqlMUapc79/+HrWPq8c+QQ9d59hSqWpZ5eWFSVxuvKv6kp7K+Pf9emBxtNJWC7Ou5M79msuqXBgritq425ccsmCUTquK/9oHL1uxp5rO+kEuWjscePCW+Nbye1RIpZL3or26XW6a+3p7PXt43R/iecd6bp89Sj9fHNJx5Lvr8dBsqFL2HJpvy+O02O1JH27fivrWBGXeujqS/Lpcq69Ts33S76PLetq7RrOXkdpsy7Z8v+9nU5JjPZx9+iex9E+riyj555LVX19fMPukzvGRKlv7lnpxgTXjyR//9F7ntXz1HV997W7l2gcc23MjRfR+yrXxvtmfJGkfTMfjpJQHfd8ce8fovRM9xyN2vg7kwef4yWJg2gen6wCAAAAAABAa7BYBQAAAAAAgNZgsQoAAAAAAACtwWIVAAAAAAAAWoPFKgAAAAAAALQGi1UAAAAAAABoDZ/hiI3qdbu6sn0vTvjK9p5ev/GO/X4XP1oFMe0uYrUycaFRXOrTe9eS211c617Px4TfmafjR6PY51vTdLyyi3Hd7qejTyXpse10vLGLyY64+PrIsqrWYlbPXj++m46p3+r6butip22EchCTfmk7HUlbBbHPUxNX+9ggXcZR9OxTu48lt3/r9pvJ7Z/Y/bA91leOX0xud1G5km/Lt00Zf2jvqj2Wi2Pf6Q20sxLLu9MbqOotwn58fZZul0dzH+1tY+JNTH3U97uddBuPIoFzr+soiCnvmfO7qOqoLN01u5hsV16Sj+N+6cDHtG/3Bmt9c9DtadDt2bE6GhOXJmJ5auryD159zh7rtWk6qvtgPrH73JgeJre78eKj+0/YY7lxbN9Eu0f1MjB1/Ph2enyVpMk8XWZfv/V6cvtH9h+3x7ppyuWjl57Q7s69+3ly54om1ZbmQVR2SYy2izB3bena7r491g3zTHRjZRRf/rG9dP1/8yA9vku+v7rnrnvuSb7NuO1PX0rPeSTpjaMbye3PXPLtYlbNtbUyL9nqD7TsL9Zi7Vft9HzkvDv/xy+nn4nPbfu+9+Xli8nt0TiaO++J5h1XtvaS2w+O02OPmwtL0mNb6XlHNI597+MfT25/e/ZgrL0Uz2E+Yur/+uxgrS1v9fpa9Pq6PNi1x5os02PS3MwtJOnyVvp4i2V6HHlqLz3nkqRDM79w8w73bJekg0W6/N1zV5Iu9dNj/6GZK2wFff/6ND2OuedL9Nx9Zic9LrxzfMfuU68cr9fp3p3TuPcp0dzKjQuLOl3HXTNPkvz8/XDp+4vj5mlu/ihJbxzdTG7/nivPJLff7KafrdH5V99n3y/qy7hYfLIKAAAAAAAArcFiFQAAAAAAAFqDxSoAAAAAAAC0BotVAAAAAAAAaA0WqwAAAAAAANAapAG2xFPdPf3k/gt3X//k/gv6W/Ov2O9/c5xOTYhSI1w6wvdcTictHC59Itd+L52aMa3S5//QIJ2UJZ2k4iTPYdI/JOmJrXSS07uzdALHJ/aessd66/hWcrtLuNnr+5QT54kgeWrQ62t3915qy2O7+9que3phP51K89WjV7LP/8LVTyS3/4t3R3afZ/efTG4/WszsPj/02KeS2794+GJyu0uRkqQbJvXuE1fTdXlzkU4Qk6SBSVD86L5PvnJt/FuHbyW3uwQ3Sfrcle9Nbv/12Rva2b13no/vfVjTzlRP9v11vb1Il8vXbr5k97m2kz7e5UE6GeapbZ8K9Mrk3eT2P3rlu5Pbf3v8mj2WS7Z0aZ+S9AO7H0tud6mi17Z8WbpknBcP0wl+UfLUD++l+9gvmuuSTpJ8VhPhru3sa6fqa2z62HM76T4pSTcW6WQcN45GSZgulSoa+1zi6243XWbX5z5t9Qce+67k9i/f8W3ccYlwUVKce47+ySfT/fiXr3/NHuuTJsnoYDFZS2xa1Est6qX2B/6598NX0uPrL9/8HbvPs3vpNvPcVjqp7KvjV+2xbHqnSQR7ctc/94/rdIpZlDrn0sKe3U3f4zcO3rDHcs+e730s/dyNHJp0OdePJenx7X3trtT11cGutgYdm1T3eDCOOU8M0vOOT/f9+P7mbjrdrLsbpDPP0+O1u/9P7qf7hCS9Pk0nG/57T31fcvurC5+6FiWfOS51zyVxumer5FOAn9y+ot2VtOUnti9rbznQ0cLPuV2i8t6OT5wcdNJt3CUrfu9e+tkqSS8fp+vlNaW3R+nM/+owPSdwyXqSNNxOH++fHqefr5+9+rw91j97Kz1e/2tPfTK5PXov5NLU3XsUSRr377WLva0ddRYnx3Bpq59+7Fl7rNuL9P3/2cufTm7/wsQ/Q5/dTSflfWucnvNKPkHvuf0PJbe7PiH55+6f2Hk+uf2fBsnoV3rpOcxrs3R7laT9Sw8+e6N5AjaHT1YBAAAAAACgNVisAgAAAAAAQGuwWAUAAAAAAIDWYLEKAAAAAAAArcFiFQAAAAAAAFqDNMCWuF7P9HPzb+ovnb7+ufk3wzS8p/fSqRm3jn2K1r9+OZ3W9Su304ly06cbAAAgAElEQVRwz+/5NI+3ZukEPZewcytIars+TSdg3Or4ff6wSfp45SidVHbTJGVJPn3oyZ10ktE7k9v2WK5entq6avfZ6va1s5IM86HtK5outzSapJOMrg7SiR2SNNxLp+y8PLuePneQHrndHSS33659uplLjHHpM66MJem1w/Q1D8w1R23fJflEaU2f2EmnmbzRN0mcQTLJ15fpNrPb3dLOSlrabndLnW6lN+e+jbn0l06QfLTbS6doucRDl/gn+ft8eZ4eE6JUHJfW9KmrH7H77HfS53dpp6uJaw9cm0nLmpv2sh0k6P3zyYtZ1yVJN2eHmvXunevW7Ejj2cQmwr0bJOhd7afHhVfn6X607Pv0Spds6ZL9JOn1SbrvuwTBWzPfX5/eSqeVuWSe/SB1zqWrvTv1KWKXt9JJQp9UuoyjOn756J3k9u/Z/4h2Vp7xT/SvaDrY0suL9PdL0q0qPV5d2/aJZC8epZMtXRpgVC9ujLmynS6XqO+/Ojbje5C+5OrFjVcf3vXP3bfNc9ylE79p5jySb+PvTHwbk6S9lb5/87TvP2PS+MZL/6yamgS7aZXe/kuHX7fHujlLz5Wev+Tngy5Bb9+kikb30jV9acv8bP3tY/+sdH2/08lPCYz6eK4787Hm83rl9UST+SRMrnVJ17N+ur1Kfm7rni+/Z+ackp9fTRfpun/TpGxL0rJKP18+ZRL/JOkbx+k+7lJtXztOz9Mk6Zn99Nj30jQ99v5bl9LvnSTpH9/8anL7lS0/T+/2781huurcnQe590/Xj/1zf8fM7X7hdjoh9rpJHJSk56+ky9+9F5CkJ3bSY/yLB+nnzndfedoeq2v65c8fpO9luvRt/4euppMdvxI891P34md82CQ+WQUAAAAAAIDWYLEKAAAAAAAArcFiFQAAAAAAAFqDxSoAAAAAAAC0BotVAAAAAAAAaA0WqwAAAAAAANAaPmsdG7ca495VR7935/X39L2rxnMfCfy17XQsrdvnG4c+xtZF4rpo6dHha/ZYLqp4Xi/sPq/O0rHXLsL7pQMfB/74Tnqf8SJdLu7eI79169v2a7v9Le1275Xb29PbmkwnNj7eRW5L0u3tcXK7i6uNYsK/cSdd/xMTVSz5tuTijY8WU3usXjfdLmpT/sdL314cFxUsSf/qKN3/Lps47qhevnr4SnL7remR9vbuHe+LN7+p8Xii4yCS95KJnXbx8ZL07dtvJbd/9PITye23Z+l2JEmLapnc7uLbX7yTjjCWpD947bnk9oNFOnJckv63619Obrexz1Mf1fxqJz2OuHs8PPbt9eYkHfketbFlXUnze+18PJ9pPJ9ptkjX/+1jXy/pFuYj1w+OfRm7PlYFQc4ujtyNPbv9dOS2JL0yTdeLO78bqyXpTtCWneUgfS9/79ZvJbcfV37smc7TY99Xly9pb36v7//OnZc1Hk/CMfl3J+kxKTr/xJz//3knHbnu2r7ko8UHvfRU8qUj/9x147Vre5J0NE/3v465rui5X5nn69duvpzcfjUYX7cHPtrdqU//3f/6d2+me7Lrx5K/f/esdnMLyfdLVy6StDdIj/0f3klv/9Zh+nkkSc/sXUtu/9/f+k27jxONvc6Tu1eS2914GfUX18b3t3bUW/ZXvm+u2XKuW/Mjeyx3nqjvR2N8SjS3c88k1/YO5v7crl5+/9j3128evGm/lvL60Q37tR3Txt8ep+dwv2TGHUk6MnPe6H3CVufe+Q+PJxqfU09Rf33tKP2sdG0vGkfend5JbnflJfnnu3tWRG38qe3Hktt/+86Lye3RvfzGQfo9V9TG3xjffGDbPOhf2Bw+WQUAAAAAAIDWYLEKAAAAAAAArcFiFQAAAAAAAFqDxSoAAAAAAAC0BotVAAAAAAAAaA3SAFtiUS/19uxeEsPbszs28U+SZiYtrA7Smt6a3Epud6kRLuFF8slX2710Ko7bLvmkiyoI3btjUrE+tHPV72S4xBRXLtt9fy8ugWQn2OfW9EjH3XtlcHt6pPHUp4O49BXJJ3O4ZL15kGTj9nEpSpJP2nDpLzen6XYkSZ3MxMvoXlzC1ltH6T4h+Xp2qXcu9UuSPnYpnbo3Xy7W+tmlwbY6g0qzILHE1b9LypKknUE6zeW1g3SSzKWtdOKg5Ovftf0oyebd43T6TJRw5FKRXOpbdC8usWbeSZ//sZ1L9ljvjtP3EvXXfqe31jf63ZPX7h63gke2Tf/p5/9MytVZlHzlUipdvUTPlxuz9Dg2NYlUrh6j87hjSb4s3RgTJfgtzNf2+ttrY8lef1vqV2EZR8mWjhvHXblE54/KLHnuIK3J1dlxcH5X/i6p7PJ2OrlV8nMYl2wYJavZ9hIk1B4eT1X1O2uvx0Ha6B96/Hn7td++8WJyu3tWRsmG7hm+ZcpF8vf/4kE6CdYlh0p+7Hf1Eh3LtfEbZp4kSa8f+hS5XK6NdzqdtefC2Wv3DJF8v7y268e+Q9Nm3dwqShR27y3csaK5nUsAj/ZxKZVuTJgGfc+9f3JzvihR1u3jkskl6VZ1r17m1fLuPbgkVDevl/z47sorSs12fT+aw9jrMnUclaW7TzfnjOYQTjQmV/WD11wQ/o73AZ+sAgAAAAAAQGuwWAUAAAAAAIDWYLEKAAAAAAAArcFiFQAAAAAAAFqDxSoAAAAAAAC0BotVAAAAAAAAaA2fRYuNqutay5UI1mW11LUdH3367iQdcRvF+LpYUhev66KdJR+Xet1c16Drm5qLRY0itA9NxHNlckajY7lI5if3riS3vzO+bY/lzuPKK+KigqM67gcR6ilR5Lvfx9/LsYkEjvbx0vef244labZMl5mLCpZ8HLorf1dfkvSNW28kt/e6XS1Xmt/B8UTj40lYXraNBfu4MnORwEdBhLqLC3YRzktzDkl68+hmcnvUjl30sos2d/Htko9wd+NIFLvsrnnHlIt0Mi7ube3efX15a1e9hY/wdjHdkm9/U1P3lwY79lizKt32o3px/e/abvo5djj3bcz1sWgcd1wce9QuFlW6LF0fWyz9dc2rdHu9Mxtr0avXXo9nk/BZ4e4/qhd3za6Mo3HExaG7frG/F7Qx+6zw47gbr6Ox13HzDnd+1yaiY0XXVdf12v2cvXbj6K35kT2Wa2NONCa75170rMyNto/a2OuHN7KOFXFz2Ki/uLHfPSvcs1XyY+9kcazOorf2OjpOxM2FJamjdL24Z3jJ881x5ShJXdNcwnHMjIuu3HLbpOTbuHuGSX5Mfu3wut3n0qV0W9odpMdXN+eJzr9QertrE5Kvs+g9x9xcm3tfdRC0sb2t9PNiUKeP5cYqKX6+O6k5ZEEzwvuAT1YBAAAAAACgNVisAgAAAAAAQGuwWAUAAAAAAIDWYLEKAAAAAAAArcFiFQAAAAAAAFqDNMCW6HQ66q0kYfS6Pd06TifrSUGST0HqXJTa4bgkqWOTShOlSbiEoSj5yd2n28elnkk+USJKmnBcipu7R0k6WE6S27d76VQgl6IkBffpNgfl4uqsJGXFpbxECUMuFcmljNyYHNhjuTTK6F5cGqRLGYnq+PYsneRU1fVa/zt7HaXi+JSVdDuSfPlf20un3LhUT8knSblUHpc8JPlrjurFt9m8tCLpJH0xxdXlTlDH40W6XVzZSif/nJ1/dcxaVEstqmWYluW4cr49Tbe9ScenT7lx1KUVSb7+n9i5nNwetVdX/64dD4L+4uo4Stzc7qWP59p+ybOi1+2uPcfOXkfPSvesds8KyV+zq+Molcz1C5d6dz0Yk126WpRU55LPStLN3Dhq5zZLn47snmNR4ub917DV62vR69vkr2/dftMex53H9aO9vh+TJ3OTruYi3OTv36UURuObO1bR3DZ7D88lsZYklLokyHAf08eiOZwrM9fGLm/vJrdLfrx2SXnRfGy3nz7PUZAQm8v1b8k/R1x6Y5SM7uol6vurz6tBt3f3tZsrROXinm/uWbEXPMPPa4Mpbp7u2lj03HXJgq6+onniYp7ulzvB/aO9+GQVAAAAAAAAWoPFKgAAAAAAALQGi1UAAAAAAABoDRarAAAAAAAA0BosVgEAAAAAAKA1SANsiXm11Lvj23dfvzu+rTpIBdrfSidNTIOkOJeYNE0HMOixnUv2WC41w6UFRak8LkEwShE7NAkYNvVNQZKNSfNoUnT/7tpc6lyUiuNSM0qSBV0qlUv/kHwq1o7Zx6U7ST5l5zNXn0tu/9Lxt+yx3PmjRLJ3x+lEPFfGl4L26uq4qqu1NJ/7X6dEZea4hK1uZuqa5Pu4SxGL0sVc+lC0j+PuJWqvi2VekpMb9yTfX6KEnaP5VPW8s/Z6PJ/axJyo77uELXcs1yckn8oTJdXZlM5ZOkkpGnfdvbi2d2TGSsnfZ5Tg5+rMpSFGiWCuzC5v7Wp3617739/aVW8h3TLpjZHo/FdM6p5LmFoGx3KJaFvm+RKNZS4t6kO7V+0+buxz41vUXp2b03R7jRLsKtOWu8G8w6VB1sv0saLkK/c1N+e7fRzMR8yxznsupc+fHhNK5lyuLgdB6tuiSvfxKji9u2YnSjfrdtInmi3m6i36a69ni3l4Ly6JNnomuXtxKY1P9NPJrVKQEmnaePTcc/01mnfYJFQzvhcl25lxLLoul/Ts3tdI0m733vu31XHgjumX7r2A5Md+117cPEmSJi4ZPXifkJv0HZVl36TwunE0mg/Nzdd2guTc1Njv2h02i09WAQAAAAAAoDVYrAIAAAAAAEBrsFgFAAAAAACA1mCxCgAAAAAAAK3BYhUAAAAAAABag8UqAAAAAAAAtEZeRiveNx111iI9+92eDky0tCRNTYxsFOXporpdVPV47pvHkYmQvrS1k9wexZW6+Phlx0clR8dL2TGR45Ivl6LoVVP+x0H0a268cxTH7b7m4lddRH10/ijy3cVbu8jzKA7cRZt/7fbLye0uol7yscu57SjiYtUl3y+XVbUW/dw5/RdHOOeVsST1OunjXZ8cJLdH8cZHJkbZtfEoCnzRTV+zGxMkH5XtItejCGvXxl3bc9HK0XmuT9NlLJ3U/2qfPXu9lKljXyy27+8NtpPbozhsV5ZHwTPJRWW7Pu7qUfLjlasXF98tSZN5+ljR2OOi1V2ZRfHWriyXdbXWl6u60rKudHl71x7rziw/2tzFjruY9m5QLq6cXVlG9eLK7KU7b9t93Lg4Ce4/165px1EZb/XSY1y0z6DXV3dxb7/pYq7pYl4UlW6fyWbojZ7hjisXKb9fuj4h+WdlSbm4Z080H3P979b0KLk9KhfHzbvcs12SFlX+/btxzHl7fNt+zV3bzelhcvuWGV+kYM5tnsfRPo/tXEpud/MUKf/9SzSOufEymqdPV+7lrN9LvoyjZ6U7v+tjB7OJPZbre+5ZIfkxzo3VUVlG9Z+8LvnrKhkvrmzvPbAtmidgc6gFAAAAAAAAtAaLVQAAAAAAAGgNFqsAAAAAAADQGixWAQAAAAAAoDVYrAIAAAAAAEBrkAbYEt1OZy21aW+wre09nzw1WaTTzVzKhRQnjeSKEo6S26MEO7PPbs+nrMzN4Vwi18f3P2SP9a07b2UdaztInXOJJWGCYK+3ljJ29tolj0VJPi6ZxtXX4zv79liujblEKsnfp7uum/N0koyUnwwSJS+VJINc3kqnArlyiZJ3XFpUKgW03+1p36TSSNLNSbrMHt+9bPe5berMXVfUXl263DtH6SSheeUTJ5fH6TKLzh8lSTXx/ZJs+YeJi/30z36iMXnQ62uwUgdnr0tSgVzCVJTs6Lh2ESeBugS//CTOgfmaSx2LuLp0/ViSOnW6zFxaUpRe6dyYHGjaWay9Hk8m5ySBpss4Gitdm6nMPtHzzZ3ftZd64a/LtdeS/uqSx+J0tXSduVRLN+5FontZVMu1azh77fpryZjsRP3IlYtLlZR8G3MpzC7NWpK65j6rOn1dl4J7d328W/mf07t5hOsXrh9Fzp7z97+OktJcWUaJzi7Fzd2jSwaX8tN2d7f8/N0lJ5c8qw6O0+l2UarpwIxXrrziNEAzvr7H+eBWr6/F6Wt3nmj+2jV9z/Uxd+9SkFLZ8+f/xNWnktvfGt9Kbo+eL25ccvOBEtGYPJ0/OMZFadLYHD5ZBQAAAAAAgNZ4KD9ZNRwOO5L+qKQ/I+nfkPQHJF2RdEvSb0n6XyX9w9FolFwyHQ6H+5J+StLnJH1c0qGkX5f0N0aj0a+839cPAAAAAADwqHpYP1n1xyX9mqT/StIP6WSR6is6ud9/R9I/kPR/D4fDBz4/PBwOn5T0m5J+WtLzkn5P0lTSn5L0heFw+Bc3cP0AAAAAAACPpId1saoj6duS/ktJT41Go+8ejUY/MBqNnpD0H0ma6WTx6b9N7Pv3JQ0lfVHSd41Go++T9Jyknzg97s8Mh8MXNnAPAAAAAAAAj5yHdbHqNyQNR6PRz4xGo7dXvzAajX5O9xap/pPhcHi3DIbD4Wd18quDlaQfG41Gr5/uU49Go78r6eck9ST91Q3cAwAAAAAAwCPnofybVaPR6M453/J5Sf+dpMclfUjSWRzc507/+4XRaPSNxH5/R9KPS/rR4XB4aTQaHTVxvdJJ2sNqQsd4PtNy7lM+omQWJ0rHSJ4jSH5yShIoembNNLrHKJ0jxSX+ST61wyUYLl0UoXwySJSGKC3WUjjmy5PXLv0nShlxSRc2/SU4lqt/l4gl+cSig1k6sWVTXL1ECXoudc+l210LkhVvTtPH6nd7a0le9ek/l5Yj+TqO0s1y26VL95JOUstSXLuI235aSfrOxLTx3HFP8glDUSpPz5ynJBHM9aMomcaVv0vYiZKfcs9xcp70eOHKP0qxcsdyqWNRwpDrF66+Ts6f3se1y5J6qet6bb+z11EbK0mJzE3Xi577LnWwJDHJtYvo+eaeVy7Fq17mX5dL74wS96IkWsfViztPlMLr2qUrY5d0K/lnVck4bttLkKDn2pJrF26sPtmnucTLusHn2KDXX6v/Tqdz93+OGy+jcdTdiztPNI64+Y17voQJdub80XPfXZvbZ6vnx3dXZv657+ve3WeUbLg6xhwdTzU+ff3UpceS3//WUTpZT/J16a7ZPVslX8ZR33/54J3kdveeL+pHLvXPpTBHZexSgKM2liozsgDb4WH9ZNV5Vp/Uq6PTD57+91fNfr+hk18h3JHErwICAAAAAAA07KH8ZNV78B+c/vcr930K61On//1maqfRaDQfDoevSPqkTv6u1a81dUHdbkd7e/fW0Pb2drXs+Z+Y9Jbpqiv56Zfjfrov+Z9wup+KRZ+scvtEP33L/WTVlvnJq5T/yarop18ln6zqdbsP1L3ky7+78PWy535iOk+vS0c/Yewt0nUW/TTDXbO7/6geXf27e4zKxdnd9T9hnnXS1+Y+WbW3Exyrmz5Wv9tL1n30aSD/k0Tfx9w+7idpu4MteyzXlpyo7ed+6kPK/6lsySer3DlKPlkVfXpRUlbfjz7B4vqLu+bok1XReO3kln/JvZR8ssqJPlnVyRxLSj5ZNV8uknXfC567JZ+scnXprqs79+d39TLomp+iB89wNy5En2JwZePqf7H0bdyN464so09W5Y6J0snYl6r/PfeJgJ4vSztXMG3czhPkn1Uln55zbSx67ru25Oormqe6sS96VtpPVhXcf/TJqlTdl3yiOPpkVTSWpER9z81v+ub84TzZjK8ln6xyY0w053dl5sbKpj9Ztb1zbyxZbQe7e+ky3qv9JzddObvne1Qvroyj+YArG/vJqoI5VMknq6I+biXG8W43f46K5j1yi1XD4fD7Jf2npy//h/u+/Pjpf28Ehzj72rUmr+uFFz6jV1/98t3Xq/8fjxbq/tFF3T/aXn/tKxd9Cbggb73xtYu+BFwg+v6j6+VXvnTRl4AL8sbrv33RlwC03iP1a4DD4fApSf+HThbp/s/RaPTz933L2Y+0/B9/Ofk1QGn9VwkBAAAAAADQgEfmk1XD4fCqTv6w+nOSvijpzyW+bSppT1LwOzA6+/xmo38x+stf/pr+9J/+D+9+suJjH3tBy1n+H1jn1wDTPgi/Brha9+PxxJb/NPhD2vvm4/3uD8BGvz7j/tDuRf8aoLvHqFyca8EfWL+1oT+wnqr7Nv8aYO4fE+bXAM//NcCzT1V85KN/OOz7/BrgZn4NMAorSPlOfg3w7BNVTz3zGY3Hkwv/NUAXkiLxa4BO6R9YT/V994eBoz+wnvtrgCV/YJ1fA2z+1wDPPlH13LPfp/F40upfA8z9A+vRs93N1R6lXwM8+0TVMx/5QxqPT95Oftj8gfW3C/7AOr8GmD+HSY3jX/jCL+iFFz6TfSw065FYrBoOh/uSflnSZyX9jqR/1yQG3tTJYtXjia+deXzlextTVfXdAUuSxuMJi1UNLlYtgr//1YbFqlXj8aR4saprbtOmAfaDNtbSxSp3jyWLVTu1b5fjSXo92k2atyvfX8bT9LHuL6+zui9ZrFo0uFhVD3y9sFiVVrpYteq8vs9ilRlfg3HMacNi1aqzumexKn+xytV/k4tVGvjraiIN8O7Yv0iX2ThI1M1drAqmQ/ZZ9TAtVkXPyk0tVq06q/s2L1a5+U1bF6uiOf9FL1atjn1ndS9Jk056QXz1veH9WKxKi/q4kxrHq4o8wDZ46BerhsPhnqR/opOkv9+X9G+PRqPr5tu/LumjOvkD6qljDXTyyayz721MrfqBCPMoYnQTCyluciD5CcWiTg8qYRx1wb3kih7oTklMd7dj3mQWBKC6B3r0xsTFbruynBRMsqPfHs5dFInaheMmR1Edu/u/MTmw++TeSyT6xNvqZKc6ja7vB3/U0bU/Vy5SNAlI77M8LogpL1h07pv+Ek7azQS8o/Q1R4sSbiHJnT96Y+TK0o2VZ/us9oGqrlTVleo6r74k3y5LxtGSH3pE95kyr/295C5w5fww4Ey0IOXO444VlZb/JORg7af/W72BFr1FWMcl/LiY/8bMcffoykvyb2aieY/7dJN77kVjT+44HrUXd13uh4pn518dm3qdrnqdrh3HS36A0Te7uE9PSWX1nxt5H5W9+0SEq8uSH4ZEP3RwZenKZafvP4Uctf/V+Xi30wnfeEv+PqN24Y7p+l60UO3af8kPiVz5R89XV85uoTiaQ7h6cWNP1F79+4T3tk99+k+S3jKfoCp5X1eZ7SU/2Ije8+TWf+4HDSQ/h1sEY1U0H3ZS7Y8/r94OD/XfrBoOhzuS/rGkf1PSS5J+ZDQavRns8i9P//vHzNf/iE5+RXAqib+EDAAAAAAA0LCHdrHq9FNQvyDpRyS9JumPj0ajV87Z7R+d/veHh8Nh6tNVP3H638+PRiP/oykAAAAAAAAUeSgXq4bDYU/SP5T0o5Le1MlC1bfO2280Gn1J0i9J6kn6+eFw+Mzp8TrD4fAvSPpxnXzi/6+9X9cOAAAAAADwKHtY/2bVvy/pc6f/fyrpfx4Oh+57/9JoNPqtldd/XtKvSfp+Sd8eDoe/K+lJSc9KqiX95dNFLQAAAAAAADTsYV2sWv1rl8+f/s+5uvpiNBq9MxwOv1/ST+lkwevTko4kfV7S/zgajf5Zo1cKAAAAAACAux7KxarRaPSzkn72O9j/QNJPn/5vI7Z7A338yofvvv74lQ/r96ev2u+/vJ1OF4tMTNKHO9ahSdiRpO3+ILl9OXdx1D5NwiVQ7G/t2H1cOkVuYokkXTZJbS4pzMWoRuJI4u5acsbZ60uDdBlHCUNRMk3udbkEktnCn9/p99IpLy5FScpPebm8vWePVRI7HaXZpEyDenFtbFEt19KPtnr9cyN3Xd/b7qW3S9KxS/0zbfyJ3cv2WG6fklQed6ynLj1m97k1O0pud+USpcK49KFLg3RbihLB3BjnrkuSdjtb2lsZf69s76m/7NjrcmUs+RQt1y6uB0mYz688i1a9Pblt99kfpMfr28fj5PYo9c4lHF0z7fLg2Ed7X9vZT25/8/Cm3Sc3RaxkHNsbbK/ttzfYlgaVDoIkTlfHEVf/bkyIYspdkpS7ruh5dGeWbhfP7D9u93Epdq78o/7qxmS3z07Qj93c6sndK3aft45uPZAAvaiW9lkZpZq68vcJcvZQKvnrIM9cupbcfn2aHmOi+WBl0tUumfHFPUOir7m6l3x6ppv3Rc831y5vTg7VW9yrs9lirtlirivBHOZobpKeg7wyN7e3yb1Bvbgx0Y0v0Tz1w3tXk9ujfdx8zKdn5ue4uXbpniGSNF6kx/coafvplTHu6f3HNemePL/c/Ufj2GKZ935kZ+DHZFv/QVnWSo9Xu2bsd+N+dG028TOY1vfMNUfjxSxRzm48wmY9lH+zCgAAAAAAAB9MLFYBAAAAAACgNVisAgAAAAAAQGuwWAUAAAAAAIDWYLEKAAAAAAAArcFiFQAAAAAAAFojPwcZ75Na9UpEZq06jMR1MboudlfyEbfuWE0qiZGN4lpdxKqLsY0ieY+CiNmUKD7cncfF7kr3Iqvd6xzu/p1e11+Xa0tRhLaLhXXRs8fKu14prksniqt1KrOPq8voug6OJ8nt273BWvTzdm+gZW9hv1+S+t10VHDUX1w9u34ZRUi7eOfc7ZIvs0MT0y35qHA3vrl6lKRBNx2V7Moy6peuLKO2d7ys1F2JMJ8u5pou5up20v3CRjjL9yU3vkdj8q3jo+T2qI27CG83jkSR644b36JyuTk9TJ8/iuM29+n2KRmve93uWr88e10yvkXnj8omxUXRS0H5mzYePV/c16ZRTLu5z61B+plc8qxy40XJPOn2sY9p73d7a2P5/a9zuHbp7jHq++7+B10/73H36dredt+3MVf/u/30WN2t/b1Mj9PHmi388809+1zbj+aDYzO33O4P1spguz/Qsr8In7tu3hH1ffc1Vy/x8y19/oGpy8XcH8vdZ/SsPDxOzwmOzbG2TXuRorld/jOpZM5/MBuv/f/x7GS+Vw+ejCIAACAASURBVCl9rMXSl2Vt9nHP13AOYcpyJyhL58jM4aLnruPaZfSsdOcJnwl6/98LowyfrAIAAAAAAEBrsFgFAAAAAACA1mCxCgAAAAAAAK3BYhUAAAAAAABag8UqAAAAAAAAtAZpgC0xWy708p137r5++c47YVqSS1gqSfM4Pk4nQGwFqUCHJq3MXXMnSGBwCRT1Ij/poSSZw53f3ctOkGQzCVJmnKqu1tJJzl73uunzHM+jc+SlWQxqPwS41JCdgU8GcQkwroy7VZDM4VLfTN275J1Sri0tTBlHbcylPM3quXrLe3UwW841W87DxJKZSUvqBUlSLuXGJfUdzHwaoeNSaaKEq4VJ5Ynq0iX5lKSoucQad6yojJ0oeaqu67WxfL5caL5c2DYep3ilr7k2/ThKabwzy0v3KhG1C3f/LiUzSnw8Xua3i4FJ+HLP1+i569rSjcmBpiupjzcmBxpPJuE44pLSSpIVnb3Btv2aTclcpO//7cUteyyXLnfbtL2IS2qbVz5tdnGcvmZX99O5Tyl0ovO7+89NopTy+2WUGu3GuDCd+jgz1Tf4dneekjHJldlxUC9N9jHXLnud7tp1L6tKy6qy8yTJ10v0THAJlhPzfI3G5JL3HI5NaA3K2D8T89OZ/fuU9HY3T5D88z0qy9V2cbxc3H1tU+/M3ErKn6uUlEuU0Oru06aJB+Xi2qW7rpJyifpL6tqae7LiO8EnqwAAAAAAANAaLFYBAAAAAACgNVisAgAAAAAAQGuwWAUAAAAAAIDWYLEKAAAAAAAArUEaYIusphfUdR0mHZSkMrnEJJeAUZLy0eum1z/ddkla1umvLev8hCWXDLIdJfiZBApX/lFSmtsnSuDodXtr193tdNXtdIsSW2yaiDl/lD7jRElC7v5dmkeU4hWlH6VEKR+uXKL0GXcvUVqXPZZLFqyrtWtbVEstqmV4jtwkTClOpMvl6sxdc5Q652yZRC4pTqZJicoyt45L0pKidlxrfZy/+9oUmUtPlKTdQV6KWZyk01z6jkv/iZ4JURpmyvGyuXGkRPSstMlTp//ufx2NiS6h1yWESvnjRZTE6fZx7WI3SBZ07bLkmeDGhKi/utQ/p9vxcwiX+laSUBolyDmu/F2ibjgmFqQRumHBXVeUkmiflQXzUXdd0RwmV/RstWmEy7n6KynAx8u5jpfz+Flh68XXpZtDOtH7Cvv+YUN5abntMmpjblxYLPPbmJ3zB8/K1WvudDp3X5fM7XKTg5fB+Foit1+6MUnyc4Von1wlSai4eHyyCgAAAAAAAK3BYhUAAAAAAABag8UqAAAAAAAAtAaLVQAAAAAAAGgNFqsAAAAAAADQGixWAQAAAAAAoDXysnvxvuloPU642+mGcaUuFrUketNG0hbE6LoY05Jo74iLXnblEsXd58bFRtHauecoEZVlbrxvSbR2FP3q4sCLYqczRbHLThQvbOtf6fNEZblU+v47nc5a2SyqpRbVUt1Ofr1E9+K4vhcdK7fvRf3bfS3qr03Kvf/jpY8pd0r6mDv/oOsf2dN5usxK+n5JXbovufOU1LGLHI+uy92La8eSH69K6tJdWrfTTUaYR+dw11XyfHH7RNHmuXOF6FlhrzkoYlc2ri6rqI2br10a7CS3354dNXZd0km7XG2bZ6/dsZbmuSMF/aKgXbj+ErVL+0wo6C+5z5eojF173e4N7D6uzdpxtGAO4ZSMY1F/tcdy1xUN75nPkSbnvJK//8rM+9xcVMqv45I5TDT2rX5tvlyE3yvFbXxpnglNz4cdO/YG45Xj7qVJUbtMjRcFT3y8D/hkFQAAAAAAAFqDxSoAAAAAAAC0BotVAAAAAAAAaA0WqwAAAAAAANAaLFYBAAAAAACgNUgDbJFUMpD9XpNAESXVNZkUl3v+kpTCkhiGkvSZ3NSSkpST8xJrVsvt7HVR8pRh00yCW3EJQ1HCkksgKUmdy92n140SUzaTjNKUkrrfChKOXIpdSepb7j7RvTSZRNpkEqrrryVpNdF1ufO7vhclP7n2745VksZXkhKZW8aSr2PXj6PrcvdfklDq2mXJvbhxP2Kf4QWJuo4rL0nqmft0ZVmSHFs1mCIWledskR4TXRuLniGu70X7LOt67evLqtKyqormY66cS5LaSp7VblzMHRMkqWvKsmhuZ+5lFqS6uvHa9YuShFinZM4RPZNyx6uoXkrGvlxNphCXzPlceymZj4R9zLzX28T7l0jJvbhnQsmxlnXeOFLy/iEcexLnaTbTEqX4ZBUAAAAAAABag8UqAAAAAAAAtAaLVQAAAAAAAGgNFqsAAAAAAADQGixWAQAAAAAAoDVIA2yJWnogGSjiknSi9B0Xa+BSG1wqiyR1XWJN5ZOP/GXl5y3YRLKCJB1nEykb0sn9r5bB2euSZJjca46uqyR5y7GJMcGhcs8TpRT6ffITY0q4eul3e2spQ/e/TnF9PEolsn3c1EvYjjKLOUxsKehjuX28JMnHhmcWXO95Y1+q77s6DlNFzXaXelaS+BjJHWNL+p5NawruJTehVMq/tqi8ojTEpsb9aJ/c9Mzo3ptMVnT7lLRLtz1KSHXnL7kXpyStquRYuc/XonSz6Hrd3HID40h4rAaT4ppsF91Od63Ozl7nJpVJKoorc+mV1XIzqckl4/h2P92Xp/P8VFvX/m2aeacgzTyw+v6p2+ncfT03bazk/O4eo/TIkpTIeRW850wo6d8lzx3XLqM5VJPv+dAsPlkFAAAAAACA1mCxCgAAAAAAAK3BYhUAAAAAAABag8UqAAAAAAAAtAaLVQAAAAAAAGgNFqsAAAAAAADQGv2LvgB4UcSni+x0kbSSVNkI6/Q+USRpXTcXH+9iUaN9ciNWBz3f1F1ZFsWlmvs/L9539bqruorj7oNy2elvJbfb+PqCqNYoXtgdr+tidIM2HkXMJo9VEMlbEuHdpGVVrcVon73eVISujYIvuPfcKPZon5I4bCdqF7kR1hF3L+GxOuv3Wp/+c8JyMV9y+7jxTZLmy/TYH/aXzKjoqF62zTjmxt6ojKP7tMzh3HmieumZ8y+rZXLcLynjSHT+5Pf30hHxUv5zpGRMKHlW23oJxrHcPh7di5tbndf2VudevW5XvW7XHis+f969lIxvUVm6Pl7SXu2YXKWvuXKdVcE1B83SzmEbfL7dP8c7b84n+bKMrsvt4/pRk/PBJp/hkjSZz5LbS+bpjm3HQdsvuc/UnC8StQ13bcs6ff/RvNq2saBd5M57StrY8bK59y+RXrJsNjMXR4xPVgEAAAAAAKA1WKwCAAAAAABAa7BYBQAAAAAAgNZgsQoAAAAAAACtwWIVAAAAAAAAWoM0wJboaD1VoaNOUYKeS+mTmk3+corSRAr2yb3m89I2UkrSRNy9NFnG0bGmi+Pmzm+qJUo4cuW8KEgfcuk/Ls0kSjlpsl7c/bsUp+g8nc56Pz97vYkkQqnZJJ2SVJwmE2OcJseXppPaOqf/7n/dZJKSTQsKxsRGU6HM+aP+6tIIS55h7j6j5FzHJeuVpKttSu61LYPvd8fqmp97liSoxXWZNy412o+ixEebTnxeCnC99v+ruvYpjcFz1z0rS5SMfc4mUgJL9ilJRMs9hxT0l0537RrOXkdjkhvHouvNTWIN21hBEqrT5HsR96yI5LalonTgKEEvMeeTZBN9w3HUfGlTKY25x2v0/WbJ8yW43nn1YFtqurxQhk9WAQAAAAAAoDVYrAIAAAAAAEBrsFgFAAAAAACA1mCxCgAAAAAAAK3BYhUAAAAAAABag8UqAAAAAAAAtEb/oi8AJ2qtR2TWqsOITxeLGkWsNhkH7+I8m44SzTXoppt0GMdtIoE3Fbvc7/Y06N277kGvr0GvbyN5w0jcBuNqSyLvc8/TD6KSc6OaXd1LPqZ+Mp/ZfXwfS59/q+fPP10cp89R0F+cknjj86LVc7j+4mLdJel4Oc86ltRshLY7T6X0OaIydueP7sUZmLa0MJHjkm+v7pqjcaQkXtrdv+vj0TiSK7oX1/fDsnTjqCmXqI67bhxZjSzXvQjzkjbWpKbnHbnHiuol91hRG3PlXNJecp9VZ1bLraorVXXlx6SgjN0+JfXVM/21aEzYQEx91PdL2qVTMueN2thqOzt7XfI8jsYeV/4l7SL3WCV179qeJC1N/8t97knBfTY3HYvH8ZWyqet77/Xc/btniOTHJddeo3px53dlf3Jtpv2ZSy5pFyXvXRttF7hwfLIKAAAAAAAArcFiFQAAAAAAAFqDxSoAAAAAAAC0BotVAAAAAAAAaA0WqwAAAAAAANAapAG2REfrqQrdTjdMxnCpBSVpGi4cIUpqc0l1W/1B1vdH5wmTfDKThKJUHptmUpDu5co4qpfLW7va29pde91bSLemR3afXCXJhruD7eT22SKd4HZ6wCxRwpJL93P7uGQ5SdrubCW3N5k6dxy0cafX6a6l5Z29Xpo0Oknqmp8xlKRFNZnWZMurIF2s5LrcPUZJOk0m0pU4SwC7/3WnLkhVzSyz6PtLEgxzk3SaTPGKEn5cHZekaJV8/yLoF6lUKJcEKcWptk7uXCEqe/esdilmJWNSSSJTkwl6V7b3ktvvzMb2WO7+z0sEW/165/Sfq/9oDpUrui6bXhkcL7e/uMRFyfdXt080hm/10vPRaK7g5CaESnFK5ep13/86eR43uSp4hLtrdnM+yc+73HWHqdXma1Fy8FLp87s6Lplb2nM3PE9IJUFKZenMTY6jrvyrTn4CeG7SsuTrMjeJMtont100mdiNcnyyCgAAAAAAAK3BYhUAAAAAAABag8UqAAAAAAAAtAaLVQAAAAAAAGgNFqsAAAAAAADQGqQBtkbngVSwEltBklCvn05EmxUko7gkIZfAEKXO7ZkEkmmQOufSXGwCRZDmkZum0e0GyVNme1Sf82qp+UpCxdlrl3SxbRIXJWmxTF+BS8CIki4Gpo4XHZ+msajNeVxqRxB+4tJ/5lU6FSlK93L3H6US1VVeMkuUvuLSZ5Z1tZbwdfY6TsVJnydKuHEpMy7dK0o4cuXv7AzS444kTeaz9Pmj9E7TZl2/iNIrcxOmoutyzksiXe0bZ69t+k1BMo1rF1Hbd2UWjT0uDdO1vZLExx3zDIsSfty4MFsc231sKpGpy5Lz16ofSAA+L4XRJbVF7SI3Ferq9iX7tYPjSXK7G6+iRGGfHtpsilgul8IbpYq68583Vq62p/r0X0miseP6ftQm3Pld35P8HO7m5DC5PWqv9plk7t+dW/Jz26hdurHfPceilEY39m33B2tj6XZ/oGV/EY4j7jxRu7hski3dWB0lGrs2XpLS6ETvX1zZPLF7Obn9+uTAHstdc5h0bbj2F72vckmQbnyLUgLdM9k9X6fBcy9qf05uCvO1nSv2WG5ccu1yHlyva0tRom76/ptLzEY5PlkFAAAAAACA1mCxCgAAAAAAAK3BYhUAAAAAAABag8UqAAAAAAAAtAaLVQAAAAAAAGgNFqsAAAAAAADQGj4nFBtVq16LOT4v8thF/0bRoy7y3h0risR1sajzOi/WXpLuzMbZ+7jzu0jabs9HJbvoVRcVHMdxm5j2oCyPjqeq+5211+PjqY2xnc599Kzjzh/dy8EsHVMe7eOu2e0TxT676GMXKx+1fReJ2+v4IdD1iyajmqu6Wru2+183xZX/wGyfBPHGlwY7ye1RJLDjyjgqgy0T1TyZz7LP7+rf1XHE9f0o8n5ZVWtl0Dn9584f9Rc3jjkuilzycdxRu3DHc+0iKmPXLlyEdRR57vbpBeOYu7Yo9ttx9b+oq7VxuT79F41jJe3ScX0sqmM/jqavK7oXVy6DoC5zx0Y3T5D8s8qJ+t7eVnpMjOZxg25fg27/gdeuv0T9293njhkrS+Zc0fPN1b9rr9F8yJ3HHWscjPvuPFFZunbhni/RsVwbP14u1F9pT8fLhY6Xi7B9u37hnjuSNFvMk9tduUT9pe74r6VEY5UbF2bL9PVGXFuOxp7jzPO455Hkx8uwLBPj/umLpGjOndsud/pb9li2vbzHe1m1MG354Dj9vkLy47sr/2h8deN1NPakvx9twCerAAAAAAAA0BosVgEAAAAAAKA1WKwCAAAAAABAa7BYBQAAAAAAgNZgsQoAAAAAAACtQRpgi5UkMETOSxi8X5g+s4GMhCiBw53f3eNq6s79otSQFJcuJcXJX7mW5rpyU4ykKHWtIOUjs7wkn74S1bFNRSpIkCtJz3T379KKoj7h2mVd12v9/Ox1mMRpvlYFXbJrknxcmUVjj2v/riyje7FjTHAvuSmdUYpXblsuG/ficTSVDFSSLJkrStFyZRm1C5cE6/apgnHMjddufI3Ky50/qkuX+leSnBuNsbnHarJduDqeFSQelvQL1/c6JrVY8s++usEE1ZI01pIk0mVdrT3j7n+dw5W/S0orSUmMru365CDrPE22lxLR/eeK2ot7Jtd1vTa/W1ZLLatl0dwumnO6eUfJOOb7a3Nz3pK022g+7rj6d+Uf1Yubp0eppva6Mt/XSH4ct4mLJvEvOn/0XtAm+NkkzPzEx5I25p8V+Sn3uHh8sgoAAAAAAACtwWIVAAAAAAAAWoPFKgAAAAAAALQGi1UAAAAAAABoDRarAAAAAAAA0BqkAbbIA6lgUSKYS1gqSDpwSQ8u5SLapyRJxylJjHH3mJuEGImSKWwi2jnpO6lEsJI0C7ePTewoSNmI6rhnkkkql2IVnN7t41LEmk7PzD1Wk+mZ0ff7ZMcglcgkbC1NXJGrRylONsw9Vkn6Sm5KY0nCUkl7KakXp2Qfd5+uvqL26mwiBVbKv+aqzk8KKxn7et30+aMUK9f3mtTkXKGkv5QkpNq+X/BMKLnm3KZcdI5AVVdr/fzsdW66l1SW7pZ7rGhMyh3Ho7LMTWormQ81OY6VjCPu/GHaqhljSsbxJufpmyjj6Hi5iYclovLy75/yyzi37Uv5KZkl8/cmU/JKUt7d9vBYJPs9VPhkFQAAAAAAAFqDxSoAAAAAAAC0BotVAAAAAAAAaA0WqwAAAAAAANAaLFYBAAAAAACgNVisAgAAAAAAQGv0L/oCcM9qPGmn0ymK5C2JpN1UHHmuknjjJrlzLEti0oN76Zz+u/91Sb3YGN2Cay6R2/5KYmxLlMRe5yqKaS/4/k3012VmHLLU7JhUEhO/iTjy8F7MJZ8XoZ3q+yXHcm2mZByrO/ll2WhfMseqlC7/kmdleH7TllwcecmzqtvpZo/7TUbOu2M1GS1+0Zp8vkTHanLsc20s7F/m0kr6ZEldusj7RttYyb0EfS/7WA22/U6n88B8/7xxahP3H7VXO4cquP8m76XkunKfCU0/X5o8Vm4dR+dw9d/k/Re1MXf+gqLfxHtHNI9PVgEAAAAAAKA1WKwCAAAAAABAa7BYBQAAAAAAgNZgsQoAAAAAAACtwWIVAAAAAAAAWoM0wBZZTSk4L7EgNxmj5FiRJlOJnE2kS0nNpnmUqE//3f96E/Vy0eVSktjSZLtoMnHyg5gy0uR4UXL/TdZxScKRa39FaVGFiTWpvu/SsqL6cgmObp8okavJBMcm20uT+xSlWJl9wrTXIClutZzPXpccK5Jb/tE5Bt30lPF4Oc++riaV9L3sthQcy/WlkufrJlJwI0XzjsyUzouec0XjW+7Y3+QcqiQl8byk6ZxjRdpal5tIfIwUJbDf917v/Zg72iTOhuvrIue9F/3+BZvDJ6sAAAAAAADQGixWAQAAAAAAoDVYrAIAAAAAAEBrsFgFAAAAAACA1mCxCgAAAAAAAK3BYhUAAAAAAABaI51DjAuxGrXZ6XQ2Fjv8Xq7nIs7T5DmiGNvcSOCmI9ebjFjNvbaSc190JGxJvVx07HLuNTfd9zYRL9xkvZQoiZBu8lil40UyxtpUf1X563Lnd2NfyZhUUl8lx8rtl4/KvTR1jkjU9hfNdbFGNfkcKyn/ZbVMbo/mHZ1OZ+3r3U5X3U7XHqvJ+WB0XW7saXIcd3OuNmv6uZsz7ku+/qP+uonn/qbGqybvxbW/Tc3HLtKm3ouUaPL9y0U/R9GsR2axajgc/qikf3L68qXRaPS8+b59ST8l6XOSPi7pUNKvS/obo9HoV97/KwUAAAAAAHh0PRK/Bni6APU/vYfve1LSb0r6aUnPS/o9SVNJf0rSF4bD4V98Hy8TAAAAAADgkfdILFZJ+uuSnpP0i+d839+XNJT0RUnfNRqNvu90v5/QyQd0f2Y4HL7wfl4oAAAAAADAo+yhX6waDoc/KOk/18lC1f8VfN9nJf0ZSZWkHxuNRq9L0mg0qkej0d+V9HOSepL+6vt+0QAAAAAAAI+oh3qxajgcDiT9PUljSf/FOd/+udP/fmE0Gn0j8fW/c/rfHx0Oh5caukQAAAAAAACseNj/wPpfkfQZST85Go1eHQ6H0ff+4Ol/f9V8/TckzSTtSHpB0q81dZFnkukgDcpNv4nObxOmClJeNpVgmHv+i06GcGXcZOpZiU4QWZNb/xedTLKpJJeojaVSQEuuqyTxchOJaJtKbCk5vyszl8jVNFf/ro9F99Lv9pLblw2OFyVtzF3XfLmwx4rGmJxzl57fsdcVpXgF+6TqPipj1y43lYbYZHKu26fJ50skty6j67L3H1xvVVVr9bmslsXjTpNpfCVtfBNzqE2kRkvNzq82lSid6yITqDdlU4mTPffcDfqyS35vcg7V5PuHhykZPtLWtoyHeLFqOBz+AUn/taQvSfqb72GXT53+95upL45Go/lwOHxF0id18netGl2s6na72tvbvft69f83pcmB4IO2WBVNNN3gvamBs9PpJOveXfMmJlPhPgVvJjYRI/tBfNC4umexajPnb3KxqvQNe07fj+QuVoWx6m5RoqDvlywWRW05JRoTB730NKdksarkuefKrFadrPuSxapIk8+xJsfkTTyrI1G95F6XE7WLuk7Xv9PkOBodK7dcovNv4oeHbX7uR9ecHPcveFGgxCbGkZLzbOoH1yVzCNfvL3qxahP1ErnouWVKt/tQ/wLaB8ZDuVg1HA47Ovn1v4GknxiNRu9lhvf46X9vBN9z9rVr38HlJX32hc/orTe+dvf16v/Ho+XN17960ZeAC0LdP9qo/0cXdf9oY8736KLuH12M+8D5HtYlw/9M0g9J+luj0eg33+M+O6f/PQ6+Z3b63+Y/9gQAAAAAAICH75NVw+Hwo5L+e0mvSfpvMnadStqTtBV8z/bpfydlV+f91pe/pj/xJ3/s7k9YnnrmMxqPmz0NvwaY1pZfAzz7CcvTH/lejccTfg3wEfo1wPvrnl8D3Mz52/JrgO+170f4NcC0tv8a4P11z68BPlq/Bvhe53z8GuDD92uA99c9vwbY3Hna/GuAly7tPTDul56fXwNMa+q6fvWf/6I++8JnGjkWyj10i1U6+ftUVyT9x6PR6CBjv5s6Wax6PPiex1e+t1FVVa1NVMbjCYtVBT6oi1WrzuqexapHY7Fq1Vnds1i1mfO3YbFq1Xl9P8JiVVqbF6tWndU9i1WPzmLVqvPmfCxWPVyLVavujvssVjV2njYvVq0eb7Xfs1jVvsWqqrrYQCuceBgXq77v9L9/ezgc/u37vnb263vPDofDN0///58djUb/n6SvS/qoTv6A+gOGw+FA0nOnL7/e4PVajb/Jy0x5KXkzkztwlp6/yUFtE6lzJUom87kPqKKFp2DSmvtmrmRxsyQp7aIXUTehqCw38EbWLVZIfsGg5M1UyTiS+/6z6bGi2+mu9Zmz172CRRG3KOWOtZSfhLkycws/kq/L3IUnSeqZP2rqzj+Zz5LbJalqcKLrrmvZ4IS26TcTdhHTXHNRWlTBAscmfhgTaTItrHTsdalgKeEiZp1+Y1zS99y9RMeqgrEkeY4NpVdetOyUxuD7Xepc1F9yk75LfuDlNL0g2qTcOeSmFmqLfhiSec1NXpfkx56SY+WO/eEPEOw0Mf+HIbh4D+Ni1Zmngq91V75+9mt//1LSD0v6Y2afP3L6vVNJX27iAgEAAAAAALDuoVusGo1Gz7uvDYfDPyfpf5H0UuL7/pGkvyLph4fD4SdHo9E37vv6T5z+9/Oj0eiwmasFAAAAAADAqoc1DTDbaDT6kqRfktST9PPD4fAZSRoOh53hcPgXJP24pErSX7u4qwQAAAAAAHi4PXSfrPoO/XlJvybp+yV9ezgc/q6kJyU9K6mW9JdPF7UAAAAAAADwPuCTVStGo9E7Olmo+uuSXpL0aUmXJH1e0o+MRqO/eYGXBwAAAAAA8NB7pD5ZNRqNflbSz57zPQeSfvr0fwAAAAAAANigR2qx6oMmitgsiXh1+7hoaxdFLjUb13rRcmN0SyLPSyKBl1U6EjY6f270atORvE1Gz9pjFUTSlpw/9zwlkfOd038PvG64G+XWZUk/duWyMO24VG60ehStnN1fCiLXzzve6jHPXi9NFHy3oO+57W7cP9knvT26f1cvx8u53cefP32s2SJ9rJ3+VnL7yfnTz7HcWHkpfiY6Nlrc1H3Tz9Blla7/aExyLjxyPijLnO9vWklbyr22klj1Juul6PwF5VIyjm9C021p9XidTkedTicsr5Lyfy/nXlUyH2xSyfO1ZEzKnUNUZgw9vYD0OaJnZWLcLz2WvazMsTIS9b3c80T10uSx7H1+8N6iQvwaIAAAAAAAAFqExSoAAAAAAAC0BotVAAAAAAAAaA0WqwAAAAAAANAaLFYBAAAAAACgNUgDbLGSdLESLq0rOkduAkdJkklJ6l4Jd82bSPg5O49NB2noukq4ZJQmEwRL2nhJykdJmojTZN+rT//d/7rpOm70mjeQslJy/02md5YkpZWcP/+6/M+XbH81x3KJe5JPCixJdixJSM19XriUQKnZerHnKHxW5CaCFbUlN8YVDDG5z8qw7zXYX0vkpsc2mcYmNZsGWfKsjq6rjecvSTdrdOwtSAHuiYJQiQAAIABJREFUBYmrq2XW7XTV7XRVmRTYppUkJ+fWZdiOXNJyQX258i85VkkC9ybGpE314yYTBDcxh9rUeyFcPD5ZBQAAAAAAgNZgsQoAAAAAAACtwWIVAAAAAAAAWoPFKgAAAAAAALQGi1UAAAAAAABoDdIAP6CK0ncykxNKknyavK4wLcqkpvjkq/amrGSfo8F0s0iTSXlF6W4N3kuTStJn3mu643lJkKWaTFjKPcemNJkKlHuOyHmpd6vHPHvt9onupesjlpKb58uFv66CMrNj3wa666aScy9aybPSPqsLUnBtwtMFpzU1mSK23d9Kbp8tjrPPf958IJkIt4FxrGlNXvOm5mq57L0ETTy6l9S4H/WXqI9bmcV/0fPkkqTptgrT1BMpsFLZnNu1i7b2o5J7dJpOaWzzGPuo45NVAAAAAAAAaA0WqwAAAAAAANAaLFYBAAAAAACgNVisAgAAAAAAQGuwWAUAAAAAAIDWYLEKAAAAAAAArdG/6AuAt6kYTXee8yLXc45Vcv4mo1ebLMsoEvWDeM1Or9tLbo/u8SLjhcOY8IKizL2Xksj3D2K8rhsXXCRxSRx31MaaPL/j9ikp+yajmufLRfY+rixLotBLoqKbLEvbx4NDldR/k3HgJTHt9lhuHAmO1eT5nU2NY+48rr6W1TL7/I2212Cfqq7W6qA+/XfRY4xTMl40OSaXnN8J+0tmu4iuK7demjyWdM6cKPX9Dc4tonOX3EuTz313nyXztNzruv94dV3ffV3yXsydp8l7qdTSOX/QXpucc+Pi8ckqAAAAAAAAtAaLVQAAAAAAAGgNFqsAAAAAAADQGixWAQAAAAAAoDVYrAIAAAAAAEBrkAbYIqvpBZ1OJzvJ4zy5qRlRAkSukmSQJtM8mhQmUBQmLz1Q951OUSpRkwlHbU3NsKk83SC9sspPRHN11mhS2Gld3/+6yQS7s+Mmtxekq5Wc3+6TmWQT7lPQ93LHi5Jx7LyUylT990xbXpp2LMnuU1ebSX3LrcswKc3cZ0l7uWiNJueathSNPdkJU8Fl5d5LOCYVDDJNpsu58y8bTPTthmmAecdqMpGs6aS2XI0mHRckYTZ5/+G9mEOVlHFbE2qdNs8tc5Mdm0wuLbGp9pKb6Nu0RlOzG5zb4uLxySoAAAAAAAC0BotVAAAAAAAAaA0WqwAAAAAAANAaLFYBAAAAAACgNVisAgAAAAAAQGuwWAUAAAAAAIDW6F/0BcCL4qhL5MaChrHTmVGuUfTqJmJRmzxHGLneYEy5UxTj2mC8ccn5e91ecvuyWmYfyynpL2HstesvDcY+13W9Vp5nr6P6cpG8JX3somOvm4xXLrkXF1XtNN3GnIXpF1Hkeu4+0b00GdXtjtXk863pMXET0e6u74f7lESYm32qKl3+uX1Cyo+Cj66rhDtWSR27cinpE65PSvljf8m9lDwrNvHci7g248aLqM80es2m+MN5stmpc/rPvU7uc8FzOHd+V19hvRQ8w5t+P5RjY3OrDcztN9Vfct9vSvnjVVheBf0V7cUnqwAAAAAAANAaLFYBAAAAAACgNVisAgAAAAAAQGuwWAUAAAAAAIDWYLEKAAAAAAAArUEaYEt0pAfTQQoSseJz5CUtNHn+KBWoJH0m9/ybSuYoPVZuIlyuklQge6yCdlGSFpWbrBim6ZQk+WwgwbHTWe/n97/Oua5u8LMHm6Rk6n/Q9Y+G4+U8uLo8JWWcmy5XkjDUZCrPuSlPiVQom3xU0CRLrysl6q/LOp181mRaktP0+G7vs8FxpKSNlexj09WUn67V5HNkE+2iyfM3XcfdTnetbs5el6Se2US2gnrpm+TeKrgXO/Y2mFzrRO0lN1kwUtJeo2fVahnUp/82pdGktg2lUzc5jjpNpidGcud8Eddf58vFd3RdqzaVoGfLoeD0m2qX2Aw+WQUAAAAAAIDWYLEKAAAAAAAArcFiFQAAAAAAAFqDxSoAAAAAAAC0BotVAAAAAAAAaA3SAFui1npCSUlayfnnyEtH2ETKhlSWSmWPtYnEkA0lYzR6noIUK3uogvSbTSTdlPSZJhMvm07vdJZVOnWtyUS0eeWTZKJEuJSmx7LcZMn3YyxNsXUcVEtd1w+M+1VdNTqOuZS+IlHgZuY1R+P+JsaLkpTInkleisp4E8+L6F6aHC+a5PprrxskTlZ5iZ+b6vvuXsJ2cV8C3HmJcNG468rMJYJFdb8w7aUoDbEgXa1r7qVoHGkwcdOm8BYkGjeppF6aTAjdZIphykUnfTtNvq+JrteNic6m5qklmkxobfL8uHh8sgoAAAAAAACtwWIVAAAAAAAAWoPFKgAAAAAAALQGi1UAAAAAAABoDRarAAAAAAAA0BosVgEAAAAAAKA1+hd9Abh4m4h+jb7/omPKc20q3rQkrnUTceRNnr8oDrug/Jssl4su4yb3KTpWg7ff6DWbcaSt0dYlNhU77c7TZBR7ybjfZF1GkfPu2traLkrkxoRL+X2s1/VlvKiWWdsjTT4TXOR81F5dv4jKsnP67/7XJf0iN76+RJN9LzpW7hhTUl5Nzjui85fcf+6xSpSM424fN45G52hybttkGTfpvbaLuq7vvi655pKxp61y+3LT9/gwPd8fNnyyCgAAAAAAAK3BYhUAAAAAAABag8UqAAAAAAAAtAaLVQAAAAAAAGgNFqsAAAAAAADQGqQBPmSihKPcBJDoWLmJYC5hJxJd76CXbrouFack/WRTaRqdTmftXPe/buQcBQlH9lgbStbbRDJHv9uzXytJpbpITZZlybHamj4TjT25STpNpzQ22ffdeF2SbLeJ8aLJsgxT19z5g3vJTbjaVLpXk2XZJFde0Rjq9lkG+2wiIbbJVNHzxp7V9nT2uq1ps219JpTcSzS3tUmoyp9DbvUGye3zapF9rE2MoyUJqSVz64ueQ+Sep8n3Vfeff/WZ7+aj86VvLxedwJ2bqtoNEmJLEjdzRXW5rD9Yc/5HCZ+sAgAAAAAAQGuwWAUAAAAAAIDWYLEKAAAAAAAArcFiFQAAAAAAAFqDxSoAAAAAAAC0BmmALfJAQkSQJFOScJSr5FglaQ42TSJIuXApQ67MNpXW5JyXpLN6rvtfN6HJdtGkTZZxSpRWtYnEmo7W+/nZ65L+UpLYEl2XU5Iu16Ts+w9uPfdYbU3EkhpOqtvAeHHRY3J4rMxLa7LvNa3RBD1TMK7tRecoSVdzmmxLjbbLBqu+yT5ZNI6FA2nesUo02Y+isqxMorRNCQzS4OaVf1a+33O+s+N+kGxsfDeafF8Vnd/VvUsz35QmkyVtmUWP3Q2k3ZL498HEJ6sAAAAAAADQGixWAQAAAAAAoDVYrAIAAAAAAEBrsFgFAAAAAACA1mCxCgAAAAAAAK3BYhUAAAAAAABao3/RF4Aym4gW31TsrTtPt+PXUhuNad/AfZ4Xbb563WevLzp2eBMxsiUR2het0cjz03/udY5GyzK4FdcvS/rkJtrSeX2vjRptYwXHajL2u0lN1vGm2mVU/psY93OPF40/HTMwNBl5vqk2nnusEh/E577jxvdNaXJMarK9NrnPpsZkd6xN1fEm5pYlNjW3dUrK/6LLzMmdJ5b4IL5/QBk+WQUAAAAAAIDWYLEKAAAAAAAArcFiFQAAAAAAAFqDxSoAAAAAAAC0BotVAAAAAAAAaA3SAFtkNb2gruswNWETyVebSoRyCUORXreX3O7KrMlyia63yZTCJtM0mkxLarKOt/sDu89sMU9ut2Uc1IvtL1HylUsRc4lYBceq6/qBfl+aYrKp/urKP7dPlp7flX+vm+4vi2qZf44G+8VFj8klBr301CAqS1cv7h7DdpF5rGWdX8eRJusl+/myoUSwknHMfa3JZ1U0jjd5fjdeLQvGiw+ai07Kitp4Sbts8vyOKzPXjqT3/uy7PxnyvO9/L9cVfe2ik3NtHw9OkZsaXjT2/P/s3XvULGddJ/rvu3Mh2dxMQEOMIObCg5BAAog4AoIcEBTwDAMsHO+XAZwlylkqggwuuSj3gyOXGeSgCAPqIA4BWXiQQRLE60jQCeBDwBCucpEcUHdCAu97/qjqnU7T3Xt379rdz9v9+ey1V3V119Nd1U9Vdff3rarfgvvKZV9n0defZ90VJ4fcj657v0S7HFkFAAAAQDOEVQAAAAA0Q1gFAAAAQDOEVQAAAAA0Q1gFAAAAQDOEVQAAAAA0Y3p9arbKKsqFzn2NGZVU57YZcJaHLP267GuMP763t9f9n7GQQ5eeXdQyrzFrWa798nWDvc6QJYTnGbKE9iyr6uNFS1vPM+v9X6Yc9jL7i+u/8uXZbRZ8/XWbVY57mXVv1ns57z1e5r2c1S+7u0tsl8t8JszQajns0X5+cnzeOjlk+fpBP18G3Izm7cdnLv8SyzLrdZbaJ63AkJ8JLX+HWMXn65CW2fbWvY6t+zvEotvePMt871v4/V/R14Qhv4+tyqq+d08z9PbS8vu87RxZBQAAAEAzhFUAAAAANENYBQAAAEAzhFUAAAAANENYBQAAAEAzVANk6y1aGWTd1WrWXZVoSEMuy9CVPNb5Prfcx0NWMlp3dbdW179lqiXNqiC4mxVVaVzQuiuSLWPIanzLTN9qtaJW14tlnmtWm6HX11nVIJd5jYW/w6x5298ky1RDW7TvV2XI7aWF5ZllyH3yLDtzSgiOv2c7OzuHx1exva67X+ZWu53xnq2z4iBtcGQVAAAAAM0QVgEAAADQDGEVAAAAAM0QVgEAAADQDGEVAAAAAM1QDbAhkxUiZlV3SparSLfuKhCzLFVpY8GqSENWa9qPlqkitYp+GfL1l6mYMq9iy6Lb2LqrWC2j1Uo+61yPVmlWVahZy3/Sgdkf2V/e/crg8zdpVf3S6nq5aEWsZP4+Zvwz/sDOgRzYObBU5aNB9z1z5nfeQ6sw6zvRrOVfVRWpZbeLWVXBplnV5/Ey6/isNjMrlDbeLwu9xpLfIRbp+2TYfc+s+Rry+9Ay9mNV0ZmvscT7tYrtZd1VeOe+xoJv85D7pJmvsdDUHC+OrAIAAACgGcIqAAAAAJohrAIAAACgGcIqAAAAAJohrAIAAACgGcIqAAAAAJoxuw42azevXOmskp1DlipelVnzPK/E6Kx5nlmSd8ByrUOXXJ8sWzwaX6ZU8aKWWZZlnm/IeV7mPZ752Lwq7SuY553sTC1fP//Jpt/datnnZcx7D76y+5WFnmuZZVnVfnTWtj/Ll+cs+6Klsocseb7s68wys4R3pn8mDr1PXoW9/t/k+CrXvVnzNbPNkOvFEkXBZ73OMss/ax0bclmWea5Z5n4fGvB1Bv1+scR8nXDghKn3z/s+PMusfpm3jIu+zjLLuLe3d6N1dnJ80eeaabiuHNSy35MXaTPkPnFoM/t+BS8/9Ofeot+hlvmevs590nq/JTDiyCoAAAAAmiGsAgAAAKAZwioAAAAAmiGsAgAAAKAZwioAAAAAmqEaYCN2cuPKJUeqlLOKqglDWqaSzTLVX9Ze4WmJ1x+yMsyQhqxw1MLyTDNkNcSlKtnMqAi27OssatZzDVl5aplqfMts+4u+xtBtZjnS8k/b9pep1Dbz9ZfYjoesLjbLvM+4We//iTMqhc2rkriMISsIDvleLvO5P7PNgOvFUvO1xPsys0rkMt8VhuyXJbfLye98c7eJAT93j1hxdoq5FfSWqNI587lm9OWQ33n343fLIS1aTTtZXRXqoSyzT1zF96EkMysAD7mO78fK8KuwDcu4iRxZBQAAAEAztuLIqlLKdyf5iST3SnKrJFcn+XCSP0nyy7XWL09Mf1KSJyb5gSTnJrkuyXuTvLjW+gcrnHUAAACArbLRR1aVUk4spbwmyVuS/NskX07yt0n+Nck9kjw1ySkTbU5J8o4kz0ty5yQfSvJPSe6X5A2llOesav4BAAAAts1Gh1VJ/ku6o6P+Osndaq23q7Xes9Z6TpLTknxvki9NtHluknsnuTLJnWutd621njs27S+UUh62siUAAAAA2CIbG1aVUu6f7tS/jyR5QK31svHHa62Haq1vqrVeP9bmjCSP70d/vNZax6Z/U7qjrZLkl4/jrAMAAABsrU2+ZtXP9sMX1lr/+SjbPDzJyUmuqLX+yZTHX57kaUnuVko5p9b64QHmM0mylxtXKBmyGtayhqymcYTihgtbRbWuQSsvLdFmqOmP9PqzrGIdHHQdG/j1h3yuefO8aCXIISuVzbJJ1fiWMWg1uCNUiZxVGWiZ55pmVl8OvR9b1Nyqc7OqRH5l8WVZhaUqgS5YCXLZ159lmfViUUN/Vi36mTDkezl4v+zceBs4UiXYISvXLrV/n7cojVaKW7R6ZbL+fcksy3wmreJzdJM+q4eswjukVr/zzrOK3ynrXvdYnY0Mq/rrTj2oH317KeVOSR6b5E7pTuW7LMkra61XTTS9Vz9817TnrbV+opRyZZJv6qcdLKwCAAAAYEPDqiR3TXJSf/s+SV6S7oipkYcmeVIp5Udrrb8zdv8d+uG8EOrD6cKqMtC8JkkOHDiQgwdPPTw+fnsRq/pL4qKJ9tBp/qYdWTVE38+ziqNxljHkOjb06w9p3rIs2vet9uUmWdV7vLOzs1D/L3sEzyLTL9tmSKv4fBnyvZxn3nNN6/v9uE9c1V/+d2Ycoj3kUWKrOrJqndv+0Nb5+i1v+/Pst8/9Vl9/llWdgbCMWX2/7u1l3d8hWzyy6sCBjb1a0r6yqWHVmWO3X5rkPUmekK4S4O2S/EqSRyf57VLK349dz+r0fvj5Oc89euy04WY3uejC8/PpT11+eHz8NttF328vfb/d/vGT/3vds8Ca2Pa3m21/e9n2t5ftHo5sU8Oqm43dPpTkIbXWq/vxD5VSvi/dUVQXJnlqkkf2j53SD6+b89yj6oHDH/4CAAAAsOU2Nay6duz2q8aCqiRJrXW3lPKiJL+d5EGllAO11t2xduOnDE66ST+8ZrC5TXLZey/Pgx/ymMN/YTnjzPNz6NDiL+E0wMWt+/SZ0ekgx9r386z7EO5Z1n1IcgunNS3a96325SZZ9WmAo7+u3ubrL5jb/04DnK7lU4GOdBrg5La/H/eJTgNc7LlGz7eubX9oTgNc3H773G/19Wdp/TTAadv9ureXdX+HbPE0wEsvuTgXXXj+cX8d5tvUsGo8nPrAjGlG9988ya2SfHas3elTW9z4savnTLOw3d3dG31YHTp0jbBqjk0Lq8Yt2/fzrPuLxizr/uBs7cf30fR9q325SVYZVo07Uv8Lq6Zr+Qfr0T7XqO/34z5RWLXYc017vlVu+0MTVh2b/fC53+rrz9JyWDVuvO/Xvb2s+ztki2HV7u7xr4rOkW1qWPX3Y7dnndI3fvTV6ApqH0zy7UnOnfPc54xN25xWS/Ie7x95x/I6i7ZZxWssaxU/WIfU6vsy5Gscqc14u8lx2jJ0wLPT/5scn1Uqe1Ul4pfZXtb5Y2Lo/cg6v7Sv6rNyGev+MbNoCflZ4VYyO+Ca+drHYR0bf87J8UWfa50W3fcNOb+rCiXWHdasu4+HtO73cpZZ+4tF9ztHMtR2f6yvPWkVf6hY92+OeXz3btdGXua+1vqJJFf1o2fPmGwUOl2b5J/623/RD+89rUEp5ax0lQDHpwUAAABgIBsZVvV+rx9+fyll2hFkP9YPL6m1frm/fXGS65OcV0q5/5Q2j+uHl9VaPzTcrAIAAACQbHZY9YIkX0h3JNRLSimnJEkpZaeU8tNJHpZkL8lzRg1qrZ9O8vJ+9JWllDJ6rJTysCRP6keffvxnHwAAAGD7bOo1q1Jr/Wwp5ZFJ3pTuiKjHlFI+mOQbkpyZLqh6Uq31nRNNn5Tk7km+Lcn7SimXJ7lZbjht8IW11otXsAgAAAAAW2eTj6xKrfXtSe6a5FVJ/jnJhUlOShdg3b/W+oIpba5Jcr8kT07y/iR3SHLrJJckeWSt9edWMe8AAAAA22hjj6waqbVekeRHF2xzXZLn9v9XZrIq2NCGrHq37moe664asahVVcBotY/Xvb60asiKUKtax1ZRXWwVVWlW9VxzX6f/Nzk+ZPXOZba9ISueznr9ZZZlP+4v1j3P66zUtu7KT4tW/Jtn6GWZVQl23evLkPbjsuy3eW75M2HfPdeMqn8t/xYa0pDfx1r9/aDi3/600UdWAQAAALC/CKsAAAAAaIawCgAAAIBmCKsAAAAAaIawCgAAAIBmCKsAAAAAaMaJ654BbjBZwn4/WlWJ0f36/iximRKri74vq3qP191fq3j9dZcvb7Xk/CrW42Vfv4X1cnK/P/Q8rXsZ122Zz6RNKkc+yyq2saH3Y5tUdnwV2/4sQ+8TW91eWp0v1mvI/Uir69Kq9slDttlvz8XqOLIKAAAAgGYIqwAAAABohrAKAAAAgGYIqwAAAABohrAKAAAAgGaoBrhPraIqzryqCa1WV5tlP1Y322/v8dAWrWbSctW3/VbFat3v17ZbZn3ZbxWOVrWOLbO/mGU/Vhdb5zwP/Vm56Dwf2Jn999jdvd2FnmuedVc83WbLfO6v+7vCuqsAt1oJdJ799pk0bx2b1vermq/9aFXr2H77nr5NHFkFAAAAQDOEVQAAAAA0Q1gFAAAAQDOEVQAAAAA0Q1gFAAAAQDNUA9ww86oj7MdKRotaZhkXbbPM+3WkKhOLVIYZsvpNy33f8rwtasiKZK1axba3KkPOV6vVmpZp0+qyrGod26TtdRlDVmhdhb0M18fLrGPbYsiKyvut6ts889al8XmYHN9PWngvW3S0VU2Pte/32/uyjE1aFpbjyCoAAAAAmiGsAgAAAKAZwioAAAAAmiGsAgAAAKAZwioAAAAAmiGsAgAAAKAZJ657BljOfiwhvgrrfl+WfY1FStmuahlX0cfLlPye9frrLqE8z7x53uYS1i1se0O1aXWfuIxZ87wfS84POV/7cb1YtC+X+exZ9zIus0+eZd3r2CxDbnvr3iete5ucZ8h1ed3v8ybxXk637vdl3fv+Ie3Hed4WjqwCAAAAoBnCKgAAAACaIawCAAAAoBnCKgAAAACaIawCAAAAoBmqATZkvKrCstVtVlWtSdWE4ezs7HxV3+/s7Kz9PW616t8yr9FqpbJWrfu9XMa6q9K0+r4sU9lv0eca2rorkW7DZ+UqlnHd+5FW3/tltLws69xeh35f1vk+L7O9rHsbG9K275P3o3VWQtWP28ORVQAAAAA0Q1gFAAAAQDOEVQAAAAA0Q1gFAAAAQDOEVQAAAAA0QzXAhoxXNli2yoHqCPvP3t7eV/X9pvXjJi3PNlTlWZUhq7x4jzeHSnGboeVKnPut4mTLny+212Fs++deq8vS8rY3yyZV0NuP88ywHFkFAAAAQDOEVQAAAAA0Q1gFAAAAQDOEVQAAAAA0Q1gFAAAAQDOEVQAAAAA048R1zwBsu52dnRuVmR2NK9e6mHW/X+t+/SFt0rJskmVKaK+7hPW6X38Zrc7zKuZrP65jy1jFvA35Gi2/l5tk3vo/jX5p0zL7saGmX6X9uO+FRTmyCgAAAIBmCKsAAAAAaIawCgAAAIBmCKsAAAAAaIawCgAAAIBmqAYIa7a3t3ejyh2T4/uJyiQswnpx/K27Utx+1OqymK82+dzbHPpsM2xLP27LcrLdHFkFAAAAQDOEVQAAAAA0Q1gFAAAAQDOEVQAAAAA0Q1gFAAAAQDOEVQAAAAA048R1zwCwOZTRBcbZJ+wv+mtx3jMWsbOzk52dna8atx7B8TW+3bF/OLIKAAAAgGYIqwAAAABohrAKAAAAgGYIqwAAAABohrAKAAAAgGaoBghbbF5lDJVpoC2r2iZn7RfsE1jE0J8v1sv12ZbvCqtYx/b29m70fJPjwPFhO9ufHFkFAAAAQDOEVQAAAAA0Q1gFAAAAQDOEVQAAAAA0Q1gFAAAAQDNUA2Smlqu/zJu3adY9vwAtaXn/vgrbvvxDWlWVPv2yPpv03tv2gUmL/q5kdRxZBQAAAEAzhFUAAAAANENYBQAAAEAzhFUAAAAANENYBQAAAEAzhFUAAAAANOPEdc8A7Wq5hG/L87aonZ2dG5VMHY2vYhk36X0Ejt62b/vbvvxD8l6yn1hf2RTjvx3GWccX5z1rlyOrAAAAAGiGsAoAAACAZgirAAAAAGiGsAoAAACAZgirAAAAAGiGaoANmawIx3bY29u7URWKyXGA1qlKxBDmffexLgHcwD6RbeDIKgAAAACaIawCAAAAoBnCKgAAAACaIawCAAAAoBnCKgAAAACaoRpgQyYrwgHAfuAziyFYjwCAEUdWAQAAANAMYRUAAAAAzRBWAQAAANAMYRUAAAAAzRBWAQAAANAMYRUAAAAAzThx3TMAAACt2tnZmfnY3t7eCucEALaHI6sAAAAAaIawCgAAAIBmCKsAAAAAaIawCgAAAIBmCKsAAAAAaIZqgAAAMIOKfwCweo6sAgAAAKAZwioAAAAAmiGsAgAAAKAZwioAAAAAmiGsAgAAAKAZwioAAAAAmiGsAgAAAKAZJ657Bo6nUsqtkvxskocmOTvJyUk+k+TPkvx6rfVPZ7S7WZInJ3lkkm9M8i9J/jLJC2qt7zz+cw4AAACwnTb2yKpSynlJ/neSpyS5c5JPJ3lfklskeVSSS0sp/9eUdrdO8r+SPDXJ7ZN8IMm1Sb4nyTtKKf9xFfMPAAAAsI02NqxK8l+TnJnkiiQX1FrPqbVelOTrkrwwyU6S5/Wh1rhXJilJ/ibJ2bXWuyW5XZLH9W1+vZRy4YqWAQAAAGCrbGRYVUq5eZL796M/X2t9/+ixWuu1SX4+yYfSnQb5XWPtLkry8CS7SR5Ta/1k32av1vobSV6T5IQkT1vFcgAAAABsm40Mq5LcJN1RUEny4ckHa617Y/efNPbQI/vhO2qtH5ryvC/vh99dSrnpEDMKAAAAwA02MqyqtX4uycf70X8z+XgfNI1O5fursYfu1Q8vnfHUf5XkS0lOGWvfDcu7AAAgAElEQVQPAAAAwEA2uRrgk9Odtvf8Uspukj9M8sUk5yd5dpIzkvy3Wuu7x9rcoR9+1dFYSVJrvb6U8rEk56a7rtW7p023jAMHDuTgwVMPj4/fZvPp++2l77eb/t9e+n676f/tpe+3l77fPw4c2MhjevadjQ2raq2vLaV8Icl/SvKKiYc/leQnc8NpfSOn98PPz3nq0WOnHfNMjrnowvPz6U9dfnh8/DbbRd9vL32/3fT/9tL3203/by99v730PRzZpkeG56ar/reb5CNJ/i7JoXRVAn8kyZ0npj+lH1435zm/1A/F4QAAAAAD29gjq0opL03yH5P8dZIH11o/2N9/apKnp6sI+O5Syl1qrVf1za5NcjDJyXOe+ib98Joh5/ey916eBz/kMYdT9jPOPD+HDg36EjTs4MFT9f2W0vfbTf9vL32/3fT/9tL320vf7x+XXnJxLrrw/HXPxtbbyLCqlHKXdKf5XZ/kUWNhVGqt1yR5UinlbkkekOQpSR7fP3x1urDq9Mx2+ti0g9nd3b3RDuvQoWvswLaUvt9e+n676f/tpe+3m/7fXvp+e+n7tu3u7q57FsjmngZ47yQ7Sa4YD6omvK0f3mPsvg/2w3OnNSilnJTkdhPTAgAAADCQTQ2rbr7AtKeM3f6LfnifGdPeM90pgtcmee8S8wUAAADAHJsaVo2OejqvlPKNM6Z5UD+sY/f9fj+8fyll2tFVj+uHb621/ssxziMAAAAAEzY1rHpbks8kOSnJ60spdxg9UEo5tZTyvHTXq0qSV48eq7W+J8kfJjkhye+WUs7s2+yUUh6b5AfTVRZ81kqWAgAAAGDLbOQF1mut/1pK+f4kb0zyLUk+UEq5Ksk/p7se1cF+0pfWWi+eaP5jSd6d5O5JriylvD/JrZPcNslekif2oRYAAAAAA9vUI6tSa317krskeUm60wJvk+Sbk3whycVJHlpr/akp7T6bLqj61SRXJblTkpsmeWuSB9RaX7ySBQAAAADYQht5ZNVIrfUfkjxhiXb/nOSp/X8AAAAAVmRjj6wCAAAAYP8RVgEAAADQDGEVAAAAAM0QVgEAAADQDGEVAAAAAM0QVgEAAADQDGEVAAAAAM0QVgEAAADQDGEVAAAAAM0QVgEAAADQDGEVAAAAAM0QVgEAAADQDGEVAAAAAM0QVgEAAADQDGEVAAAAAM0QVgEAAADQDGEVAAAAAM0QVgEAAADQDGEVAAAAAM04cd0zAAC0Y2dnZ+r9e3t7K54TAAC2lSOrAAAAAGiGsAoAAACAZgirAAAAAGiGsAoAAACAZgirAAAAAGiGaoAAwGGq/gEAsG6OrAIAAACgGcIqAAAAAJohrAIAAACgGcIqAAAAAJohrAIAAACgGcIqAAAAAJohrAIAAACgGcIqAAAAAJohrAIAAACgGcIqAAAAAJohrAIAAACgGcIqAAAAAJohrAIAAACgGcIqAAAAAJohrAIAAACgGcIqAAAAAJohrAIAAACgGcIqAAAAAJohrAIAAACgGcIqAAAAAJohrAIAAACgGcIqAAAAAJohrAIAAACgGcIqAAAAAJohrAIAAACgGcIqAAAAAJohrAIAAACgGcIqAAAAAJohrAIAAACgGcIqAAAAAJohrAIAAACgGcIqAAAAAJohrAIAAACgGcIqAAAAAJohrAIAAACgGcIqAAAAAJohrAIAAACgGcIqAAAAAJohrAIAAACgGcIqAAAAAJohrAIAAACgGcIqAAAAAJohrAIAAACgGcIqAAAAAJohrAIAAACgGcIqAAAAAJohrAIAAACgGcIqAAAAAJohrAIAAACgGcIqAAAAAJohrAIAAACgGcIqAAAAAJohrAIAAACgGcIqAAAAAJohrAIAAACgGcIqAAAAAJohrAIAAACgGcIqAAAAAJohrAIAAACgGcIqAAAAAJohrAIAAACgGcIqAAAAAJohrAIAAACgGcIqAAAAAJohrAIAAACgGcIqAAAAAJohrAIAAACgGcIqAAAAAJohrAIAAACgGcIqAAAAAJohrAIAAACgGcIqAAAAAJohrAIAAACgGcIqAAAAAJohrAIAAACgGcIqAAAAAJohrAIAAACgGcIqAAAAAJohrAIAAACgGcIqAAAAAJohrAIAAACgGcIqAAAAAJohrAIAAACgGcIqAAAAAJpx4rpnYJ5Sym2SPDDJt/T/L0xySpJLaq33O0Lbk5I8MckPJDk3yXVJ3pvkxbXWPzhC24uSPDnJdyT5miSfTPLmJM+qtX72GBYJAAAAgDlaP7LqMUleneQJSe6VLqg6olLKKUnekeR5Se6c5ENJ/inJ/ZK8oZTynDltH5HkL5M8OslOkvcl+bokP53kb0spZy+5LAAAAAAcQeth1ReTvD3Js5M8Iskzj7Ldc5PcO8mVSe5ca71rrfXcJN+b5EtJfqGU8rDJRqWUs5K8JslJ/WudVWu9e5KzkvxRkjOT/F4pZeeYlgoAAACAqZoOq2qtv1lrfWCt9Rdrrf8jyWeO1KaUckaSx/ejP15rrWPP96Z0R1slyS9Paf7zSQ4mubTW+ku11i/37b6Q5N8n+UKSeyR56JKLBAAAAMAcTYdVS3p4kpOTXFFr/ZMpj7+8H96tlHLOxGOP7Ie/Mdmo1np1ktf3o48eYkYBAAAAuLGmL7C+pHv1w3dNe7DW+olSypVJvqmf9sNJUkq5bbrT/ZLk0hnP/a4kPzH2GoM5cOBADh489fD4+G02n77fXvp+u+n/7aXvt5v+3176fnvp+/3jwIFNPKZn/9nEsOoO/fDDc6b5cLqwqkxpd12Sj89plyRnl1JOqrVev/RcTrjowvPz6U9dfnh8/DbbRd9vL32/3fT/9tL3203/by99v730PRzZJkaGp/fDz8+ZZvTYaVPaXV1r3TtCuwNJbrHc7AEAAAAwyyYeWXVKP7xuzjRf6ofjx18u0m6y7TG77L2X58EPeczhlP2MM8/PoUPXDPkSNOzgwVP1/ZbS99tN/28vfb/d9P/20vfbS9/vH5decnEuuvD8dc/G1tvEsOrafnjynGlu0g/H9xCLtJtse8x2d3dvtMM6dOgaO7Atpe+3l77fbvp/e+n77ab/t5e+3176vm27u7vrngWymacBXt0PT58zzeFT/qa0O62UsnOEdrtJvrjc7AEAAAAwyyaGVR/sh+fOmeaciWnHb5+c5LZHaHflkBdXBwAAAKCziWHVX/TDe097sJRyVrpKgOPTptb60SSf7EfvM+O5R/f/+THOIwAAAABTbGJYdXGS65OcV0q5/5THH9cPL6u1fmjisTf0w8dONiqlnJbkUf3o64eYUQAAAABubOPCqlrrp5O8vB99ZSmljB4rpTwsyZP60adPaf78dBdOv28p5RmllBP6drdM8rokt0xyWZI3H6fZBwAAANhqTVcDLKXcNl04NHJKP/z2Usrnxu5/Xq31eWPjT0py9yTfluR9pZTLk9wsN1xz6oW11osnX6/W+rFSyg8l+Z0kT0vyuFLKx5LcMclNk3w6yaNrrXvHvnQAAAAATGr9yKoTktxq7P9N+/tPnLj/4HijWus1Se6X5MlJ3p/kDkluneSSJI+stf7crBestf5+km9N8vv9XRck+WySlyS5y5RTBwEAAAAYSNNHVtVaP5JkZ8m21yV5bv9/0bbvyQ3XpwIAAABgRVo/sgoAAACALSKsAgAAAKAZwioAAAAAmiGsAgAAAKAZwioAAAAAmiGsAgAAAKAZwioAAAAAmiGsAgAAAKAZwioAAAAAmiGsAgAAAKAZwioAAAAAmiGsAgAAAKAZwioAAAAAmiGsAgAAAKAZwioAAAAAmiGsAgAAAKAZwioAAAAAmiGsAgAAAKAZwioAAAAAmiGsAgAAAKAZwioAAAAAmiGsAgAAAKAZwioAAAAAmiGsAgAAAKAZwioAAAAAmiGsAgAAAKAZwioAAAAAmiGsAgAAAKAZwioAAAAAmiGsAgAAAKAZwioAAAAAmiGsAgAAAKAZwioAAAAAmiGsAgAAAKAZwioAAAAAmiGsAgAAAKAZwioAAAAAmiGsAgAAAKAZwioAAAAAmiGsAgAAAKAZwioAAAAAmiGsAgAAAKAZwioAAAAAmiGsAgAAAKAZwioAAAAAmiGsAgAAAKAZwioAAAAAmiGsAgAAAKAZwioAAAAAmiGsAgAAAKAZwioAAAAAmiGsAgAAAKAZwioAAAAAmiGsAgAAAKAZwioAAAAAmiGsAgAAAKAZwioAAAAAmiGsAgAAAKAZwioAAAAAmiGsAgAAAKAZwioAAAAAmiGsAgAAAKAZwioAAAAAmiGsAgAAAKAZwioAAAAAmiGsAgAAAKAZwioAAAAAmiGsAgAAAKAZwioAAAAAmiGsAgAAAKAZwioAAAAAmiGsAgAAAKAZwioAAAAAmiGsAgAAAKAZwioAAAAAmiGsAgAAAKAZwioAAAAAmiGsAgAAAKAZwioAAAAAmiGsAgAAAKAZwioAAAAAmiGsAgAAAKAZwioAAAAAmiGsAgAAAKAZwioAAAAAmiGsAgAAAKAZwioAAAAAmiGsAgAAAKAZwioAAAAAmiGsAgAAAKAZwioAAAAAmiGsAgAAAKAZwioAAAAAmiGsAgAAAKAZwioAAAAAmiGsAgAAAKAZwioAAAAAmiGsAgAAAKAZwioAAAAAmiGsAgAAAKAZwioAAAAAmiGsAgAAAKAZwioAAAAAmiGsAgAAAKAZwioAAAAAmiGsAgAAAKAZwioAAAAAmiGsAgAAAKAZwioAAAAAmnHiumdgnlLKbZI8MMm39P8vTHJKkktqrfeb0ebmSR6W5Lv6NrdPF8p9Isk7k7yo1nr5EV73oiRPTvIdSb4mySeTvDnJs2qtnz3GxQIAAABghtaPrHpMklcneUKSe6ULqo7kZUlem+SH0gVVV/T/z0ryY0neU0r50VmNSymPSPKXSR6dZCfJ+5J8XZKfTvK3pZSzl1wWAAAAAI6g9bDqi0nenuTZSR6R5JlH2e4tSb4nydfUWu9aa70gydcneV2Sk5K8opRywWSjUspZSV7TT/PMJGfVWu+eLuj6oyRnJvm9UsrOMS0VAAAAAFM1fRpgrfU3k/zmaLwPk47kibXWf5ryXJ8vpfxIkrsmuXOSH0/yxInJfj7JwSSX1lp/aaztF0op/z7JlUnukeSh6U4LBAAAAGBArR9ZtbBpQdXYY9cn+Z/9aJkyySP74W9MaXt1ktf3o48+lnkEAAAAYLqNC6uOwqn98ND4naWU26Y73S9JLp3R9l398F7HYb4AAAAAtl7TpwEOrZRyMMn39qPvmnj4Dv3wuiQfn/EUH+6HZ5dSTuqP1BrEgQMHcvDgqYfHx2+z+fT99tL3203/by99v930//bS99tL3+8fBw5s4zE97dmqsCrJr6Sr7PfZjF0Lq3d6P7y61ro3o/3n++GBJLdIMvOUw0VddOH5+fSnLj88Pn6b7aLvt5e+3276f3vp++2m/7eXvt9e+h6ObGsiw1LK9+WGC6r/h1rrFycmOaUfXjfnab40dlscDgAAADCwrTiyqpTywCSv6kefWmu9eMpk1/bDk+c81U3Gbl8zwKwddtl7L8+DH/KYwyn7GWeen0OHBn0JGnbw4Kn6fkvp++2m/7eXvt9u+n976fvtpe/3j0svuTgXXXj+umdj6218WFVKuW+SN6YLoZ5Ta/3VGZNe3Q9PK6XszDgVcHSq4G6SySOzjsnu7u6NdliHDl1jB7al9P320vfbTf9vL32/3fT/9tL320vft213d3fds0A2/DTAUsq3JXlLkoNJXlxrfcqcyT/YD09OctsZ05zTD68c8uLqAAAAAHQ2Nqwqpdw9yVuT3CzJK5P8zLzpa60fTfLJfvQ+MyYb3f/nQ8wjAAAAADe2kWFVKeWCJG9Lcsskr03y2DkV/sa9oR8+dspznpbkUf3o64eYTwAAAABubOPCqlLKeUn+ON31pV6f5IdrrUd70unz0104/b6llGeUUk7on/OWSV6XLvy6LMmbB59xAAAAANq+wHop5bbpwqGRU/rht5dSPjd2//Nqrc/rb78kyRn97W9MckkpZdrTf6rW+qjxO2qtHyul/FCS30nytCSPK6V8LMkdk9w0yaeTPPooj9ICAAAAYEFNh1VJTkhyqyn3nzhx/8Gx2zcZu33POc991bQ7a62/X0r5hyRPSXLfJBeku5bVbyV5Zq31M0cx3wAAAAAsoemwqtb6kSQ7C7a53wCv+57ccH0qAAAAAFZk465ZBQAAAMD+JawCAAAAoBnCKgAAAACaIawCAAAAoBnCKgAAAACaIawCAAAAoBnCKgAAAACaIawCAAAAoBnCKgAAAACaIawCAAAAoBnCKgAAAACaIawCAAAAoBnCKgAAAACaIawCAAAAoBnCKgAAAACaIawCAAAAoBnCKgAAAACaIawCAAAAoBnCKgAAAACaIawCAAAAoBnCKgAAAACaIawCAAAAoBnCKgAAAACaIawCAAAAoBnCKgAAAACaIawCAAAAoBnCKgAAAACaIawCAAAAoBnCKgAAAACaIawCAAAAoBnCKgAAAACaIawCAAAAoBnCKgAAAACaIawCAAAAoBnCKgAAAACaIawCAAAAoBnCKgAAAACaceK6Z4DcPknueMdzc+klFx++89JLLs7u7u665okVO3DghtxY328Xfb/d9P/20vfbTf9vL32/vfT9/nHHO547unn7Nc7G1tvZ29tb9zxsu39NcnDdMwEAAAAcdijJTdc9E9vKkVXr95kkX5fk2iQfWe+sAAAAwFa7fZJT0v1WZ00cWQUAAABAM1xgHQAAAIBmCKsAAAAAaIawCgAAAIBmCKsAAAAAaIawCgAAAIBmCKsAAAAAaIawCgAAAIBmCKsAAAAAaIawCgAAAIBmCKsAAAAAaIawCgAAAIBmCKsAAAAAaIawCgAAAIBmCKsAAAAAaIawCgAAAIBmnLjuGaBTSrl/kp9N8q1JbpbkqiSvT/KcWuu/rnPeWE4pZSfJtyV5eJJ7J/nmJLdI8v8luSzJbyd5Xa11b0b7myV5cpJHJvnGJP+S5C+TvKDW+s7jPf8Mr5Ty3Une0o9eVWu9/Yzp9P0G6fv9J5LcK8mtklyd5MNJ/iTJL9davzwx/UlJnpjkB5Kcm+S6JO9N8uJa6x+scNZZUinlVuk+0x+a5OwkJyf5TJI/S/LrtdY/ndHOtt+4Usptkjwwybf0/y9MckqSS2qt9ztC26W37VLKRenWje9I8jVJPpnkzUmeVWv97DEsEgtYpv9LKTdP8rAk39W3uX26AwY+keSdSV5Ua738CK+r/9fsWLb9Kc/135M8qh99eq31l+dMq+/ZWjt7e1N/J7NCpZQnJPnPSXaSfDzJZ5PcKclNknwgyb1rrZ9f3xyyjFLKA5K8feyuf0j3I/Wbkpze3/eWJP+u1vqliba3TvKnSUqSLyV5f5KvTfINSfaS/FSt9WXHdQEYVP8j9H1JbtffNTWs0vebo5RyYpLfSvfDNEk+luQf0wVW35AuwLh5rfVfxtqckuSP0wXcX0m3ztw0yTn9JM+ttT55JQvAUkop5yW5JMmZSXaTfCTJF9P14c3Tbcc/W2t90UQ72/4+UEp5YpIXTXlo7g/WY9m2SymPSPK7SU5KF3p+PN16ctMkn0r3PfEfllkeFrNM/5dSXpMbPgeuSXJFurDqvHTf9a9P8rha62/NaK//G7Dstj/leR6W5E1jd80Mq/Q9285pgGtWSrl7kl/rRx+X5Ha11rul+0vs36Q7GucVa5o9js1OkiuT/EySM2qt59Ra71FrvVWSH0r3Y+R7kjxjSttXpvsw+pskZ/frxO3SrSM7SX69lHLhCpaB4fxquj68+AjT6fvN8V/S/UD56yR3q7XertZ6z1rrOUlOS/K96fYD456b7sfslUnuXGu9a6313LFpf6H/oku7/mu6oOqKJBf0+/6Lknxdkhem246f14da42z7+8MX0/0h6tlJHpHkmUfZbqltu5RyVpLXpPux+swkZ9Va757krCR/lG5d+73+aG6Ov2X7/y3pvvN9Td/3FyT5+iSvS9e3ryilXDDZSP83Zdm+P6yUcoskL0sXOv3NEabV92w9R1atWSnljem+qLy61vrDE4+dl+Tv04WKd621/t0aZpEl9R9I19Rar5/x+C8m+ZUkn0/ytbXW3f7+i5K8J91f5Eut9UMT7V6d5AeT/EGt9d8dx0VgIKWUeyV5d7rDtt+Y7mibrzqySt9vjv7U7nekO6rmLrXWfz6KNmck+Wi6I66+s9b6JxOPPyPJ05K8p//CSmP6032+kC5c+j9rrRdPPL6T5IPpTgF7Qq31Jf39tv19qpTyU0lenPlH1iy9bZdSfi3dH70urbV+x8Rjp6ULv26Z5OG11jcPslActaPs/1vVWv9pxmMnpbs0xJ2T/Oda6xMnHtf/jTqavp/S5mVJfjLJv013SvB3ZMaRVfoeHFm1Vv1pQQ/uR39j8vFa6xXpfuwkN5zXzD5Ra/3irKCq99Z+eHq6Uz1GHtkP3zH5g6X38n743aWUmx7jbHKc9V9EX5HkUJKfOsLk+n5z/Gw/fOHRBFW9h6f7MXvF5I/Z3qj/71ZKOWfK46zfTdIFVUl3XbIb6a9ROLr/pLGHbPub7Vi27dG6Me174tXprm+aJI8eYkYZ3qygqn/s+iT/sx8tUybR/xuilPLtSR6f5OJa6xuPoom+Z+sJq9bronRfbL+U5K9mTPOufnivlcwRq3Tq2O1rxm6P+vrSGe3+Kt06c0q6izvStqckOT/J02qtHz/CtPp+A/TXpnlQP/r2UsqdSim/Vkp5WynlzaWUZ5RSvnFK01H/v2vKY6m1fiLdX1LHp6UhtdbPpTu9I0n+zeTjfdA02nbHP/dt+5ttqW27lHLbdKf8JLPXDd8T97/R98FD43fq/81RSjk53R8u/zXJE45ien0PEVat2x364UfnHIEz+gvstL+2sL99Xz/821rrF8fuH60XX/VX+eTwX+E+1o9aLxpWSvnmJL+Y7vSeFx9FE32/Ge6aG46auU+6Uzx+Jl0VoYemO92nllK+b6Ld3P6feEz/t+vJ6S6I/vxSyk+UUm5TSjlYSrlnuovqnpHkv9Va3z3Wxra/2ZbdtkftrssNIeisdmf3R/Kyj5RSDqa7HEjy1WGm/t8c/ynddYh/qdb6sSNNHH0PSYRV6zaqCDev0t/osdOO87ywQv2F9R/fjz5n4mHrxQbor03zinShxeNqrV85imb6fjOcOXb7penCqnumO5L2vCT/vb/92/21ikb0/waotb423WlfH0i3D/hUur+m/2W6Hys/ma7Ixjh9v9mW7d9Ru6v7U0jntTuQ5BbLzR5r9Cvpii98NslvTjym/zdAKeXO6f6I8Z4kv36UzfQ9RFi1bqf0w+vmTDOqFHXqnGnYR/oLrf5BkhOT/I9a6+9OTGK92Aw/meTbk7yk1vq/jrKNvt8MNxu7fSjJQ2qtf11rva6/HtH3JXlvuiDzqWPT6v/NcW66H6C76S6y/3fp1oUzk/xIuospj9P3m23Z/l2k3WRbGtcfXTu6oPp/mDjKPtH/+14p5UCS/yfJCTn6P1wm+h6SCKvW7dp+ePKcaW7SD6+ZMw37RCnllukurH67dCVrf2TKZNaLfa4vN/zsJJ9Id+j30dL3m+Hasduv6i+Eelhf+fNF/eiD+i+z4+30/z5WSnlpuv79XJJvrrV+U631rkluneT5Sb41ybsnrlum7zfbsv27SLvJtjSslPLAJK/qR586WTm0p//3v59Kd02ply7wh8tE30MSYdW6jX7AnD5nmsOHgR7neeE466s//lG6C+u/L8l3TfkrWmK92AQvTndI9k8vUAku0febYrxvPjBjmtH9N09yq4l2+n+fKqXcJd1RldcneVSt9YOjx2qt19Ran5Su8tct0hVfGNH3m23Z/h3dPq0/tXxeu90k075T0JhSyn2TvDFdEPGcWuuvzphU/+9jpZSvT3ea5ydy46Ooj4a+h3SnIbE+oy+xtyulnDTjIuvnTEzLPtRfQPMt6f66ckWS/2NOKeMPpqsAcu6M5zop3ZFZo2lpz9364ctKKS+beGx0qPZtSyn/2N9+RK31z6LvN8Xfj92edQj/+NFXoz8cfTDdqaNT+7/nM6Ft906yk+SKWutVM6Z5W5IHJLnH2H22/c227LY9un1yktsm+eicdlfOKdZDI0op35bu++DBJC+utT5lzuT6f3+7Q7rLApyQ5IpSvqo2xihs+rlSyuOTfKzW+i39ffoe4siqdbss3Q+Zm6S7+O409+mHf76SOWJwfRn7NyW5b5Krkjyg1vqPc5r8RT+8z4zH75nuw+vadNe9oV1nTPk/ugjmgbH7Rod56/sN0JehHwUVZ8+YbPQl89oko+B61P/3ntagP730myampS03X2DaU8Zu2/Y321Lbdq31o0k+2Y/OWjd8T9wn+uI6b00XYLwyXZXYmfT/xjg1078Pjir43bQf/9pRA30PHWHVGvWnB/2//ehjJx8vpZyX5Dv70d9f1XwxnP6v4W9I91f0TyT5zqMoWTvq6/uXUqb9FfZx/fCttdZ/GWZOGVKt9fa11p1p/5P8aD/ZVWP3v7O/T99vjt/rh99fSpl2FPOP9cNLaq1f7m9fnO70sfNKKfef0mbU/5f1F2qnPaO/hp83cU2qcQ/qh3XsPtv+ZjuWbfsN/XDa98TTkjyqH339EDPK8VFKuSDdUZW3TPLaJI+dU+VtnP7fp2qt75z1XbD/PnhJP+nT+/tuP/EU+p6tJ6xav2cm2Uvyg6WUx47OSy6lnJnkd9L10RtrrX+7xnlkCaWUE5K8Lsl3J/nHdEHVPxypXa31PUn+MN1hw7/brwsppeyUUh6b5AfTnZ/+rOM176yHvt8oL0jyhXRHS7ykP8Jy1Jc/neRh6fb9zxk1qLV+OsnL+9FXlrFzBkopD0vypH706cd/9uUYURcAAALtSURBVFnS25J8Jt1fzF9fSrnD6IFSyqmllOel++NFkrx69Jhtf7Md47b9/HQXT75vKeUZ/XeLUcGW16ULPy5L8ubjNPsco/6Pz3+c7rSv1yf54b7QxtHQ/9tL37P1dvb2jibU53gqpTwxyf+d7joXH0tXQehO6U4PrEnuXWv93PrmkGX0JYlf149+JN2RVbM8odZ62Vjbr03y7iTnpStN+/78/+3dPWtUQRQG4Be0MElhq2AglVcLo+AXVipqZxl7f4BgI2JpZREUBLX2D1ionWChrbXN2AULkZQpbFQszoYsS2KxIWGSPA9sc7OzyXLuwJ03Z+6tJ0nNpxa491trL3bgz2aHDcNwN8nrVGfVwiY/V/t9YhiGm6ktwDOp4OpbkhNJjqdq+bC19nRizEzqBtxXkvxJ8jW1ZWR92+Cz1tqDXfkCTGVU97eprR1/U1tC11L3K5odve1Va+3exDhzfw8YhmE+tUBcdyRV69+peb5uubW2PDZu6rk9DMNS6h+Yh1Nh6Pckp0a/92fqOlG35S6Ypv7DMHzIRkfll1SX3WZ+tNbuTB5U/z5MO/f/83mfklxNdVY93uI9as+BprOqA62150lupfaxz6WCqpUkT5JcEFTtWeOPlF1I3Vx1q9fR8YGttdUk51PnwErqnJhLnSM3LFj2L7XfP1prH5OcTT2efC3JuVTHzfsk1yeDqtGYX0muJXmUCitOpgKLz0mWBFX9G9V9McnLVEB5LMnp1GLmXZLbk0HVaJy5vzccSj3Bc/01Nzp+eOL47Pig7czt1tqbJJezsV30TJLV1Dm2aLG6q6ap//j14KVsfS14MZtQ/25MNfe3Q+056HRWAQAAANANnVUAAAAAdENYBQAAAEA3hFUAAAAAdENYBQAAAEA3hFUAAAAAdENYBQAAAEA3hFUAAAAAdENYBQAAAEA3hFUAAAAAdENYBQAAAEA3hFUAAAAAdENYBQAAAEA3hFUAAAAAdENYBQAAAEA3/gH673+yQ2CRiwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 1920x1080 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbKi3yP_7YVc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "s = model.prototype_visualize(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04_yUWUtq1VT",
        "colab_type": "code",
        "outputId": "f0805d90-df66-4bdf-fa29-5e67998efd01",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "plt.figure(figsize = (23.8, 15.8), dpi = 100)\n",
        "n, m = divmod(s.shape[1], 3)\n",
        "for i in range(s.shape[1]):\n",
        "    plt.subplot(n + m, 3, i + 1)\n",
        "    plt.imshow(s[l, i].cpu())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAB4UAAASICAYAAAAUMBlyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAAPYQAAD2EBqD+naQAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nOzdf5Sld10f8Pdu9sfMEBUiEmMkP0jItyQpm19ibMESqb8i4KkncGirrVolVsXSWhEbU0WsosVTC/4oIIriEQr4IyhEc2KE0LQBIZCWgN+QuK6CCClEBXZmEzrbP+buMk7mzuzMPN97c7/7ep2z57mz93me+c773Jn5zLzvfWbX0aNHAwAAAAAAAECfdk97AQAAAAAAAAC0oxQGAAAAAAAA6JhSGAAAAAAAAKBjSmEAAAAAAACAjimFAQAAAAAAADqmFAYAAAAAAADomFIYAAAAAAAAoGNKYQAAAAAAAICOKYUBAAAAAAAAOqYUBgAAAAAAAOjYnmkvYKtKKVcl+f4kX57k1CSHkrwxyUtqrZ+Z5toAAJgusyIAAOOYFQGAk9muo0ePTnsNJ6yU8rwk/zXJriQfTnJfkguT7E/ywSRPrrV+cnorBABgWsyKAACMY1YEAE52M3P56FLK5Ul+dvTmtUnOqrVeluRxSd6T5AlJXjWl5QEAMEVmRQAAxjErAgDM0CuFSym/k+Qbk/xarfVfrrnv8Un+JCsl94Fa6/+ewhIBAJgSsyIAAOOYFQEAZuSVwqWUU5N83ejNV669v9b6oSS3jN581qTWBQDA9JkVAQAYx6wIALBiz7QXcIIuzcrf9ziS5F1j9nlHkn+c5MqB3ufBJI9JspTkzwY6JwDAes5JMpfk40nOne5SZpJZEQDo2TkxK+6EWREA6Nk5OcFZcVZK4QtG2z+vtT44Zp97R9sy0Pt8TJKF0b/TBjonAMBGHjPtBcwosyIAcDIwK26PWREAOBlsOivOxOWj87nh6ZMb7HPsvkcN9D6XBjoPAMCJMn9sj1kRADgZmD+2x6wIAJwMNp0/ZuWVwnOj7QMb7HNktJ0f6H3+WVY9k++pF12dpUXz3BDm5ufytrvemkSuQ9pKrnd94tCkltWFhYX5fOyj70+SnH7GxTl8eHHKK+qDXNuRbRstc7317Tfk0ksuTlxabrumPiv6XBuOr2FtbCXXR86dOqlldWF+YT53H7w9SXLBuVdm0WN2EHJtR7ZttMz1LTe9Lk88cGFiVtwus2JHzIptbCXXhX1zY+/joRYW5nPw0LuTJOeefYXH7EDk2o5s22iZ6003vyEHDlyUnMCsOCul8LF2a98G++wfbZs8QpcWl7J0WHk5NLm2sVmuvpBv3+HDi/JrQK7tyLaNoXNdXl4e7FwnqanPij7X2pBrG5vlum/5lAmupi+LHrNNyLUd2bYxdK5mxR0zK3ZKrm1smutnj05uMZ3xmG1Dru3Ito1p/l5xVi4fff9ou9Hf4Dh23/0b7AMAQH/MigAAjGNWBADI7JTCd4+2Z5VS9o7Z57w1+wIAcHIwKwIAMI5ZEQAgs1MKvzcrf/djf5InjdnnKaPt/5rIigAAeLgwKwIAMI5ZEQAgM1IK11o/leQPRm8+d+39pZTHJ/mq0ZtvmtS6AACYPrMiAADjmBUBAFbMRCk88uIkR5N8SynluaWUXUlSSjkjyeuy8rH8Tq31zimuEQCA6TArAgAwjlkRADjpzUwpXGv94yT/bvTmK5IcKqXckeRgksuT1CTfOaXlAQAwRWZFAADGMSsCAMxQKZwktdafTfLVSW5M8ogkFyY5lOQnklxRa/2/U1weAABTZFYEAGAcsyIAcLLbM+0FbFWt9Q+T/OG01wEAwMOPWREAgHHMigDAyWymXikMAAAAAAAAwNYohQEAAAAAAAA6phQGAAAAAAAA6JhSGAAAAAAAAKBjSmEAAAAAAACAjimFAQAAAAAAADqmFAYAAAAAAADomFIYAAAAAAAAoGNKYQAAAAAAAICOKYUBAAAAAAAAOqYUBgAAAAAAAOiYUhgAAAAAAACgY0phAAAAAAAAgI4phQEAAAAAAAA6phQGAAAAAAAA6JhSGAAAAAAAAKBjSmEAAAAAAACAjimFAQAAAAAAADqmFAYAAAAAAADomFIYAAAAAAAAoGNKYQAAAAAAAICOKYUBAAAAAAAAOqYUBgAAAAAAAOiYUhgAAAAAAACgY0phAAAAAAAAgI4phQEAAAAAAAA6phQGAAAAAAAA6JhSGAAAAAAAAKBjSmEAAAAAAACAjimFAQAAAAAAADqmFAYAAAAAAADomFIYAAAAAAAAoGNKYQAAAAAAAICOKYUBAAAAAAAAOqYUBgAAAAAAAOiYUhgAAAAAAACgY0phAAAAAAAAgI4phQEAAAAAAAA6phQGAAAAAAAA6JhSGAAAAAAAAKBjSmEAAAAAAACAjimFAQAAAAAAADqmFAYAAAAAAADomFIYAAAAAAAAoGNKYQAAAAAAAICOKYUBAAAAAAAAOqYUBgAAAAAAAOiYUhgAAAAAAACgY0phAAAAAAAAgI4phQEAAAAAAAA6phQGAAAAAAAA6NieSb2jUsquJF+R5JlJnpzkCUk+P8lfJ3lvkl9N8hu11qNjjj81yQuTXJPk7CSfTvLOJC+ttb6t9foBAGjHrAgAwDhmRQCAnZvkK4W/KsltSX4wyT/MytB252gNX53k15P8bill/9oDSymPTvLuJNclOSfJB5MsJfmGJLeUUr57AusHAKAdsyIAAOOYFQEAdmiSpfCuJAeT/Jskp9daz6u1XlFr/cIk/yLJkawMYz+2zrGvTlKSvCfJ42qtlyU5K8m1o/O+rJRyyQQ+BgAA2jArAgAwjlkRAGCHJlkKvytJqbW+rNb68dV31Fpfm88Nbd9RSjm+rlLKpVm5NMxykufUWv9ydMzRWusrk7w2ySlJrp/AxwAAQBtmRQAAxjErAgDs0MRK4Vrr39ZaH9xglxtH29OSfNGq/79mtL2l1nrPOse9YrS9upTyiB0uEwCAKTArAgAwjlkRAGDnJvlK4c3Mr7q9uOr2laPtrWOOe1dWLhEzl8SlXgAA+mRWBABgHLMiAMAm9kx7Aav809H2zlrr3676/wtG23vXO6jW+mAp5S+SnJ+Vvw9yW4vFzc3PtTjtSWl1lnIdzlZyXVic3/B+/q6Fhfl1b7Mzcm1Htm20zHX37ofT8/Qeth7Ws6LPteH4GtbGVnJdmJP7VsyvynPeY3Ywcm1Htm20zNWseELMiicJs2IbW5oV9/l97lZ4zLYh13Zk28bD5feKD4tSuJRyeZLvGr35kjV3nzbafnKDUxy771FDrmu1t9311lanPqnJtQ25tvOxj75/2kvoklzbkW0bcp2sWZgVPSbakGsbcm3n7oO3T3sJXZJrO7JtQ66TZVY8ecm1Dbm2c/DQu6e9hC7JtR3ZtjHNXKf+VMNSyulJfisrBfVv11pfv2aXY089emCD0xwZbT1tAQCgI2ZFAADGMSsCAJy4qb5SuJTyBUluTHJWkvck+dZ1dltKspBk3wan2j/aLm6wz4489aKrs7S41Or0J5W5+bnjr2SV63C2kutdnzg0qWV1YWFh/vizJE8/4+IcPtzsS81JRa7tyLaNlrne+vYbcuklFw92vl7M0qzoc204voa1sZVcHzl36qSW1YX5hfnjrwq84Nwrs+gxOwi5tiPbNlrm+pabXpcnHrhwsPP1wqx4cjIrtrGVXF0+emsWFuaPvyrw3LOv8JgdiFzbkW0bLXO96eY35MCBi05o36mVwqWUU5P8fpJLk9yV5GvX/M2PY+7PyvB22jr3HXPaqn2bWFpcytJh5eXQ5NrGZrn6Qr59hw8vyq8BubYj2zaGznV5eXmwc/Vi1mZFn2ttyLWNzXLdt3zKBFfTl0WP2Sbk2o5s2xg6V7PiQ5kVSeTayqa5fvbo5BbTGY/ZNuTajmzbmObvFady+ehSykKStyS5MsmHkvzjWusnxux+92h7/phz7c3KMwJX7wsAwIwyKwIAMI5ZEQBgeyZeCpdS5pK8OclXJjmU5Gm11r/a4JDbR9unjLn/SVm5BMxSkvcNtU4AACbPrAgAwDhmRQCA7ZtoKTx69t1vJnlako8k+apa619sctibRturSinrPavv2tH2xlrrp4dZKQAAk2ZWBABgHLMiAMDOTKwULqWckuQ3klyd5K+yMrj96WbH1VrvSPJ7SU5J8vpSyhmj8+0qpTw3ybckWU7y463WDgBAW2ZFAADGMSsCAOzcngm+r2cnuWZ0eynJL5dSxu37vFrre1e9/e1JbktyeZKDpZQPJHl0kscmOZrk+aMhDwCA2WRWBABgHLMiAMAOTbIU3r/q9jmjf+N8weo3aq33lVIuT/LCrAyAFyb5TJIbk/znWusfDbpSAAAmzawIAMA4ZkUAgB2aWClca31Nktfs4PhPJblu9A8AgI6YFQEAGMesCACwcxP7m8IAAAAAAAAATJ5SGAAAAAAAAKBjSmEAAAAAAACAjimFAQAAAAAAADqmFAYAAAAAAADomFIYAAAAAAAAoGNKYQAAAAAAAICOKYUBAAAAAAAAOqYUBgAAAAAAAOiYUhgAAAAAAACgY0phAAAAAAAAgI4phQEAAAAAAAA6phQGAAAAAAAA6JhSGAAAAAAAAKBjSmEAAAAAAACAjimFAQAAAAAAADqmFAYAAAAAAADomFIYAAAAAAAAoGNKYQAAAAAAAICOKYUBAAAAAAAAOqYUBgAAAAAAAOiYUhgAAAAAAACgY0phAAAAAAAAgI4phQEAAAAAAAA6phQGAAAAAAAA6JhSGAAAAAAAAKBjSmEAAAAAAACAjimFAQAAAAAAADqmFAYAAAAAAADomFIYAAAAAAAAoGNKYQAAAAAAAICOKYUBAAAAAAAAOqYUBgAAAAAAAOiYUhgAAAAAAACgY0phAAAAAAAAgI4phQEAAAAAAAA6phQGAAAAAAAA6JhSGAAAAAAAAKBjSmEAAAAAAACAjimFAQAAAAAAADqmFAYAAAAAAADomFIYAAAAAAAAoGNKYQAAAAAAAICOKYUBAAAAAAAAOqYUBgAAAAAAAOiYUhgAAAAAAACgY0phAAAAAAAAgI4phQEAAAAAAAA6phQGAAAAAAAA6JhSGAAAAAAAAKBjSmEAAAAAAACAju2Z9gJKKVcnecvozUO11nPG7HdqkhcmuSbJ2Uk+neSdSV5aa31b+5UCADBpZkUAAMYxKwIAnLipvlJ4NJD94gns9+gk705yXZJzknwwyVKSb0hySynluxsuEwCAKTArAgAwjlkRAGBrpn356J9IclaSGzbZ79VJSpL3JHlcrfWy0XHXJtmV5GWllEtaLhQAgIkzKwIAMI5ZEQBgC6ZWCpdSrkzyPVkZ3H5ng/0uTfLMJMtJnlNr/cskqbUerbW+Mslrk5yS5PrmiwYAYCLMigAAjGNWBADYuqmUwqWUvUleleRwku/dZPdrRttbaq33rHP/K0bbq0spjxhoiQAATIlZEQCAccyKAADbM61XCv9QkouTXF9r/fAm+1452t465v53JTmSZC6JS70AAMw+syIAAOOYFQEAtmHPpN9hKeUJSf5DkjuSvPwEDrlgtL13vTtrrQ+WUv4iyflZ+fsgtw2xzrXm5udanPaktDpLuQ5nK7kuLM63Xk5XFhbm173Nzsi1Hdm20TLX3bun9hc9HnZmdVb0uTYcX8Pa2EquC3Ny34r5VXnOe8wORq7tyLaNlrmaFT/HrIhZsY0tzYr7/D53Kzxm25BrO7Jt4+Hye8WJlsKllF1ZubzL3iTX1lr/3wkcdtpo+8kN9jl236N2sLwNve2ut7Y69UlNrm3ItZ2PffT9015Cl+TajmzbkGsbszwreky0Idc25NrO3Qdvn/YSuiTXdmTbhlzbMCuyllzbkGs7Bw+9e9pL6JJc25FtG9PMddJPNfzXSf5hkp+rtZ7oR33sqUcPbLDPkdHW0xYAAGaXWREAgHHMigAAOzCxVwqXUs5M8pNJPpLkh7dw6FKShST7Nthn/2i7uL3Vbe6pF12dpcWlVqc/qczNzx1/Jatch7OVXO/6xKFJLasLCwvzx58lefoZF+fw4WZfak4qcm1Htm20zPXWt9+QSy+5eLDzzaJZnxV9rg3H17A2tpLrI+dOndSyujC/MH/8VYEXnHtlFj1mByHXdmTbRstc33LT6/LEAxcOdr5ZZFbkGLNiG1vJ1eWjt2ZhYf74qwLPPfsKj9mByLUd2bbRMtebbn5DDhy46IT2neTlo1+e5POTfFut9VNbOO7+rAxvp22wz2mr9m1iaXEpS4eVl0OTaxub5eoL+fYdPrwovwbk2o5s2xg61+Xl5cHONcNmelb0udaGXNvYLNd9y6dMcDV9WfSYbUKu7ci2jaFzNSsmMSuyDrm2sWmunz06ucV0xmO2Dbm2I9s2pvl7xUmWwpeNtr9QSvmFNfcduzzLY0spfzW6/U211v+Z5O4kZyY5f72TllL2Jjlr9ObdA64XAIDJMSsCADCOWREAYIcmWQofc/oG9+1edf+xy7rcnuSqJE8Zc8yTRvsuJXnfEAsEAGBqzIoAAIxjVgQA2KaJlcK11nPG3VdK+dYkv5Lk0Dr7vSnJDyW5qpRyfq31njX3Xzva3lhr/fQwqwUAYJLMigAAjGNWBADYud3TXsBmaq13JPm9JKckeX0p5YwkKaXsKqU8N8m3JFlO8uPTWyUAANNgVgQAYByzIgDA50zj8tHb8e1JbktyeZKDpZQPJHl0kscmOZrk+aMhDwCAk49ZEQCAccyKAACZgVcKJ0mt9b6sDG4/keRQkguTPCLJjUmeVmt9+RSXBwDAFJkVAQAYx6wIALDiYfFK4Vrra5K8ZpN9PpXkutE/AABOEmZFAADGMSsCAJyYmXilMAAAAAAAAADboxQGAAAAAAAA6JhSGAAAAAAAAKBjSmEAAAAAAACAjimFAQAAAAAAADqmFAYAAAAAAADomFIYAAAAAAAAoGNKYQAAAAAAAICOKYUBAAAAAAAAOqYUBgAAAAAAAOiYUhgAAAAAAACgY0phAAAAAAAAgI4phQEAAAAAAAA6phQGAAAAAAAA6JhSGAAAAAAAAKBjSmEAAAAAAACAjimFAQAAAAAAADqmFAYAAAAAAADomFIYAAAAAAAAoGNKYQAAAAAAAICOKYUBAAAAAAAAOqYUBgAAAAAAAOiYUhgAAAAAAACgY0phAAAAAAAAgI4phQEAAAAAAAA6phQGAAAAAAAA6JhSGAAAAAAAAKBjSmEAAAAAAACAjimFAQAAAAAAADqmFAYAAAAAAADomFIYAAAAAAAAoGNKYQAAAAAAAICOKYUBAAAAAAAAOqYUBgAAAAAAAOiYUhgAAAAAAACgY0phAAAAAAAAgI4phQEAAAAAAAA6phQGAAAAAAAA6JhSGAAAAAAAAKBjSmEAAAAAAACAjimFAQAAAAAAADqmFAYAAAAAAADomFIYAAAAAAAAoGNKYQAAAAAAAICOKYUBAAAAAAAAOqYUBgAAAAAAAOiYUhgAAAAAAACgY0phAAAAAAAAgI4phQEAAAAAAAA6phQGAAAAAAAA6JhSGAAAAAAAAKBje6b1jkspVyf5jiRXJvnCJPcnuTfJHyX50VrrZ9fsvzfJ85N8c5LzkzyQ5H1JXl5r/a0JLh0AgMbMigAAjGNWBADYuom/UriUsqeU8tokb0nyT5J8NsmdST6T5Iok1yWZW3PMXJJbkvx0kouS3JPkE0memuQ3SykvmdT6AQBox6wIAMA4ZkUAgO2bxuWjfzErz8r74ySX1VrPqrU+qdZ6XpJHJfnGJEfWHPNTSZ6c5GCSi2qtB2qt56/a9wdLKc+Y2EcAAEArZkUAAMYxKwIAbNNES+FSylVZubTLnyV5Wq31vavvr7UerrW+udb64KpjTk/yXaM3/1Wtta7a/81ZeZZfkvxow6UDANCYWREAgHHMigAAOzPpVwp//2j7M7XWT53gMc9Msi/Jh2qtf7TO/a8YbS8rpZy30wUCADA1ZkUAAMYxKwIA7MCeSb2j0d/v+JrRmzeXUi5M8twkF2blUi3vTfLqWuuhNYdeOdq+Y73z1lo/Uko5mOTc0b73Dr12AADaMisCADCOWREAYOcmVgonOZBk7+j2U5L8XFaeqXfM05O8oJTybbXW1636/wtG242GsnuzMryVgdb6EHPzc61OfdJZnaVch7OVXBcW51svpysLC/Pr3mZn5NqObNtomevu3ZO+eMvD0kzPij7XhuNrWBtbyXVhTu5bMb8qz3mP2cHItR3ZttEyV7NiErMiI2bFNrY0K+7z+9yt8JhtQ67tyLaNh8vvFSdZCp+x6vbPJ7kjyfOS3JnkrCT/Kcmzk/xqKeVPVv1dkNNG209ucO5j9z1quOX+XW+7662tTn1Sk2sbcm3nYx99/7SX0CW5tiPbNuTaxEzPih4Tbci1Dbm2c/fB26e9hC7JtR3ZtiHXJsyKPIRc25BrOwcPvXvaS+iSXNuRbRvTzHWSpfCpq24fTvL1tdb7R2/fU0r5p1l59t4lSa5Lcs3ovmNPPXpgg3MfGW09bQEAYDaZFQEAGMesCACwQ5MshZdW3X7NqsEtSVJrXS6l/Jckv5rka0opu2uty6uOW31JmLX2j7aLg612jadedHWWFpc235FNzc3PHX8lq1yHs5Vc7/rE2j+xw0YWFuaPP0vy9DMuzuHDzb7UnFTk2o5s22iZ661vvyGXXnLxYOebUTM9K/pcG46vYW1sJddHzp069j4ean5h/virAi8498oseswOQq7tyLaNlrm+5abX5YkHLhzsfDPKrEgSs2IrW8nV5aO3ZmFh/virAs89+wqP2YHItR3ZttEy15tufkMOHLjohPadZCm8elj74Jh9jv3/5yX5wiT3rTrutHWP+Lv33b/BPjuytLiUpcPKy6HJtY3NcvWFfPsOH16UXwNybUe2bQyd6/Ly8mDnmmEzPSv6XGtDrm1sluu+5VMmuJq+LHrMNiHXdmTbxtC5mhWTmBVZh1zb2DTXzx6d3GI64zHbhlzbkW0b0/y94on/9eGd+5NVt8ddsmV1i3VsbXePtudvcO7z1uwLAMBsMSsCADCOWREAYIcmVgrXWj+S5Ng1ax83ZrdjQ9hSkk+Mbt8+2j55vQNKKWcmOXfNvgAAzBCzIgAA45gVAQB2bpKvFE6S/z7a/vNSynqXrv720fbttdbPjm7fkOTBJI8vpVy1zjHXjrbvrbXeM9xSAQCYMLMiAADjmBUBAHZg0qXwS5P8TVaegfdzpZS5JCml7CqlfF+SZyQ5muQlxw6otX4syStGb766lFKO3VdKeUaSF4zefFH75QMA0JBZEQCAccyKAAA7sN6z6pqptd5XSrkmyZuz8ky855RS7k7ypUnOyMrg9oJa69vWHPqCJJcn+Yokd5VS3p/k1HzusjA/U2u9YQIfAgAAjZgVAQAYx6wIALAzk36lcGqtNyc5kOQ1ST6V5JIke7My0F1Va33pOscsJnlqkhcm+UCSC5I8Osnbk1xTa/33k1g7AABtmRUBABjHrAgAsH0TfaXwMbXWDyX5ti0e80CSnxr9AwCgU2ZFAADGMSsCAGzPxF8pDAAAAAAAAMDkTOWVwrPoHe/8paz8aRJ2btfxW3Id0onn+oNfdt0E1tOPffP7j9/+ni95ch5YPDLF1fRjqFw9u+mhVmf7PI/ZwbTM9fS9pw52Lqbjskefn6XFpWkvowtz83PHb8t1OFvJ9X/c+cuTWFJHPjeH/+n7fzt+vhnKMLkuf/r+gdbTkV2fm6DveeevJEeXp7iYjjTMde+XnDvYuZiOq06/OEf8XDaI/at+LpPrcLaS65tvuX4SS+rHqu8Pf/6/fsn33aEMlOvuR37xUCvqyOfm8A9/4Hfj55uhtMt1zyO/9IT39bt0AAAAAAAAgI4phQEAAAAAAAA6phQGAAAAAAAA6JhSGAAAAAAAAKBjSmEAAAAAAACAjimFAQAAAAAAADqmFAYAAAAAAADomFIYAAAAAAAAoGNKYQAAAAAAAICOKYUBAAAAAAAAOqYUBgAAAAAAAOiYUhgAAAAAAACgY0phAAAAAAAAgI4phQEAAAAAAAA6phQGAAAAAAAA6JhSGAAAAAAAAKBjSmEAAAAAAACAjimFAQAAAAAAADqmFAYAAAAAAADomFIYAAAAAAAAoGNKYQAAAAAAAICOKYUBAAAAAAAAOqYUBgAAAAAAAOiYUhgAAAAAAACgY0phAAAAAAAAgI4phQEAAAAAAAA6phQGAAAAAAAA6JhSGAAAAAAAAKBjSmEAAAAAAACAjimFAQAAAAAAADqmFAYAAAAAAADomFIYAAAAAAAAoGNKYQAAAAAAAICOKYUBAAAAAAAAOqYUBgAAAAAAAOiYUhgAAAAAAACgY0phAAAAAAAAgI4phQEAAAAAAAA6phQGAAAAAAAA6JhSGAAAAAAAAKBjSmEAAAAAAACAjimFAQAAAAAAADqmFAYAAAAAAADomFIYAAAAAAAAoGNKYQAAAAAAAICOKYUBAAAAAAAAOqYUBgAAAAAAAOiYUhgAAAAAAACgY0phAAAAAAAAgI7tmfQ7LKV8YZLvT/L0JI9Lsi/Jx5P8zyQvq7X+jzHHnZrkhUmuSXJ2kk8neWeSl9Za39Z+5QAAtGZWBABgHLMiAMD2TfSVwqWUxyf5P0l+KMlFST6W5K4kn5/kWUluLaX823WOe3SSdye5Lsk5ST6YZCnJNyS5pZTy3ZNYPwAA7ZgVAQAYx6wIALAzk7589H9LckaSDyX5+7XW82qtlyZ5TJKfSbIryU+PhrzVXp2kJHlPksfVWi9LclaSa0fHvKyUcsmEPgYAANowKwIAMI5ZEQBgByZWCpdSPi/JVaM3f6DW+oFj99Val5L8QJJ7snJJ669dddylSZ6ZZDnJc2qtfzk65mit9ZVJXpvklCTXT+LjAABgeGZFAADGMSsCAOzcJF8pvD8rz75LknvX3llrPbrq//euuuua0faWWus965z3FaPt1aWURwyxUAAAJs6sCADAOGZFAIAdmlgpXGv9v0k+PHrzH6y9fzR4HbtUy7tW3XXlaHvrmFO/K8mRJHOrjgcAYIaYFb5TVzEAACAASURBVAEAGMesCACwc3sm/P5emJXLsvznUspykt9L8rdJLk7yk0lOT/LrtdbbVh1zwWj7kGcBJkmt9cFSyl8kOT8rfx/ktvX227ldm+/CCdo15jY7c+K57pvf33Ypndk7v2/d2+zMULlO8pIXs8Jjto2Wue7a7ZE8MrOz4pzvrYNZnaVch7O1XM3oW+PnmzYGynWX77EPsToT+Qynaa6+tozM7Ky430wzmNVZynU4W8rV946t8X23jcFy9T32ofx808bDI9ddR48eneg7LKU8PckPJ/nyNXd9NMmPJXnF6JIvx/b/TJKFJF9fa/39Med8Z5InJfn3tdafGWip70ly2UDnAgA4EXckuXzai5gmsyIAwFhmRbMiAMA4m86K03hqyvlJHpNkOcmfJfnfSQ4nOSPJtya5aM3+c6PtAxuc88hoOz/UIgEAmAqzIgAA45gVAQC2aaKXjy6l/HyS707yx0m+rtZ69+j/55O8KMkPJLmtlPLEWuuh0WFLWXlG30bXaTx2TYvFJgtP8uB9B5NM9lXV/dqVvV90bhK5DuvEc73+K180oTX1Ye/8vrz4jlclSa6/7Dvz4OJGP0tyoobK1YV3Hmrv/L68aJTtj3jMDqZlrt/zphflzIvOGex8s2qWZ8WvvfiZWVo8svmObGpufn/+4P1vTiLXIW0l15tv/8VJLasTfr5pY5hclz/z1wOuqRO7dmf/2St/OvXIofclR5envKBONMx17xl/L7v3Lwx2vlk1y7Pisw48O0fMNIPYP78/b7zzDUnkOqSt5PrGt75wUsvqw67d2X/eysUNjtz7Tt93hzJQrru/4PQhV9UJP9+00S7XPY88M7v2ntifVJhYKVxKeWKSf53kwSTPWjWcpda6mOQFpZTLkjwtyQ8l+a7R3fdnZXg7bYPTn7Zq30aOxoO/Bbm2sXGuDxiYt+3BxQfk18BOclUKb8xjto2hcz267IfCWZ8VlxaPZGlxqdXpT1pybWPzXM3n2+fnmzZ2kKtfvG7s6LKMWhg8V19XZn1WPLJ4RHnZgFzb2DRX3ze2z/fdNnaUq++xG/PzTRvTy3WSv0t/clb+evKHVg9ua9w02l6x6v/uHm3PX++AUsreJGet2RcAgNliVgQAYByzIgDADk2yFP68Lew7t+r27aPtU8bs+6SsXAJmKcn7trEuAACmz6wIAMA4ZkUAgB2aZCl87Nl2jy+lnD1mn68Zbeuq/3vTaHtVKWW9Z/VdO9reWGv99A7XCADAdJgVAQAYx6wIALBDkyyFb0ry8SR7k7yxlHLBsTtKKfOllJ/Oyt/9SJJfO3ZfrfWOJL+X5JQkry+lnDE6Zlcp5blJviXJcpIfn8hHAQBAC2ZFAADGMSsCAOzQnkm9o1rrZ0op/zzJ7yT5siQfLKUcSvKprPxdj4XRrj9fa71hzeHfnuS2JJcnOVhK+UCSRyd5bFb+GvPzR0MeAAAzyKwIAMA4ZkUAgJ2b5CuFU2u9OckTk/xcVi778sVJnpDkb5LckOTptdbvXee4+7IyuP1EkkNJLkzyiCQ3JnlarfXlE/kAAABoxqwIAMA4ZkUAgJ2Z2CuFj6m1/mmS523juE8luW70DwCADpkVAQAYx6wIALB9E32lMAAAAAAAAACTpRQGAAAAAAAA6JhSGAAAAAAAAKBjSmEAAAAAAACAjimFAQAAAAAAADqmFAYAAAAAAADomFIYAAAAAAAAoGNKYQAAAAAAAICOKYUBAAAAAAAAOqYUBgAAAAAAAOiYUhgAAAAAAACgY0phAAAAAAAAgI4phQEAAAAAAAA6phQGAAAAAAAA6JhSGAAAAAAAAKBjSmEAAAAAAACAjimFAQAAAAAAADqmFAYAAAAAAADomFIYAAAAAAAAoGNKYQAAAAAAAICOKYUBAAAAAAAAOqYUBgAAAAAAAOiYUhgAAAAAAACgY0phAAAAAAAAgI4phQEAAAAAAAA6phQGAAAAAAAA6JhSGAAAAAAAAKBjSmEAAAAAAACAjimFAQAAAAAAADqmFAYAAAAAAADomFIYAAAAAAAAoGNKYQAAAAAAAICOKYUBAAAAAAAAOqYUBgAAAAAAAOiYUhgAAAAAAACgY0phAAAAAAAAgI4phQEAAAAAAAA6phQGAAAAAAAA6JhSGAAAAAAAAKBjSmEAAAAAAACAjimFAQAAAAAAADqmFAYAAAAAAADomFIYAAAAAAAAoGNKYQAAAAAAAICOKYUBAAAAAAAAOqYUBgAAAAAAAOiYUhgAAAAAAACgY0phAAAAAAAAgI4phQEAAAAAAAA6phQGAAAAAAAA6JhSGAAAAAAAAKBjSmEAAAAAAACAju3ZzkGllC9O8tVJvmz075Ikc0neXmt96ibH7k3y/CTfnOT8JA8keV+Sl9daf2uTYy9N8sIk/yjJI5P8ZZLfTfLjtdb7tvOxAAAwLLMiAADjmBUBAKZju68Ufk6SX0vyvCRXZmVw21QpZS7JLUl+OslFSe5J8okkT03ym6WUl2xw7DcleWeSZyfZleSuJI9J8n1J7iylPG6bHwsAAMMyKwIAMI5ZEQBgCrZbCv9tkpuT/GSSb0ry4hM87qeSPDnJwSQX1VoP1FrPT/KNSY4k+cFSyjPWHlRKOTPJa5PsHb2vM2utlyc5M8nvJzkjyX8vpeza5scDAMBwzIoAAIxjVgQAmIJtlcK11l+utX51rfU/1Fp/O8nHNzumlHJ6ku8avfmvaq111fnenJVn+SXJj65z+A8kWUhya631P9ZaPzs67m+S/LMkf5PkiiRP387HAwDAcMyKAACMY1YEAJiO7b5SeDuemWRfkg/VWv9onftfMdpeVko5b81914y2r1x7UK31/iRvHL357CEWCgDAxJkVAQAYx6wIALBDeyb4vq4cbd+x3p211o+UUg4mOXe0771JUkp5bFYu55Ikt4459zuSfMeq99GAK8gMZ9eY2+zMiee6b35/26V0Zu/8vnVvszND5TrJZzfNCo/ZNlrmumu3R3JmfFac8711MKuzlOtwtparGX1r/HzTxkC57vI99iFWZyKf4TTN1deWzPisuN9MM5jVWcp1OFvK1feOrfF9t43BcvU99qH8fNPGwyPXSZbCF4y2926wz71ZGd7KOsc9kOTDGxyXJI8rpeyttT647VWOsfeLzh36lESurWyW60s++KsTWkl/XnzHq6a9hC7JtZ0XybYJuTYx07PiH7z/zUOfksi1Fbm24+ebNnaU6xcNt44e7T/7kmkvoUtybWKmZ8U33vmGoU9J5NqKXNvZf96XT3sJXZJrO36+aWOauU7yqSmnjbaf3GCfY/c9ap3j7q+1Ht3kuN1JPn97ywMAYIrMigAAjGNWBADYoUm+UnhutH1gg32OjLbz2zxu7bGDefC+g0nGzY5sza7jz4SQ65BOPNfrv/JFE1pTH/bO7zv+StbrL/vOPLi40ZcjTtRQubrwzkPtnd93/JWsP+IxO5iWuX7Pm16UMy86Z7DzzaiZnhW/9uJnZmnxyOY7sqm5+f3HX8kq1+FsJdebb//FSS2rE36+aWOYXJc/89cDrqkTu3YffyXrkUPvS44uT3lBnWiY694z/l52718Y7HwzaqZnxWcdeHaOmGkGsX9+//FXssp1OFvJ9Y3/n707j5bsLugE/n2d7vSSSEiQAEYgEMKPfQuyjOwScVRgBgkjzgCNsnk8KI6oMAIOxAXwOODgQZYBQQ6bCcgiIgjIorIpEUmUH0sS9j1hkXR3gt3zx70veXm8et2v3r1Vr379+ZyTc19V3Vv961/uq/pWf2/d+1dPmtWw2rC07cpvsh749Ae97w5loHnddsJ1hhxVI3y+Gcd487r9mqdkaceRXVJhlqXw/n653kX4lke9b8rtVm87oEOx84/BvI5j/Xm9XGCe2hX7Ljd/I9jMvCqF12efHcfQ83rooA+FWfCsuH/fgezft//wK7Ih5nUch59X+Xx6Pt+MYxPz6h9e13fooDkaw+Dz6nUlC54VD+w7oLwcgXkdx2Hn1fvG9LzvjmNT8+o9dn0+34xjfvM6y39Lv7RfnrTOOlee0mWN7U4spUy6+vLydgeTfHu64QEAMEeyIgAAk8iKAACbNMtS+BP98ibrrHPaqnVX/nxskusfZruLaq1XTDc8AADmSFYEAGASWREAYJNmWQp/oF/eba0HSymnJLnRqnVTa/1ski/2N+8+4bmX73//JscIAMB8yIoAAEwiKwIAbNIsS+E3JrkiyemllHuv8fhj++V5tdZPrXrsdf3yMas3KqWcmOSs/uY5QwwUAICZkxUBAJhEVgQA2KSZlcK11q8keWF/8yWllLL8WCnl/kl+o7/59DU2/4Mk+5Lco5TyjFLKMf12JyR5VZITkpyX5M0jDR8AgBHJigAATCIrAgBs3vZpNiqlXD9dWFq2q1/+aCnl6yvuf3at9dkrbv9GkjOS3DXJBaWU85Mcn6uu3fGHtdY3rv7zaq2fK6U8PMmrkzw1yWNLKZ9LcrMkxyX5SpKH1FoPTfP3AQBgOLIiAACTyIoAAPMx7TeFj0lyrRX/Hdffv33V/XtWblRr3ZfkXkmelORfk9w0yQ8meU+SB9danzjpD6y1npvkzknO7e+6dZKvJfnjJLdZ49QwAADMh6wIAMAksiIAwBxM9U3hWuvFSZam3PbyJM/q/9voth/JVdf5AABgC5IVAQCYRFYEAJiPmV1TGAAAAAAAAIDZUwoDAAAAAAAANEwpDAAAAAAAANAwpTAAAAAAAABAw5TCAAAAAAAAAA1TCgMAAAAAAAA0TCkMAAAAAAAA0DClMAAAAAAAAEDDlMIAAAAAAAAADVMKAwAAAAAAADRMKQwAAAAAAADQMKUwAAAAAAAAQMOUwgAAAAAAAAANUwoDAAAAAAAANEwpDAAAAAAAANAwpTAAAAAAAABAw5TCAAAAAAAAAA1TCgMAAAAAAAA0TCkMAAAAAAAA0DClMAAAAAAAAEDDlMIAAAAAAAAADVMKAwAAAAAAADRMKQwAAAAAAADQMKUwAAAAAAAAQMOUwgAAAAAAAAANUwoDAAAAAAAANEwpDAAAAAAAANAwpTAAAAAAAABAw5TCAAAAAAAAAA1TCgMAAAAAAAA0TCkMAAAAAAAA0DClMAAAAAAAAEDDlMIAAAAAAAAADVMKAwAAAAAAADRMKQwAAAAAAADQMKUwAAAAAAAAQMOUwgAAAAAAAAANUwoDAAAAAAAANEwpDAAAAAAAANAwpTAAAAAAAABAw5TCAAAAAAAAAA1TCgMAAAAAAAA0TCkMAAAAAAAA0DClMAAAAAAAAEDDlMIAAAAAAAAADVMKAwAAAAAAADRMKQwAAAAAAADQMKUwAAAAAAAAQMOUwgAAAAAAAAANUwoDAAAAAAAANEwpDAAAAAAAANCw7dNsVEq5bpIzk/xI/9/tkuxK8p5a670mbPMDSe6f5H79NqemK6W/kOTdSZ5Taz3/MH/u7ZM8Kck9k1wzyReTvDnJ79RavzbN3wUAgGHJigAATCIrAgDMx7TfFP7ZJH+W5PFJ7pIuuB3O85O8MsnD0wW3T/b/nZLk55N8pJTyyEkbl1IelOSDSR6SZCnJBUlOTvLLST5aSrnxlH8XAACGJSsCADCJrAgAMAfTlsLfTvKOJL+f5EFJzj7C7d6S5KeSXLPWetta662T/FCSVyXZkeTFpZRbr96olHJKklf065yd5JRa6xnpgt9fJ7lekteWUpam/PsAADAcWREAgElkRQCAOZjq9NG11pcmeeny7T5cHc4Taq3fWOO5Liml7E1y2yS3TPILSZ6warVfT7InyXtrrU9bse23Sik/l+SiJHdM8tPpTvsCAMCcyIoAAEwiKwIAzMe03xTesLWC24rHrkjyzv5mWWOVB/fLF62x7aVJzulvPmQzYwQAYD5kRQAAJpEVAQA2b6pvCo9kd7+8bOWdpZTrpzudS5K8d8K270vyqHTXIRmJM8gMZ2nCz2zOkc/rsbt3jjuUxuzYfeyaP7M5Q83rzI5uWiD22XGMOa9L2+zJR2BLZ8Vd3lsHs3IuzetwNjavMvrG+HwzjoHmdcl77PdZOSfmZzijzqvXliOwpbPiTplmMCvn0rwOZ0Pz6r1jY7zvjmOwefUe+/18vhnH1pjXLVEKl1L2JHlgf/N9qx6+ab+8PMnnJzzFp/vljUspO/ojBAe149o3GvopiXkdy+Hm9Zn/9vIZjaQ9Z3/kxfMeQpPM63iebm5HYV5naxGy4tvOf9PQT0nM61jM63h8vhnHpub12sONo0U7b3i7eQ+hSeZ1thYhK57z0T8f+imJeR2LeR3PztPuPO8hNMm8jsfnm3HMc163yqEpv5vk5CRfy4privRO6peX1loPTdj+kn65Lck1hh8eAABzJCsCADCJrAgAcATm/k3hUspDkzyhv/noWuu3V62yq19evs7THFjx8+6Ja23CFV+7KMmk7MjGLF15JIR5HdKRz+tT7/H0GY2pDTt2H3vlN1mfeodH54p9670ccaSGmtetcnTTVrJj97FXfpP1t+2zgxlzXn/p3KfnlFueOtjztWRRsuL9bvWA7N934PArcli7du+88pus5nU4G5nXd3zgT2Y1rEb4fDOOYeb14He/OeCYGrG07cpvsh74zD8nhw7OeUCNGHFed1zvZtm2c89gz9eSRcmKZ932ITkg0wxi5+6dV36T1bwOZyPzes5fPWlWw2rD0rYrv8l64NMf9L47lIHmddsJ1xlyVI3w+WYc483r9muekqUdR3ZJhbmWwqWUM5O8rL/5W7XWN66x2v5+ud7F+1b+bfcNMLQ1HIqdfwzmdRzrz+vlAvPUrth3ufkbwWbmVSm8PvvsOIae10MHfShcyyJlxf37DmT/vv2HX5ENMa/jOPy8yufT8/lmHJuYV//wur5DB83RGAafV68ra1mkrHhg3wHl5QjM6zgOO6/eN6bnfXccm5pX77Hr8/lmHPOb17n9W3op5R5J3pAulD2z1vp7E1a9tF+eWEqZdPXl5VPBHEyy+ohAAAAWjKwIAMAksiIAwMbNpRQupdw1yVuS7EnyvFrrk9dZ/RP98tgk15+wzmn98qJa6xXDjBIAgHmQFQEAmERWBACYzsxL4VLKGUnemuT4JC9J8ivrrV9r/WySL/Y37z5hteX73z/EGAEAmA9ZEQCASWRFAIDpzbQULqXcOsnbk5yQ5JVJHlNrPZITZ7+uXz5mjec8MclZ/c1zhhgnAACzJysCADCJrAgAsDkzK4VLKacn+Zt01+k4J8kjaq1HevXvP0iyL8k9SinPKKUc0z/nCUlelS4MnpfkzYMPHACA0cmKAABMIisCAGze9mk2KqVcP11YWrarX/5oKeXrK+5/dq312f3Pf5zkOv3PN0zynlLKWk//pVrrWSvvqLV+rpTy8CSvTvLUJI8tpXwuyc2SHJfkK0kecoRHBwIAMCJZEQCASWRFAID5mKoUTnJMkmtNeL6V9+9Z8fPOFT/faZ3n/sxad9Zazy2lXJjkyUnukeTW6a4J8qdJzq61fvUIxg0AwPhkRQAAJpEVAQDmYKpSuNZ6cZKlDW5zr2n+rFXP8ZFcdZ0PAAC2IFkRAIBJZEUAgPmY2TWFAQAAAAAAAJg9pTAAAAAAAABAw5TCAAAAAAAAAA1TCgMAAAAAAAA0TCkMAAAAAAAA0DClMAAAAAAAAEDDlMIAAAAAAAAADVMKAwAAAAAAADRMKQwAAAAAAADQMKUwAAAAAAAAQMOUwgAAAAAAAAANUwoDAAAAAAAANEwpDAAAAAAAANAwpTAAAAAAAABAw5YOHTo07zFsVd9IctLyjUNXHJjjUNqztGNnEvM6tCOd189//AuzGE4zlrZtyw/f8tQkyecvuDiHDh6c74AaMdS8Lg04plYsbduWU/q5/YJ9djBjzuvJNzklx+7emSSXJLnWYE/MmK6WFev5n/S7NpClbdtSbnV6EvM6pI3Ma7n5qTMaVTt8vhnHEPN66OD3hhpOQ5aybeeeJMnBA5cl8e9CwxhvXpd27MrStmMSWXGRXC0rfur8T+XQQb9rQ1jatpSb3OomSczrkDYyr6fd9HqzGlYztu06PklycP+/z3kkbRliXpeO2THUcJri8804RpvX7TuytLQtOYKsqBSe7LtJ9sx7EADAUeWyJMfNexAcEVkRAJg1WXFxyIoAwKwdNitun9FAFtFXk5ycZH+Si+c7FACgcacm2ZUuf7AYZEUAYFZOjay4aGRFAGBWTs0RZkXfFAYAAAAAAABo2LZ5DwAAAAAAAACA8SiFAQAAAAAAABqmFAYAAAAAAABomFIYAAAAAAAAoGFKYQAAAAAAAICGKYUBAAAAAAAAGqYUBgAAAAAAAGiYUhgAAAAAAACgYUphAAAAAAAAgIYphQEAAAAAAAAaphQGAAAAAAAAaJhSGAAAAAAAAKBhSmEAAAAAAACAhimFAQAAAAAAABqmFAYAAAAAAABomFIYAAAAAAAAoGHb5z2AraqUcu8kv5bkzkmOT/KZJOckeWat9bvzHNtWVEpZSnLXJA9IcrckN09yjSTfTHJekpcneVWt9dAa237ffat8pdZ63WFHvFhKKf87yW8fZrVfrLW+YI1tdyR5QpL/keQmSS5P8s9Jnldrff3AQ10YpZRTk1x0hKu/rNb6yBXbXpzkhofZZnetdf9Ug1sApZTrJjkzyY/0/90uya4k76m13usw2069T5ZSbp/kSUnumeSaSb6Y5M1JfqfW+rVN/JW2hGnmtZTyA0nun+R+/Tanpjvo6wtJ3p3kObXW8ydsuzfJnx5mWM+qtT5pY3+TrWfafXazv++llBsneUqSH09y7SRfTfL2dPvskb4GsQXJihsjK45LVhyerLg5suI4ZMXxyIoMTVbcGFlxXLLi8GTFzZEVxyErjqelrKgUXkMp5fFJ/ijJUpLPJ/lcklukm/yfKaXcrdZ6yRyHuBXdJ8k7Vty+MN0b443S/bKcmeShpZSfqbUemPAc/5hkrce+MeRAF9xXk3xywmNfWn1HKWVXkr9JF6j/I8kFSY5Lcq8k9yqlNPGiPKX9Sf5+ncd3JTmj//kfJqxzfpJvTXjs4JTjWhQ/m+Q5G91oM/tkKeVBSV6TZEe634ULkpQkv5zkrP61+cKN/1W2lGnm9fnpgnCS7Ev3GrEtyelJfj7Jw0opj621rhfSvp3kYxMeu3iD49mqptpnV9jw73sp5a7pgtrxSS5NN8enpfv/clYp5b611g9tYkzMiaw4FVlxNmTF4ciKmyMrjkNWHI+syGBkxanIirMhKw5HVtwcWXEcsuJ4msmKSuFVSilnJHluf/OxSV5caz1USvmhJG9K92L+4iQ/M6chblVL6cLac5O8ptb61eUHSikPSzdnP5XkGUl+c8JznFVrvXjkcS66t9Za925g/Wele5O8KMl/rrXWJCmlPCDJnyf5zVLK39da3zz4SLe4WuuX083Nmkopj0jysnRvhq+dsNrja63vHnxwi+Hb6T6wfbj/7/ZJnnoE2021T5ZSTknyinTB7ewkz6i1fq+UckK6QPcTSV5bSrnTWkcOL5Bp5/Ut6ULcO2qtlydJKeWkJM9L8nNJXlxK+cda66SAdt7hjsRswLRzu2xDv++llOOSvC5dcHtpkl+qte7vP8A8P8kjk7yulHLTWuu+DYyDOZMVpyYrzoasOBBZcdNkxXHIiuORFRmErDg1WXE2ZMWByIqbJiuOQ1YcTzNZ0TWFv99T083LK2qtL1p+Eai1fjHJQ9O19g8qpdxmjmPcij6UpNRa/+/K4JYktdZXpAttSfKoUor9bgZKKddJ8rj+5i8sv0kmSa31TUme3d/83zMe2qLY2y9fX2v99jwHshXVWl9aaz2z1vq/aq1/ke4Iu3Vtcp/89SR7kry31vq0Wuv3+u2+lS6cfCvJHZP89JR/pS1hmnlN8oRa60/XWv9qObj1z3VJuv34giTHJPmFUQa9IKac2814dJLrJflUksctnwamXz4uyaeT/HCSR408DoYnK05HVtxiZMVN29svZcU1yIrjkBXHIysyIFlxOrLiFiMrbtrefikrrkFWHIesOJ6WsqI30RVKKcenOyokSV60+vFa6yeTvKu/edasxrUIaq3frrVesc4qb+2XJ6U79znje0CSY5N8stb6t2s8/sJ+eYdSymmzG9bW118X5J79zZfNbyTN2cw++eB+udZr86Xprs2UJA8ZYqCLpNY68VRY/evyO/ubZTYjorecE162+v2xD9nLp9056vbZRSYrTk9W3JJkxSnJiqORFUcgK25ZsmKDZMXpyYpbkqw4JVlxNLLiCGTFLWu0rOj00Vd3+yQ7011/YtK5uN+X5L5J7jKrQTVi94qfJ32d/an96XS2p7uQ+buSvLZOvlbI0ei2pZRXJbluku8k+Zd0p9W5YI11l/fR9631RLXWL5RSlq/Pcpd0R5fQeUS6Uxd9Nld9YFvL40opT0y3f3853Vy/stb6nfGHuJCm2idLKddPckq/2nsnPPf70h0Z5bX5+y2//l62zjo3KKW8LMn1071G/1uS19VaPzDy2BbJEf++l1KOSXeEabL+PpskP1JKOabW+h9DD5hRyIrjkRWHISvOhqw4DllxPmTFYciKJLLimGTFYciKsyErjkNWnA9ZcRhbJiv6pvDV3bRffnado9OW3+AcGbExD+2XH13nlBk/n+6Iyvume/N8eZKPl1LuMIPxLYrbpZvLe6c7OuopST5WSnlO/2Kx0vL+vF4osz+vUkpZSrf/Jcmf1VrXvNB777+lu6bNfdKdauRPklxYSjlz3FEurGn3yeXtLk/y+cNsd+NSyo7phteeUsqeJA/sb64Zmns3Srff3yfdPv3EJO8vpby6fw429vt+arqjV5PJ+/vy/TuT3HC4YTIyWXE8suIwZMWRyYqjkhVnTFYclKxIIiuOSVYchqw4MllxVLLijMmKg9oyWVEpfHUn9ctL8YRm2QAAIABJREFU1lln+bETRx5LM0opZ+Sq8/0/c41V3pjuFA6npztS4trpAsqF6X4B3t4f0XM0+2KSpyW5c7r52ZXkNklekO7Isyck+f1V29ifp3PPdG9kyeRTvLw7ycOT3DzJcenm7/5Jzkvyg0ne5EPHmqbdJ5e3u3T5ekzrbLctyTWmG16TfjfJyUm+luSlazx+abprrtw93XUqdqYLzr+b5HtJfjZOdfTubPz3/aQVP0/a31fe7zV4cXhvHYGsOAhZcXZkxfHIirMnK27euyMrchXvrSOQFQchK86OrDgeWXH2ZMXNe3e2WFZ0+uir29UvL19nneVTjuxeZx16/QXgX59uX/uLWutrVq9Ta/0vq+7an+Q1pZR3JPmnJDdI8tuZ4qLZrai1ft/1DpJ8LMkv9qfFeFaSXy2lPL/WenH/uP15Onv75ftqrWseiVNr3bvqrsuS/GUp5Z1J/i7JHdK9Id53pDEuqmn3yY1st3rbo1Yp5aHpPtglyaPXOpq61vrGdB+gV/pEkqeUUv4lyWuTnFVKuVut9e9GHfAWNeXv+64VP0/ab+2zi8l768BkxWHIijO1t1/KisOTFWdIVhyGrMgq3lsHJisOQ1acqb39UlYcnqw4Q7LiMLZiVvRN4avb3y+PXWednf1y0vUr6JVSTkjy1nTh659y1ZviEam1fj1XHaX2X/vTb/D9/jDdEX/b0536ZZn9eYNKKcenO7o0meIoplrrviS/1d+8dynFkZJXN+0+uZHtVm97VOpPPfKy/uZv9SFtQ2qtf57kg/3NBw00tGYc5vd9/4qfJ+239tnF5L11QLLizMiKA5EVRycrzoisOD5Z8ajlvXVAsuLMyIoDkRVHJyvOiKw4vnlmRaXw1V3aL09aZ50rTzcw8lgWWv8m+NdJbp/kgiT3W+eaH+v5h355Utb//3LU6i8ivvwCe/qKh+zPG/fgdKdxuCzJOVM+x/I+uy3JjYcYVEOm3SeXfz5xnQ9xy9sdTDLNa00zSin3SPKGdKHhmbXW39vE0y3vz6evu9bRa9Lv+8r9d9L+vvJ+r8GLw3vrQGTF2ZEVByUrjktWnAFZcaZkxaOP99aByIqzIysOSlYcl6w4A7LiTM0lKyqFr+4T/fIG61xQ/LRV67JKf/HwtyS5S5JPJrlvrfUbUz7dyq/HO935ZMvztHKOlvfRm6yznf356vb2y3Nrrd+Z8jnss5NNu08u/3xskknXAVre7qJa6xXTDW/xlVLumu71d0+S59Van7zJp1zrtYWrTPp9v3jFY5P29+V99kCSzww7LEYkKw5AVpwLWXEYe/ulrDgOWXFksuLMyYpHH1lxALLiXMiKw9jbL2XFcciKI5MVZ24uWVEpfHXnpZvsnUnuNGGdu/fL989kRAumlLIryZuS3CPdzvhjtdYvb+Ipb9Uv9yeZNgAeDZbn6fMr7vtAv7zbWhuUUk5JcqNV6x61Sik3SrffJlOc4mWFW634+fMT1zo6TbVP1lo/m+5URslVr8GrHfWvzaWUM9KdWuv4JC9J8isDPO1ary1cZc3f91rr99Kd3iw5/D774f7IbBaDrLhJsuLcyIqbJCvOhKw4IllxLmTFo4+suEmy4tzIipskK86ErDgiWXEu5pIVlcIr9EfwvK2/+ZjVj5dSTk9yn/7mubMa16Loj4J8XZIfS/KFJPeptX5uE8+3Pcmv9Tff1f8ysEop5aeS3LK/+fYVD70xyRVJTi+l3HuNTR/bL8+rtX5qxCEuikckWUp3JM67N/E8v9kv/7XW+oVNjqk1m9knX9cv13ptPjHJWf3NaU/Ps9BKKbdO9/t/QpJXJnlMrfXQJp/zNkl+or/59vXWPYqt9/u+nBP2rv6WQCnl2CSP7G8elfvsopIVN0dWnA9ZcTCy4vhkxZHIinMjKx5lZMXNkRXnQ1YcjKw4PllxJLLi3MwlKyqFv9/ZSQ4leVgp5THL55kvpVwvyavTzdkbaq0fneMYt5xSyjFJXpXkJ5N8OV1wu/AItntmKeURpZQfWHX/9dPt+HdJ8r0kzxh+1IuhlHLLUsoLSym3XXX/tlLKQ9PNe5L8Za31w8uP11q/kuSF/c2XlFLKim3vn+Q3+ptPH2/0i6H/PX94f/Pl673plVKeWEp5fCnlWqvuv1Yp5YXprh+SJE8bZ7SLa5P75B8k2ZfkHqWUZ/SvOSmlnJDud+CEdEdlv3mk4W9Z/T8s/E26a0mck+QRtdaDR7DdNUopry2l/KfV11Qppdwv3dGBxyT5aJLXDz/yrW+Tv+8vTPd+eJMkL+iPeF8+8v0F6U7z8sUk/2+s8TMaWXEKsuJ4ZMXxyYqzISuOQ1Ycj6zIBLLiFGTF8ciK45MVZ0NWHIesOJ6tmhWXDh3aVOHfpFLKE5L8n3RH93wuydeT3CLd6V9qkrvVWr8+vxFuPatCxMXpjuib5PG11vP67d6Q5IFJ/iPJhUkuSfciXNLN//4kj6q1vnKckW99pZTbpXtTSrr5+Uy6QHuTJCf2978vyQNqrd9cte3uJO9Mctd0c3x+ulNALJ9z/g9rrU8c9S+wAEop90ryt+k+uJ1Wa71onXWfm+70GYfS7etfS7I7yc3Tnfv/YJIn11qfPe6o56v/gHXeirt2JTku3b75rRX3P3vlXGxmnyylPDjdh+jtSb6a7vX5Zv2f+5V0r80LfXTqNPNaSnlbkh/v7/9QuqMm1/KlWuvykY8ppVwzyaX9ze+kew0+kOSGSa7T339Bkp/sT7Wz0Kac2039vpdSfjTdNwWOSzfXFya5cbrX7n9Pcmat9ag/zdYikhU3TlYcj6w4Pllx42TFcciK45EVGZKsuHGy4nhkxfHJihsnK45DVhxPS1nRBZ7XUGt9binlY+lOMXLnJCene8M8N8nv11r/fZ7j26J2rvj51P6/SU5Y8fOfpDvi4Y5JTum3O5DuBeMdSf641vrpAce5iC5O8pR0b3Y3TxfadqULcm9NF5pfvda542ut+/pg8qtJ/nuSm6a7vs170l0s/nWrtzlK7e2X710vuPVe0y/vnOQGSW6bqz58vCfJ82ut/zzGILeYY5Jca437t6+6f8/KBzezT9Zazy2lXJjkyemu03LrdEdE/WmSs2utX536b7N1TDOvK19/J123Kunex1b6bpJfT/facqt0oe34dEHmb9O957201rr/iEa+9U0zt5v6fa+1/n1/NPZTk5yZ5DbpAuAb0+2zhz3yna1JVpyKrDieiyMrjm1vv5QVj5ysOA5ZcTyyIoORFaciK47n4siKY9vbL2XFIycrjkNWHE8zWdE3hQEAAAAAAAAa5prCAAAAAAAAAA1TCgMAAAAAAAA0TCkMAAAAAAAA0DClMAAAAAAAAEDDlMIAAAAAAAAADVMKAwAAAAAAADRMKQwAAAAAAADQMKUwAAAAAAAAQMOUwgAAAAAAAAANUwoDAAAAAAAANEwpDAAAAAAAANAwpTAAAAAAAABAw5TCAAAAAAAAAA1TCgMAAAAAAAA0TCkMAAAAAAAA0DClMAAAAAAAAEDDlMIAAAAAAAAADVMKAwAAAAAAADRMKQwAAAAAAADQMKUwAAAAAAAAQMOUwgAAAAAAAAANUwoDAAAAAAAANEwpDAAAAAAAANAwpTAAAAAAAABAw5TCAAAAAAAAAA1TCgMAAAAAAAA0TCkMAAAAAAAA0DClMAAAAAAAAEDDlMIAAAAAAAAADVMKAwAAAAAAADRMKQwAAAAAAADQMKUwAAAAAAAAQMOUwgAAAAAAAAANUwoDAAAAAAAANEwpDAAAAAAAANAwpTAAAAAAAABAw5TCAAAAAAAAAA1TCgMAAAAAAAA0TCkMAAAAAAAA0DClMAAAAAAAAEDDlMIAAAAAAAAADVMKAwAAAAAAADRMKQwAAAAAAADQMKUwAAAAAAAAQMOUwgAAAAAAAAANUwoDAAAAAAAANEwpDAAAAAAAANAwpTAAAAAAAABAw5TCAAAAAAAAAA1TCgMAAAAAAAA0TCkMAAAAAAAA0DClMAAAAAAAAEDDlMIAAAAAAAAADVMKAwAAAAAAADRMKQwAAAAAAADQMKUwAAAAAAAAQMOUwgAAAAAAAAANUwoDAAAAAAAANEwpDAAAAAAAANAwpTAAAAAAAABAw5TCAAAAAAAAAA1TCgMAAAAAAAA0TCkMAAAAAAAA0DClMAAAAAAAAEDDlMIAAAAAAAAADVMKAwAAAAAAADRMKQwAAAAAAADQMKUwAAAAAAAAQMOUwgAAAAAAAAANUwoDAAAAAAAANEwpDAAAAAAAANAwpTAAAAAAAABAw5TCAAAAAAAAAA1TCgMAAAAAAAA0TCkMAAAAAAAA0DClMAAAAAAAAEDDlMIAAAAAAAAADVMKAwAAAAAAADRMKQwAAAAAAADQMKUwAAAAAAAAQMOUwgAAAAAAAAANUwoDAAAAAAAANEwpDAAAAAAAANAwpTAAAAAAAABAw5TCAAAAAAAAAA1TCgMAAAAAAAA0TCkMAAAAAAAA0DClMAAAAAAAAEDDlMIAAAAAAAAADVMKAwAAAAAAADRMKQwAAAAAAADQMKUwAAAAAAAAQMOUwgAAAAAAAAANUwoDAAAAAAAANEwpDAAAAAAAANAwpTAAAAAAAABAw5TCAAAAAAAAAA1TCgMAAAAAAAA0TCkMAAAAAAAA0DClMAAAAAAAAEDDlMIAAAAAAAAADVMKAwAAAAAAADRMKQwAAAAAAADQMKUwAAAAAAAAQMOUwgAAAAAAAAANUwoDAAAAAAAANEwpDAAAAAAAANAwpTAAAAAAAABAw5TCAAAAAAAAAA1TCgMAAAAAAAA0TCkMAAAAAAAA0DClMAAAAAAAAEDDlMIAAAAAAAAADVMKAwAAAAAAADRMKQwAAAAAAADQMKUwAAAAAAAAQMOUwgAAAAAAAAANUwoDAAAAAAAANEwpDAAAAAAAANAwpTAAAAAAAABAw5TCAAAAAAAAAA1TCgMAAAAAAAA0TCkMAAAAAAAA0DClMAAAAAAAAEDDlMIAAAAAAAAADVMKAwAAAAAAADRMKQwAAAAAAADQMKUwAAAAAAAAQMOUwgAAAAAAAAANUwoDAAAAAAAANEwpDAAAAAAAANAwpTAAAAAAAABAw5TCAAAAAAAAAA1TCgMAAAAAAAA0TCkMAAAAAAAA0DClMAAAAAAAAEDDlMIAAAAAAAAADVMKAwAAAAAAADRMKQwAAAAAAADQMKUwAAAAAAAAQMOUwgAAAAAAAAANUwoDAAAAAAAANEwpDAAAAAAAANAwpTAAAAAAAABAw5TCAAAAAAAAAA1TCgMAAAAAAAA0TCkMAAAAAAAA0DClMAAAAAAAAEDDlMIAAAAAAAAADVMKAwAAAAAAADRMKQwAAAAAAADQMKUwAAAAAAAAQMOUwgAAAAAAAAANUwoDAAAAAAAANEwpDAAAAAAAANAwpTAAAAAAAABAw5TCAAAAAAAAAA1TCgMAAAAAAAA0TCkMAAAAAAAA0DClMAAAAAAAAEDDlMIAAAAAAAAADVMKAwAAAAAAADRMKQwAAAAAAADQMKUwAAAAAAAAQMOUwgAAAAAAAAANUwoDAAAAAAAANGz7vAewUaWUeyf5tSR3TnJ8ks8kOSfJM2ut353n2AAAAAAAAAC2mqVDhw7NewxHrJTy+CR/lGQpyeeTfC3JLZLsTPJvSe5Wa71kfiMEAAAAAAAA2FoW5vTRpZQzkjy3v/nYJDeotd4hyY2T/FOSmyd58ZyGBwAAAAAAALAlLcw3hUspb0jywCR/Vmt9xKrHTk/y8XQl921rrf8yhyECAAAAAAAAbDkLcU3hUsrxSX6iv/mi1Y/XWj9ZSnlXkvsmOSvJEKXwRUlOTrI/ycUDPB8AwCSnJtmV5KtJbjTfoQAAAAAArVmIUjjJ7dNdN/hAkg9NWOd96Urhuwz0Z56cZE//30kDPScAwHpOnvcAAAAAAID2LMo1hW/aLz9ba71iwjqf7pdloD9z/0DPAwBwpOQPAAAAAGBwi1IKL39T95J11ll+7MSB/syLB3oeAIAjdfG8BwAAAAAAtGdRTh+9q19evs46B/rl7jEGcJ3r3SqXXbZvjKc+6uzZsztf+dL5SczrkDYyryfsOm5Ww2rC7j2788mLPpgkOf1Gd84+++wghprXY5YW5fim2dm9Z1c+fuEHkiQ3u/Fdsu8yXz4dwpjz+pdve1VufdtbDPZ8AAAAAAArLUopvPyvrseus87OfjlKW3PZZfuUlyMwr+M43LzuOKhEm9Y+++woNjOvSuH17btsv312BEPP68GDBwd7LgAAAACA1RblX9Iv7ZcnrbPO8mOXrrMOAAAAAAAAwFFlUUrhT/TLG5RSdkxY57RV6wIAAAAAAAAc9RalFD4v3fWEdya504R17t4v3z+TEQEAAAAAAAAsgIUohWut30nytv7mY1Y/Xko5Pcl9+pvnzmpcAAAAAAAAAFvdQpTCvbOTHErysFLKY0opS0lSSrleklen+7u8odb60TmOEQAAAAAAAGBLWZhSuNb64ST/s7/5wiSfKaV8JMlFSc5IUpM8ek7DAwAAAAAAANiSFqYUTpJa63OTnJnkrUmOS3KLJJ9J8ntJ7lhr/fochwcAAAAAAACw5Wyf9wA2qtb6ziTvnPc4AAAAAAAAABbBQn1TGAAAAAAAAICNUQoDAAAAAAAANEwpDAAAAAAAANAwpTAAAAAAAABAw5TCAAAAAAAAAA1TCgMAAAAAAAA0TCkMAAAAAAAA0DClMAAAAAAAAEDDlMIAAAAAAAAADVMKAwAAAAAAADRMKQwAAAAAAADQMKUwAAAAAAAAQMOUwgAAAAAAAAANUwoDAAAAAAAANEwpDAAAAAAAANAwpTAAAAAAAABAw5TCAAAAAAAAAA1TCgMAAAAAAAA0TCkMAAAAAAAA0DClMAAAAAAAAEDDlMIAAAAAAAAADVMKAwAAAAAAADRMKQwAAAAAAADQMKUwAAAAAAAAQMOUwgAAAAAAAAANUwoDAAAAAAAANEwpDAAAAAAAANAwpTAAAAAAAABAw5TCAAAAAAAAAA1TCgMAAAAAAAA0TCkMAAAAAAAA0DClMAAAAAAAAEDDlMIAAAAAAAAADVMKAwAAAAAAADRMKQwAAAAAAADQMKUwAAAAAAAAQMOUwgAAAAAAAAANUwoDAAAAAAAANEwpDAAAAAAAANAwpTAAAAAAAABAw5TCAAAAAAAAAA1TCgMAAAAAAAA0TCkMAAAAAAAA0DClMAAAAAAAAEDDlMIAAAAAAAAADVMKAwAAAAAAADRMKQwAAAAAAADQMKUwAAAAAAAAQMOUwgAAAAAAAAANUwoDAAAAAAAANEwpDAAAAAAAANCw7bP6g0opS0numuQBSe6W5OZJrpHkm0nOS/LyJK+qtR6asP3xSZ6U5MFJbpj/z969B2la1XcC//b0DNPdoFxECTsBuR8Dcjc4WS+BuCbrNaU1UpiLqyYL6saEVCLBEFOJul5QK1Vi4mIKQ0KCZkUTFAvNuqi4JGAUvOvh4khQDBKlBJ2eC/TsH/30+FbTl+me932bPvP5VHWd53mfc8573l+9f/W3znmTHyW5Kcnba62fGvT6AQAAAAAAAFajYe4U/oUkNyT5gyRPyXQY/MVuDc9M8rdJPlJKWT97YCnl4CSfS3JRkiOSfD3J1iTPSXJdKeVVQ1g/AAAAAAAAwKozzFB4JMnmJL+T5JBa69G11ifVWh+T5CVJtmU65H39HGMvS1KSfD7JUbXW05IcnuS8bt53llJOGcJnAAAAAAAAAFhVhhkKfzZJqbW+s9b6vd4HtdYr8pMw+DdLKbvWVUo5NdNHTk8lOafWenc3Zmet9T1JrkgymuR1Q/gMAAAAAAAAAKvK0ELhWuv9tdYdC3S5tmsPSvLYntc3de11tdbb5xh3adc+u5Sy7x4uEwAAAAAAAKApa1d6AT3Ge64ne643du3184z7bKaPnh5Lckqmf7e47yYmxhfvxG7praW69s9S6joxpu5LMd5Tz3Hf2b7pV11HR4Z56MXqMD4xNuc1e2aQdV2zxvcYAAAAABicR1Io/OKu/WKt9f6e14/r2jvmGlRr3VFKuSvJMZn+3eGBhML3fPcrg5h2r6eug6Gug3Pb5ptWeglNUtfB+cY3b1zpJTRJXQEAAACA1eQRsS2llHJ6kld0t2+Z9figrv3BAlPMPDuwn+sCAAAAAAAAWO1WfKdwKeWQJB/q1vIPtdb3z+oycz7j9gWm2da1AzvX9ZBDn5gtWyYX78iiJibGd+1kVdf+WUpd9x/z89tLMT4xvmsn67FHPjmTvrN90a+6Oj764cYnxnbtZH3CURszuWXrCq+oDYOs6zUfvzInnnx83+YDAAAAAOi1oqFwKWX/JNcmOTzJ55O8dI5uW5NMJNlnganWd+3AkpotWyaFlwOgroOxWF3XTQnRlmvSd3Yg9qSuQuGFTW7Z6js7AP2u69TUVN/mAgAAAACYbcX+k15K2S/Jx5KcmuSrSX5p1m8Jz7ivaw+a41lmPbtvgT4AAAAAAAAAe50VCYVLKRNJPppkY5LbkvyXWuv35+l+a9ceM89c6zK907i3LwAAAAAAAABZgVC4lDKW5MNJnp7kziTPqLX++wJDbuzap83z/IxMHy29NckX+rVOAAAAAAAAgBYMNRTudvV+MMkzknwnyS/UWu9aZNhVXXtWKWWu3cLnde21tdYf9WelAAAAAAAAAG0YWihcShlNcmWSZyf590wHwt9cbFyt9eYk1yQZTfL+Usqh3XwjpZRzk/x6kqkkbxzU2gEAAAAAAABWq7VDfK+zk2zqrrcmeW8pZb6+r6613tJz//IkNyQ5PcnmUsrXkhyc5LAkO5Oc34XHAAAAAAAAAPQYZii8vuf6iO5vPvv33tRa7y2lnJ7kwkwHy8cn+XGSa5O8rdb6yb6uFAAAAAAAAKARQwuFa62XJ7l8D8Y/kOSi7g8AAAAAAACA3TC03xQGAAAAAAAAYPiEwgAAAAAAAAANEwoDAAAAAAAANEwoDAAAAAAAANAwoTAAAAAAAABAw4TCAAAAAAAAAA0TCgMAAAAAAAA0TCgMAAAAAAAA0DChMAAAAAAAAEDDhMIAAAAAAAAADRMKAwAAAAAAADRMKAwAAAAAAADQMKEwAAAAAAAAQMOEwgAAAAAAAAANEwoDAAAAAAAANEwoDAAAAAAAANAwoTAAAAAAAABAw4TCAAAAAAAAAA0TCgMAAAAAAAA0TCgMAAAAAAAA0DChMAAAAAAAAEDDhMIAAAAAAAAADRMKAwAAAAAAADRMKAwAAAAAAADQMKEwAAAAAAAAQMOEwgAAAAAAAAANEwoDAAAAAAAANEwoDAAAAAAAANAwoTAAAAAAAABAw4TCAAAAAAAAAA0TCgMAAAAAAAA0TCgMAAAAAAAA0DChMAAAAAAAAEDDhMIAAAAAAAAADRMKAwAAAAAAADRMKAwAAAAAAADQMKEwAAAAAAAAQMOEwgAAAAAAAAANEwoDAAAAAAAANEwoDAAAAAAAANAwoTAAAAAAAABAw4TCAAAAAAAAAA0TCgMAAAAAAAA0TCgMAAAAAAAA0DChMAAAAAAAAEDDhMIAAAAAAAAADRMKAwAAAAAAADRMKAwAAAAAAADQMKEwAAAAAAAAQMOEwgAAAAAAAAANEwoDAAAAAAAANGztSi+glPLsJB/tbu+stR4xT7/9klyYZFOSxyf5UZKbkry91vqpwa8UAAAAAAAAYPVZ0Z3CXdD77t3od3CSzyW5KMkRSb6eZGuS5yS5rpTyqgEuEwAAAAAAAGDVWunjo9+U5PAkVy/S77IkJcnnkxxVaz2tG3dekpEk7yylnDLIhQIAAAAAAACsRisWCpdSNib5H5kOhP9xgX6nJnl+kqkk59Ra706SWuvOWut7klyRZDTJ6wa+aAAAAAAAAIBVZkVC4VLKuiR/mWRLkt9apPumrr2u1nr7HM8v7dpnl1L27dMSAQAAAAAAAJqwdoXe97VJnpjkd2ut3y6lLNR3Y9deP8/zzybZlmQsySlJbujXIntNTIwPYtq9Um8t1bV/llLXiTF1X4rxnnqO+872Tb/qOjqy0r+E8MgzPjE25zV7ZpB1XbPG9xgAAAAAGJyhh8KllJ9J8odJbk5yyW4MOa5r75jrYa11RynlriTHZPp3hwcSCt/z3a8MYtq9nroOhroOzm2bb1rpJTRJXQfnG9+8caWX0CR1BQAAAABWk6FuSymljGT62Oh1Sc6rtT60G8MO6tofLNBn5tmBe7A8AAAAAAAAgOYMe6fwK5M8Jck7a62f280xM+czbl+gz7auHdi5rocc+sRs2TI5qOn3KhMT47t2sqpr/yylrvuP+fntpRifGN+1k/XYI5+cSd/ZvuhXXR0f/XDjE2O7drI+4aiNmdyydYVX1IZB1vWaj1+ZE08+vm/zAQAAAAD0GlooXErZkOTNSb6T5I+WMHRrkokk+yzQZ33XDiyp2bJlUng5AOo6GIvVdd2UEG25Jn1nB2JP6ioUXtjklq2+swPQ77pOTU31bS4AAAAAgNmGuVP4kiSPTvKyWusDSxh3X6ZD4YMW6HNQT18AAAAAAAAAOsMMhU/r2r8opfzFrGczxz4fVkr59+76hbXWf05ya5INSY6Za9JSyrokh3e3t/ZxvQAAAAAAAACr3rB/UzhJDlng2Zqe5zPHRd+Y5KwkT5tnzBld361JvtCPBQIAAAAAAAC0YmihcK31iPmelVJemuSvktw5R7+rkrw2yVmllGNqrbfPen5e115ba/1Rf1YLAAAAAAAA0IY1K72AxdRab05yTZLRJO8vpRyaJKWUkVLKuUl+PclUkjeu3CoBAAAAAAAAHplW4vjo5Xh5khuSnJ5kcynla0kOTnJYkp1Jzu/CYwAAAAAAAAB6POJ3CidJrfXeTAfCb0pyZ5Ljk+yb5Nokz6i1XrKCywMAAAAAAAB4xHpE7BSutV6yu9rdAAAgAElEQVSe5PJF+jyQ5KLuDwAAAAAAAIDdsCp2CgMAAAAAAACwPEJhAAAAAAAAgIYJhQEAAAAAAAAaJhQGAAAAAAAAaJhQGAAAAAAAAKBhQmEAAAAAAACAhgmFAQAAAAAAABomFAYAAAAAAABomFAYAAAAAAAAoGFCYQAAAAAAAICGCYUBAAAAAAAAGiYUBgAAAAAAAGiYUBgAAAAAAACgYUJhAAAAAAAAgIYJhQEAAAAAAAAaJhQGAAAAAAAAaJhQGAAAAAAAAKBhQmEAAAAAAACAhgmFAQAAAAAAABomFAYAAAAAAABomFAYAAAAAAAAoGFCYQAAAAAAAICGCYUBAAAAAAAAGiYUBgAAAAAAAGiYUBgAAAAAAACgYUJhAAAAAAAAgIYJhQEAAAAAAAAaJhQGAAAAAAAAaJhQGAAAAAAAAKBhQmEAAAAAAACAhgmFAQAAAAAAABomFAYAAAAAAABomFAYAAAAAAAAoGFCYQAAAAAAAICGCYUBAAAAAAAAGiYUBgAAAAAAAGiYUBgAAAAAAACgYUJhAAAAAAAAgIYJhQEAAAAAAAAaJhQGAAAAAAAAaJhQGAAAAAAAAKBhQmEAAAAAAACAhgmFAQAAAAAAABomFAYAAAAAAABomFAYAAAAAAAAoGFCYQAAAAAAAICGCYUBAAAAAAAAGiYUBgAAAAAAAGiYUBgAAAAAAACgYUJhAAAAAAAAgIYJhQEAAAAAAAAatnal3riU8uwkv5lkY5LHJLkvyR1JPpnkT2qtD87qvy7J+Ul+LckxSbYn+UKSS2qtHxri0gEAAAAAAABWjaHvFC6lrC2lXJHko0lekOTBJF9M8uMkT0pyUZKxWWPGklyX5OIkJyS5Pcn3k5yZ5IOllLcMa/0AAAAAAAAAq8lKHB/97kzv9v3XJKfVWg+vtZ5Raz06yYFJfjnJtllj3prkqUk2Jzmh1npyrfWYnr5/UEp53tA+AQAAAAAAAMAqMdRQuJRyVqaPjP5WkmfUWm/pfV5r3VJr/XCtdUfPmEOSvKK7/Y1aa+3p/+FM7x5Okj8Z4NIBAAAAAAAAVqVh7xT+va59R631gd0c8/wk+yS5rdb6yTmeX9q1p5VSjt7TBQIAAAAAAAC0ZO2w3qj7XeBf7G4/UUo5Psm5SY7P9BHQtyS5rNZ656yhG7v2M3PNW2v9Tillc5Iju7539HvtSTIxMT6IafdKvbVU1/5ZSl0nxtR9KcZ76jnuO9s3/arr6MhK/BLCI9v4xNic1+yZQdZ1zRrfYwAAAABgcIYWCic5Ocm67vppSd6V6R3AM56b5IJSystqre/ref24rl0o7L0j06Fw6dNaH+ae735lUFPv1dR1MNR1cG7bfNNKL6FJ6jo43/jmjSu9hCapKwAAAACwmgxzW8qhPdd/numdwWckWZ/k2CT/u7v+61LKqT19D+raHyww98yzA/uzVAAAAAAAAIA2DHOn8H4911uSPKvWel93f3sp5cWZ3hV8SpKLkmzqns2cz7h9gbm3de3AznU95NAnZsuWyUFNv1eZmBjftZNVXftnKXXdf2zfYS2rCeMT47t2sh575JMz6TvbF/2qq+OjH258YmzXTtYnHLUxk1u2rvCK2jDIul7z8Stz4snH920+AAAAAIBewwyFe/9zenlPIJwkqbVOlVL+LMlfJ/nFUsqaWutUz7jeo6ZnW9+1A0tqtmyZFF4OgLoOxmJ1XTclRFuuSd/ZgdiTugqFFza5Zavv7AD0u65TU1N9mwsAAAAAYLZh/ie9NwT++jx9Zl5/VJLHzBp30MO77zLz7L4F+gAAAAAAAADsdYYZCn+j53q+o6B7dxPPrO3Wrj1mgbmPntUXAAAAAAAAgAwxFK61fifJnd3tUfN0mwl3tyb5fnd9Y9c+da4BpZQNSY6c1RcAAAAAAACADHencJL8fdf+aillrt8zfnnXfrrW+mB3fXWSHUmOLaWcNceY87r2llrr7f1bKgAAAAAAAMDqN+xQ+O1Jfpjpnb3vKqWMJUkpZaSU8ttJnpdkZ5K3zAyotd6T5NLu9rJSSpl5Vkp5XpILuts/HfzyAQAAAAAAAFaXuXbrDkyt9d5SyqYkH870Dt9zSim3JvnpJIdmOhC+oNb6qVlDL0hyepKfS/LVUspXkuyXnxw3/Y5a69VD+AgAAAAAAAAAq8qwdwqn1vqJJCcnuTzJA0lOSbIu00HxWbXWt88xZjLJmUkuTPK1JMclOTjJp5NsqrX+/jDWDgAAAAAAALDaDHWn8Ixa621JXrbEMduTvLX7AwAAAAAAAGA3DH2nMAAAAAAAAADDsyI7hVejdz/2zDw4uW2ll9GEtePrd12ra/8spa7nfORFw1hSO9aM7rq8/eNvSqYeWsHFNKRPdR097In9WlFDRnZd3f7lDyXZuXJLacrg6rr2gJ/u21wAAAAAALPZKQwAAAAAAADQMKEwAAAAAAAAQMOEwgAAAAAAAAANEwoDAAAAAAAANEwoDAAAAAAAANAwoTAAAAAAAABAw4TCAAAAAAAAAA0TCgMAAAAAAAA0TCgMAAAAAAAA0DChMAAAAAAAAEDDhMIAAAAAAAAADRMKAwAAAAAAADRMKAwAAAAAAADQMKEwAAAAAAAAQMOEwgAAAAAAAAANEwoDAAAAAAAANEwoDAAAAAAAANAwoTAAAAAAAABAw4TCAAAAAAAAAA0TCgMAAAAAAAA0TCgMAAAAAAAA0DChMAAAAAAAAEDDhMIAAAAAAAAADRMKAwAAAAAAADRMKAwAAAAAAADQMKEwAAAAAAAAQMOEwgAAAAAAAAANEwoDAAAAAAAANEwoDAAAAAAAANAwoTAAAAAAAABAw4TCAAAAAAAAAA0TCgMAAAAAAAA0TCgMAAAAAAAA0DChMAAAAAAAAEDDhMIAAAAAAAAADRMKAwAAAAAAADRMKAwAAAAAAADQMKEwAAAAAAAAQMOEwgAAAAAAAAANEwoDAAAAAAAANEwoDAAAAAAAANAwoTAAAAAAAABAw4TCAAAAAAAAAA0TCgMAAAAAAAA0TCgMAAAAAAAA0DChMAAAAAAAAEDDhMIAAAAAAAAADRMKAwAAAAAAADRMKAwAAAAAAADQsLXDfsNSymOS/F6S5yY5Ksk+Sb6X5J+TvLPW+v/mGbdfkguTbEry+CQ/SnJTkrfXWj81+JUDAAAAAAAArD5D3SlcSjk2yZeTvDbJCUnuSfLVJI9O8qIk15dSfneOcQcn+VySi5IckeTrSbYmeU6S60oprxrG+gEAAAAAAABWm2EfH/2/khya5LYkJ9Zaj661nprkcUnekWQkycVdeNzrsiQlyeeTHFVrPS3J4UnO68a8s5RyypA+AwAAAAAAAMCqMbRQuJTyqCRndbevqbV+beZZrXVrktckuT3TR1r/Us+4U5M8P8lUknNqrXd3Y3bWWt+T5Ioko0leN4zPAQAAAAAAALCaDHOn8PpM7+pNkjtmP6y17ux5fV3Po01de12t9fY55r20a59dStm3HwsFAAAAAAAAaMXQQuFa638k+XZ3+59nP+8C3ZkjoD/b82hj114/z9SfTbItyVjPeAAAAAAAAAAyfVTzMF2Y6eOe31ZKmUpyTZL7kzwxyZuTHJLkb2utN/SMOa5rH7a7OElqrTtKKXclOSbTvzt8w1z99tTo+D6DmHav1FtLde2fJdV1zeiAV9OY3nqpXf/0ra4ji3fZ64zMc82eUVcAAAAAYHUa2blz51DfsJTy3CR/lOTJsx59N8nrk1zaHSU90//HSSaSPKvW+rF55rwpyRlJfr/W+o4+LfXzSU7r01wAALvj5iSnr/QiAAAAAIC2DPM3hWcck+RxSaaSfCvJl5JsSXJokpcmOWFW/7Gu3b7AnNu6drxfiwQAAAAAAABowVCPjy6l/HmSVyX51yT/tdZ6a/f6eJI/TfKaJDeUUk6qtd7ZDdua6Z3CC52Hu75rJwey8CTvO/GVeWhyoVya3TU6vk9e/OV3J1HXflpKXTdd9YJhLasNa0YzdtKzkiRbv3RtMvXQCi+oEX2q6+iG4/u5qkaMZN1jj0yS7Lh3c5LhngrSrsHVde0BGzKybv3iHQEAAAAAlmFooXAp5aQkr0yyI8mLekLf1Fonk1xQSjktyTOSvDbJK7rH92U6FD5ogekP6uk7EA9Nbs+Dk9sW78iSqOtgLFpXoebyTT2kfoOwR3UVeC5sZ9RoENQVAAAAAFg9hnl89FOTjCS5rTcQnuWfuvZJPa/d2rXHzDWglLIuyeGz+gIAAAAAAACQ4YbCj1pC37Ge6xu79mnz9D0j00dLb03yhWWsCwAAAAAAAKBZwwyFZ3bxHltKefw8fX6xa2vPa1d17VmllLl2C5/XtdfWWn+0h2sEAAAAAAAAaMowQ+F/SvK9JOuSfKCUctzMg1LKeCnl4kz/nnCS/M3Ms1rrzUmuSTKa5P2llEO7MSOllHOT/HqSqSRvHMqnAAAAAAAAAFhF1g7rjWqtPy6l/GqSf0zys0m+Xkq5M8kDmf694Imu65/XWq+eNfzlSW5IcnqSzaWUryU5OMlhSXYmOb8LjwEAAAAAAADoMcydwqm1fiLJSUnelenjpH8qyc8k+WGSq5M8t9b6W3OMuzfTgfCbktyZ5Pgk+ya5Nskzaq2XDOUDAAAAAAAAAKwyQ9spPKPW+s0kr17GuAeSXNT9AQAAAAAAALAbhrpTGAAAAAAAAIDhEgoDAAAAAAAANEwoDAAAAAAAANAwoTAAAAAAAABAw4TCAAAAAAAAAA0TCgMAAAAAAAA0TCgMAAAAAAAA0DChMAAAAAAAAEDDhMIAAAAAAAAADRMKAwAAAAAAADRMKAwAAAAAAADQMKEwAAAAAAAAQMOEwgAAAAAAAAANEwoDAAAAAAAANEwoDAAAAAAAANAwoTAAAAAAAABAw4TCAAAAAAAAAA0TCgMAAAAAAAA0TCgMAAAAAAAA0DChMAAAAAAAAEDDhMIAAAAAAAAADRMKAwAAAAAAADRMKAwAAAAAAADQMKEwAAAAAAAAQMOEwgAAAAAAAAANEwoDAAAAAAAANEwoDAAAAAAAANAwoTAAAAAAAABAw4TCAAAAAAAAAA0TCgMAAAAAAAA0TCgMAAAAAAAA0DChMAAAAAAAAEDDhMIAAAAAAAAADRMKAwAAAAAAADRMKAwAAAAAAADQMKEwAAAAAAAAQMOEwgAAAAAAAAANEwoDAAAAAAAANEwoDAAAAAAAANAwoTAAAAAAAABAw4TCAAAAAAAAAA0TCgMAAAAAAAA0TCgMAAAAAAAA0DChMAAAAAAAAEDDhMIAAAAAAAAADRMKAwAAAAAAADRMKAwAAAAAAADQMKEwAAAAAAAAQMOEwgAAAAAAAAANEwoDAAAAAAAANEwoDAAAAAAAANCwtcsZVEr5qSTPTPKz3d8pScaSfLrWeuYiY9clOT/JryU5Jsn2JF9Ickmt9UOLjD01yYVJfj7JAUnuTvKRJG+std67nM8CAAAAAAAA0LLl7hQ+J8nfJHl1ko2ZDoQXVUoZS3JdkouTnJDk9iTfT3Jmkg+WUt6ywNgXJrkpydlJRpJ8Ncnjkvx2ki+WUo5a5mcBAAAAAAAAaNZyQ+H7k3wiyZuTvDDJG3Zz3FuTPDXJ5iQn1FpPrrUek+SXk2xL8gellOfNHlRK2ZDkiiTruvfaUGs9PcmGJB9LcmiSvy+ljCzz8wAAAAAAAAA0aVmhcK31vbXWZ9Za/7DW+g9JvrfYmFLKIUle0d3+Rq219sz34UzvHk6SP5lj+GuSTCS5vtb6x7XWB7txP0zyK0l+mORJSZ67nM8DAAAAAAAA0Krl7hRejucn2SfJbbXWT87x/NKuPa2UcvSsZ5u69j2zB9Va70vyge727H4sFAAAAAAAAKAVwwyFN3btZ+Z6WGv9TqaPle7tm1LKYZk+JjpJrp9n7pk5N87zHAAAAAAAAGCvtHaI73Vc196xQJ87khyZpMwxbnuSby8wLkmOKqWsq7XuWPYq5zE6vk+/p9xr9dZSXftnSXVdMzrg1TSmt15q1z99q6ufk3+4kXmu2TPqCgAAAACsTsMMhQ/q2h8s0Gfm2YFzjLuv1rpzkXFrkjw6yfeXtcIFvPjL7+73lERdB0VdB2fspGet9BKapK6Ds+6xR670EpqkrgAAAADAajLM46PHunb7An22de34MsfNHgsAAAAAAACwVxvmTuGtXbvQubbru3ZymeNmj+2b9534yjw0uVAuze4aHd9n105Wde2fpdR101UvGNay2rBmdNdO1q1fujaZemiFF9SIPtV1dMPx/VxVI0Z27WTdce/mJPMdtMHSDK6uaw/YkJF16xfvCAAAAACwDMMMhe/r2oMW6LPrqOg5xh1YShmZ5wjpmXFTSe5f/hLn99Dk9jw4uW3xjiyJug7GonUVai7f1EPqNwh7VFeB58J2Ro0GQV0BAAAAgNVjmMdH39q1xyzQ5+hZfXuv90ly2CLjNtdadyxveQAAAAAAAADtGWYofGPXPnWuh6WUDUmOnNU3tdZ/S3J3d/u0eeaeef1f9nCNAAAAAAAAAE0ZZih8dZIdSY4tpZw1x/PzuvaWWuvts559sGvPnT2olHJgkhd1tx/ox0IBAAAAAAAAWjG0ULjWek+SS7vby0opZeZZKeV5SS7obv90juFvSzKZ5OmllNeXUka7cfsnuTLJ/kluSfKRAS0fAAAAAAAAYFVau5xBpZTDMh3Czhjr2qeUUv6j5/WLa60X99xfkOT0JD+X5KullK8k2S8/+U3gd9Rar579frXWu0opL0nyviSvS3JeKeWuJE9Ism+Se5KcXWvduZzPAwAAAAAAANCq5e4UHk3ymJ6/fbvX1856faJ3UK11MsmZSS5M8rUkxyU5OMmnk2yqtf7+fG9Ya70qyZOTXNW9dGKSe5O8K8lJcxw5DQAAAAAAALDXW9ZO4Vrrt5KMLHPs9iRv7f6WOvbm/OT3gwEAAAAAAABYxNB+UxgAAAAAAACA4RMKAwAAAAAAADRMKAwAAAAAAADQMKEwAAAAAAAAQMOEwgAAAAAAAAANEwoDAAAAAAAANEwoDAAAAAAAANAwoTAAAAAAAABAw4TCAAAAAAAAAA0TCgMAAAAAAAA0TCgMAAAAAAAA0DChMAAAAAAAAEDDhMIAAAAAAAAADRMKAwAAAAAAADRMKAwAAAAAAADQMKEwAAAAAAAAQMOEwgAAAAAAAAANEwoDAAAAAAAANEwoDAAAAAAAANAwoTAAAAAAAABAw4TCAAAAAAAAAA0TCgMAAAAAAAA0TCgMAAAAAAAA0DChMAAAAAAAAEDDhMIAAAAAAAAADRMKAwAAAAAAADRMKAwAAAAAAADQMKEwAAAAAAAAQMOEwgAAAAAAAAANEwoDAAAAAAAANEwoDAAAAAAAANAwoTAAAAAAAABAw4TCAAAAAAAAAA0TCgMAAAAAAAA0TCgMAAAAAAAA0DChMAAAAAAAAEDDhMIAAAAAAAAADRMKAwAAAAAAADRMKAwAAAAAAADQMKEwAAAAAAAAQMOEwgAAAAAAAAANEwoDAAAAAAAANEwoDAAAAAAAANAwoTAAAAAAAABAw4TCAAAAAAAAAA0TCgMAAAAAAAA0TCgMAAAAAAAA0DChMAAAAAAAAEDDhMIAAAAAAAAADRMKAwAAAAAAADRMKAwAAAAAAADQsLXLGVRK+akkz0zys93fKUnGkny61nrmPGMeleR5SX6pG3NEpkPp7yT5VJI/q7V+ZZH3PTXJhUl+PskBSe5O8pEkb6y13ruczwIAAAAAAADQsuXuFD4nyd8keXWSjZkOhBfzF0n+LslLMh0I39b9bUjy8iQ3l1JeNt/gUsoLk9yU5OwkI0m+muRxSX47yRdLKUct87MAAAAAAAAANGu5ofD9ST6R5M1JXpjkDbs57qNJnpPkgFrrybXWE5P8pyRXJlmX5C9LKSfOHlRK2ZDkiq7PG5JsqLWenulA+WNJDk3y96WUkWV+HgAAAAAAAIAmLev46Frre5O8d+a+C20Xc36t9ftzzPWDUspLk5yc5IQkv5Hk/FndXpNkIsn1tdY/7hn7w1LKryTZnORJSZ6b6eOkAQAAAAAAAMjydwov2VyBcM+zHUn+b3db5uiyqWvfM8fY+5J8oLs9e0/WCAAAAAAAANCaoYXCu2G8a7f0vlhKOSzTx0QnyfXzjP1M124cwLoAAAAAAAAAVq1lHR/db6WUiSS/3N1+Ztbj47p2e5JvzzPFHV17VCllXbfzuK9Gx/fp95R7rd5aqmv/LKmua0YHvJrG9NZL7fqnb3X1c/IPNzLPNXtGXQEAAACA1ekREQon+Z9JHpfk3vT8VnHnoK69r9a6c57xP+jaNUkenWTeo6qX68Vffne/pyTqOijqOjhjJz1rpZfQJHUdnHWPPXKll9AkdQUAAAAAVpMVPz66lPLiJOd3t/+91nr/rC5jXbt9gWm29VyPz9sLAAAAAAAAYC+zojuFSynPTHJ5d3tRrfXqObpt7dqFzsNd33M92YelPcz7TnxlHppcKJdmd42O77NrJ6u69s9S6rrpqhcMa1ltWDO6ayfr1i9dm0w9tMILakSf6jq64fh+rqoRI7t2su64d3OS+Q7aYGkGV9e1B2zIyLr1i3cEAAAAAFiGFQuFSylPT/KPmQ5731JrfdM8Xe/r2gNLKSPzHCE9c8T0VJLZO4374qHJ7XlwctviHVkSdR2MResq1Fy+qYfUbxD2qK4Cz4XtjBoNgroCAAAAAKvHihwfXUr5uSQfTTKR5JJa62sX6H5r1+6T5LB5+hzdtZtrrTv6s0oAAAAAAACA1W/ooXAp5fQk1ybZL8llSX5nof611n9Lcnd3+7R5us28/i/9WCMAAAAAAABAK4YaCpdSTkzyT0n2T/J3Sc6d5zjo2T7YtefOMeeBSV7U3X6gH+sEAAAAAAAAaMXQQuFSyrFJ/k+mf//3A0n+W611ajeHvy3JZJKnl1JeX0oZ7ebcP8mVmQ6Zb0nykb4vHAAAAAAAAGAVW7ucQaWUwzIdws4Y69qnlFL+o+f1i2utF3fX70pySHf9+CSfLqXMNf13a60v6n2h1npXKeUlSd6X5HVJziul3JXkCUn2TXJPkrN3c9cxAAAAAAAAwF5jWaFwktEkj5lnvt7XJ3qu1/dcn7HA3HfO9WKt9apSyjeTvDbJ05OcmOnfGv6rJG+otX5vN9YNAAAAAAAAsFdZVihca/1WkpEljjlzOe81a46b85PfDwYAAAAAAABgEUP7TWEAAAAAAAAAhk8oDAAAAAAAANAwoTAAAAAAAABAw4TCAAAAAAAAAA0TCgP/v707D5asqg84/n2zMAvIwBABQ9jBX1AEARVIUBZBjAomwCSSRBlcACtFgiUGiYAGYkRTBhJSCBJxiKWALLJoiAiyuUW0RgWS/ESHYRVRdoFhm8kf57bT09PdM6/f6/e67/t+qqZu3+Vcfu/wu3em3q/POZIkSZIkSZIkSaoxi8KSJEmSJEmSJEmSVGMWhSVJkiRJkiRJkiSpxiwKS5IkSZIkSZIkSVKNWRSWJEmSJEmSJEmSpBqzKCxJkiRJkiRJkiRJNWZRWJIkSZIkSZIkSZJqzKKwJEmSJEmSJEmSJNWYRWFJkiRJkiRJkiRJqjGLwpIkSZIkSZIkSZJUYxaFJUmSJEmSJEmSJKnGRlasWDHZMQyqh4H5v925fSkrlttX42Fk2ggb7bgVYL+Op9H06/ztNpygqOpj2twNAFj+9GOTHEm9jEe/jsycM17h1MrIzFkArHj+2UmOpF761q8zZjIyMg3gEWCj8b25JEmSJEmSpKnOonBnTwFzJzsISZI0pTwNrDvZQUiSJEmSJEmqlxmTHcAAewjYGFgGLJ3cUCRJUs1tBcym/PtDkiRJkiRJksaVI4UlSZIkSZIkSZIkqcamTXYAkiRJkiRJkiRJkqT+sSgsSZIkSZIkSZIkSTVmUViSJEmSJEmSJEmSasyisCRJkiRJkiRJkiTVmEVhSZIkSZIkSZIkSaoxi8KSJEmSJEmSJEmSVGMWhSVJkiRJkiRJkiSpxiwKS5IkSZIkSZIkSVKNWRSWJEmSJEmSJEmSpBqzKCxJkiRJkiRJkiRJNWZRWJIkSZIkSZIkSZJqzKKwJEmSJEmSJEmSJNWYRWFJkiRJkiRJkiRJqjGLwpIkSZIkSZIkSZJUYxaFJUmSJEmSJEmSJKnGLApLkiRJkiRJkiRJUo3NmOwABlVE7At8ENgdWA+4G7gEOD0zn5rM2AZRRIwAewIHA3sBOwDrA48Bi4ELgC9l5oo2bVc71uKXmbnp+EY8XCLiY8BH13DZ+zPznDZtZwLHAX8JbAc8B/wIOCszLx/nUIdGRGwF3LWWly/KzCOb2i4FtlxDmzmZuayn4IZARGwKHAC8tvrzamA2cFNm7rOGtj3nZETsAnwY2BvYAHgAuBr4h8z81Rh+pIHQS79GxEuAg4ADqzZbUb70dT9wI3BGZt7eoe1C4PNrCOuTmfnh0f0kg6fXnB3r8x4R2wAnAW8CXgo8BFxLydm1fQdJkiRJkiRJ0phYFG4jIo4F/gUYAe4D7gVeQfml7qERsVdmPjKJIQ6i/YDrmvaXUApuW1N+CX8AcHhEHJqZz3a4xw+AduceHs9Ah9xDwJ0dzv2i9UBEzAa+QSnUvwjcAawL7APsExG1KPb0aBnw7S7nZwO7VZ+/0+Ga24HHO5xb3mNcw+IdwBmjbTSWnIyIQ4CLgJmUZ+EOIIC/BhZU7+Ylo/9RBkov/Xo2pcAO8AzlHTEN2B54N/DOiDg6M7sVf58Abutwbuko4xlUPeVsk1E/7xGxJ6UAvB7wKKWPt6X8f1kQEftn5vfHEJMkSZIkSZIkrRWLwi0iYjfgzGr3aOC8zFwREb8LXEUpEp0HHDpJIQ6qEUoR+Ezgosx8qHEiIt5J6bO3AqcCJ3S4x4LMXNrnOIfdNZm5cBTXf3BswE8AAAudSURBVJJSfLsL+KPMTICIOBj4MnBCRHw7M68e90gHXGY+SOmbtiLiCGARpch2cYfLjs3MG8c9uOHwBOWLILdWf3YBTl6Ldj3lZERsBnyBUhA+DTg1M1+IiHmUQvGbgYsj4nXtZiQYIr3269coxeHrMvM5gIiYD5wF/DlwXkT8IDM7FX4Xr2mEdw302rcNo3reI2Jd4DJKQfh84K8yc1n1xYizgSOByyLi5Zn5zCjikCRJkiRJkqRRc03h1Z1M6ZcvZOZnG8WFzHwAOJwyGuiQiNhpEmMcRN8HIjP/tbkgDJCZX6AUgwHeGxHm3QSIiE2AY6rd9zSKbwCZeRXwqWr3YxMc2rBYWG0vz8wnJjOQQZSZ52fmAZn5d5n5FcrI3a7GmJMfAuYCN2fmKZn5QtXucUrR83HgNcDbevyRBkIv/Qocl5lvy8z/bBSEq3s9QsnjO4DpwHv6EvSQ6LFvx+J9wMuAnwHHNKaXrrbHAD8Hfg94b5/jkCRJkiRJkiSLws0iYj3KaDOAz7aez8w7gW9WuwsmKq5hkJlPZObzXS65ptrOp6ypqP47GFgHuDMzb2hz/txqu2tEbDtxYQ2+ar3hvavdRZMXSe2MJScPq7bt3s2PUtZ8B/jT8Qh0mGRmxyn2q/fy9dVuTExEqjT+nbCo9e/HqnjfmM57yuWsJEmSJEmSpInn9NGr2gWYRVnXttMaf7cA+wN7TFRQNTGn6XOnaTJPrqbpngHcTynAX9xlDeKpaOeI+BKwKfAk8BPKdN13tLm2kaO3tLtRZt4fEY11n/egjFpTcQRlSvR7WPlFkHaOiYjjKfn9IKWvv5iZT/Y/xKHUU05GxObAZtVlN3e49y2UEZe+m1fXeP8+3eWaLSJiEbA55R39v8Blmfm9Psc2TNb6eY+I6ZSR69A9ZwFeGxHTM/PF8Q5YkiRJkiRJkhocKbyql1fbe7qMem0UzhxxNTqHV9sfd5mK992Ukdr7U4pyFwD/FxG7TkB8w+LVlL7clzLq8iTgtog4oypCNGvkc7dir/ncIiJGKPkH8B+ZubzL5X9GWSt7P8oUxp8BlkTEAf2Ncmj1mpONds8B962h3TYRMbO38OonIuYCb6922xbjK1tT8n4/Sk4fD3w3Ii6s7qHRPe9bUUbFQ+d8bxyfBWw5fmFKkiRJkiRJ0uosCq9qfrV9pMs1jXMb9jmW2oiI3Vi5jujpbS65kjI17PaUEVgvpRQ+l1B+sX5tNVJwKnsAOAXYndI/s4GdgHMoI1qPAz7R0sZ87s3elAIZdJ46+kbgXcAOwLqU/jsIWAz8DnCVX2Zoq9ecbLR7tLHOe5d204D1ewuvlj4ObAz8Cji/zflHKWs5v56y/u0sSkH+48ALwDtwCvUbGf3zPr/pc6d8bz7uO1iSJEmSJElSXzl99KpmV9vnulzTmMp4TpdrVImITYDLKbn2lcy8qPWazPzjlkPLgIsi4jrgh8AWwEcpU8NOSZm52jqqwG3A+6vpdj8JfCAizs7MpdV587k3C6vtLZnZdoRfZi5sOfQ08NWIuB74FrArpdC2f59iHFa95uRo2rW2nbIi4nDKF0YA3tdulobMvJLyxZxmPwVOioifABcDCyJir8z8Vl8DHlA9Pu+zmz53yltzVpIkSZIkSdKEcaTwqpZV23W6XDOr2nZaF1eViJgHXEMp6v6QlcW2tZKZv2bl6Nc/qab11eo+TRlJPIMypXSD+TxKEbEeZdQ69DA6MjOfAT5S7e4bEY7+W1WvOTmadq1tp6RqSuNF1e5HquLvqGTml4H/rnYPGafQamMNz/uyps+d8taclSRJkiRJkjRhLAqv6tFqO7/LNb+dxrTPsQy1qrj2X8AuwB3AgV3WEu7mO9V2Pt3/v0xZmfkiKws32zedMp9H7zDK9LBPA5f0eI9Gzk4DthmPoGqk15xsfN6wy5dDGu2WA728a2ojIt4AXEEpRp6emf84hts18nn7rldNXZ2e9+b87ZTvzcd9B0uSJEmSJEnqK4vCq/pptd0iImZ2uGbblmvVIiLmAl8D9gDuBPbPzId7vF3ztJtOd95Zo5+a+6iRo9t1aWc+r2phtb00M5/s8R7mbGe95mTj8zpAp/XFG+3uysznewtv+EXEnpT371zgrMw8cYy3bPdu0UqdnvelTec65XsjZ58F7h7fsCRJkiRJkiRpVRaFV7WY8kvcWcDrOlzz+mr73QmJaMhExGzgKuANlF9yvzEzHxzDLXestsuAXgvLU0Gjn+5rOva9artXuwYRsRmwdcu1U1ZEbE3JW+hh6ugmOzZ9vq/jVVNTTzmZmfdQpkiHle/gVlP+3RwRu1Gm7F8P+BzwN+Nw23bvFq3U9nnPzBcoyybAmnP21mrGB0mSJEmSJEnqG4vCTaqRgV+vdo9qPR8R2wP7VbuXTlRcw6IaXX0Z8EbgfmC/zLx3DPebAXyw2v1m9Ut2tYiItwKvrHavbTp1JfA8sH1E7Num6dHVdnFm/qyPIQ6LI4ARygi/G8dwnxOq7f9k5v1jjKluxpKTl1Xbdu/mDYEF1W6v034PtYh4FeX5nwd8ETgqM1eM8Z47AW+udq/tdu0U1u15b/w7YWHr7CMRsQ5wZLU7JXNWkiRJkiRJ0sSyKLy604AVwDsj4qjG+pUR8TLgQkqfXZGZP57EGAdOREwHvgS8BXiQUhBeshbtTo+IIyLiJS3HN6f8Qn0P4AXg1PGPejhExCsj4tyI2Lnl+LSIOJzS7wBfzcxbG+cz85fAudXu5yIimtoeBPxttfv3/Yt+OFTP+buq3Qu6FdMi4viIODYiNmo5vlFEnEtZlxjglP5EO7zGmJP/BDwDvCEiTq3eOUTEPMozMI8y28PVfQp/YFVfWPoGZY3aS4AjMnP5WrRbPyIujog/aF2rOSIOpIw6ng78GLh8/CMffGN83s+l/H24HXBONZNGY0aNcyjTRz8A/Hu/4pckSZIkSZKkhpEVK8Y0kKiWIuI44J8powbvBX4NvIIyrXQCe2XmrycvwsHTUpxcShkp3Mmxmbm4ancF8HbgRWAJ8AiluBOU/l8GvDczv9ifyAdfRLyaUuyC0j93Uwrl2wEbVsdvAQ7OzMda2s4Brgf2pPTx7ZSpZRtrWX46M4/v6w8wBCJiH+AGyhdCts3Mu7pceyZlWt4VlFz/FTAH2IGypuhy4MTM/FR/o55c1Rc3Fjcdmg2sS8nNx5uOf6q5L8aSkxFxGOXLOTOAhyjv59+v/ru/pLybh3rUey/9GhFfB95UHf8+ZTR2O7/IzMaIaiJiA+DRavdJyjv4WWBLYJPq+B3AW6opvIdaj307puc9Iv6QMgPJupS+XgJsQ3l3/wY4IDOn/PT9kiRJkiRJkvpvxmQHMIgy88yIuI0ydfHuwMaUQtylwCcy8zeTGd+AmtX0eavqTyfzmj5/hjKS6jXAZlW7ZymFiOuAf8vMn49jnMNoKXASpYi2A6UYPJtSIL6GUoy/sN2alJn5TFXw/ADwF8DLKetm3wSclZmXtbaZohZW25u7FYQrF1Xb3YEtgJ1Z+aWGm4CzM/NH/QhywEwHNmpzfEbL8bnNJ8eSk5l5aUQsAU6krP/8KspIy88Dp2XmQz3/NIOjl35tfv++rsu9727Zfwr4EOXdsiOlGLwepUB6A+XvvPMzc9laRT74eunbMT3vmfntapaHk4EDgJ0oheUrKTm7xhk1JEmSJEmSJGk8OFJYkiRJkiRJkiRJkmrMNYUlSZIkSZIkSZIkqcYsCkuSJEmSJEmSJElSjVkUliRJkiRJkiRJkqQasygsSZIkSZIkSZIkSTVmUViSJEmSJEmSJEmSasyisCRJkiRJkiRJkiTVmEVhSZIkSZIkSZIkSaoxi8KSJEmSJEmSJEmSVGMWhSVJkiRJkiRJkiSpxiwKS5IkSZIkSZIkSVKNWRSWJEmSJEmSJEmSpBqzKCxJkiRJkiRJkiRJNWZRWJIkSZIkSZIkSZJq7P8BkG12waSRz8oAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 2380x1580 with 4 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RSp0ZULKv9hS",
        "colab_type": "text"
      },
      "source": [
        "# Evaluation Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QcNDr5iwAbO",
        "colab_type": "code",
        "outputId": "10b101f9-acd4-4d6f-afe3-31e8bf4e26d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# 1) Check Architecture\n",
        "# 2) Check Preprocessing\n",
        "\n",
        "base_path = '/content/drive/My Drive/DCASE/Evaluation_Dataset'\n",
        "machine_type = 'ToyConveyor'\n",
        "machine_ids = ['04', '05', '06']\n",
        "\n",
        "for machine_id in machine_ids:\n",
        "    train_audiopaths = load(base_path + '/S128_%s_%s_train_audiopaths.joblib' % (machine_type, machine_id))\n",
        "    test_audiopaths = load(base_path + '/S128_%s_%s_test_audiopaths.joblib' % (machine_type, machine_id))\n",
        "    test_audiopaths = [fn.split('/')[-1] for fn in test_audiopaths]\n",
        "    \n",
        "    S_train = np.load(base_path + '/S128_%s_%s_train.npy' % (machine_type, machine_id))\n",
        "    S_test = np.load(base_path + '/S128_%s_%s_test.npy' % (machine_type, machine_id))\n",
        "\n",
        "\n",
        "    # Preprocessing\n",
        "    X_train = torch.tensor(10 * np.log10(S_train + sys.float_info.epsilon), dtype = torch.float)\n",
        "    X_train = X_train.view(X_train.shape[0], 1, *X_train.shape[1:]).to(device)\n",
        "\n",
        "    X_test = torch.tensor(10 * np.log10(S_test + sys.float_info.epsilon), dtype = torch.float)\n",
        "    X_test = X_test.view(X_test.shape[0], 1, *X_test.shape[1:]).to(device)\n",
        "    \n",
        "    # initialize model #\n",
        "    model = AProtoPNet().to(device)   \n",
        "\n",
        "    # Train Model \n",
        "    print('-' * 25)\n",
        "    print('Training Model [ID = %s]' % machine_id)\n",
        "    print('-' * 25)\n",
        "    model.train_m(X_train) \n",
        "\n",
        "    with torch.no_grad():\n",
        "        # Evaluate On X_test\n",
        "        Y_pred = model(X_test)\n",
        "        y_score = Y_pred.min(dim = 1)[0].cpu().numpy()        \n",
        "        df = pd.DataFrame({'filename': test_audiopaths, 'Anomaly_Score': y_score})\n",
        "        df.to_csv('anomaly_score_%s_id_%s.csv' % (machine_type, machine_id), header = False, index = False)\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-------------------------\n",
            "Training Model [ID = 04]\n",
            "-------------------------\n",
            "Epoch [0] Train_Loss 6.4994e+00, Val_Loss 3.3972e+00\n",
            "Saving Model\n",
            "\n",
            "Epoch [1] Train_Loss 2.3398e+00, Val_Loss 1.4572e+00\n",
            "Saving Model\n",
            "\n",
            "Epoch [2] Train_Loss 8.9962e-01, Val_Loss 5.4377e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [3] Train_Loss 4.4143e-01, Val_Loss 3.5744e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [4] Train_Loss 3.3272e-01, Val_Loss 2.7976e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [5] Train_Loss 3.1565e-01, Val_Loss 2.8436e-01\n",
            "Epoch [6] Train_Loss 2.4743e-01, Val_Loss 2.2792e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [7] Train_Loss 2.1554e-01, Val_Loss 2.0167e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [8] Train_Loss 1.9445e-01, Val_Loss 1.8104e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [9] Train_Loss 1.7691e-01, Val_Loss 1.6454e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [10] Train_Loss 1.8077e-01, Val_Loss 1.5402e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [11] Train_Loss 1.5623e-01, Val_Loss 1.4042e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [12] Train_Loss 1.4292e-01, Val_Loss 1.2955e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [13] Train_Loss 1.3333e-01, Val_Loss 1.2218e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [14] Train_Loss 1.2332e-01, Val_Loss 1.1447e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [15] Train_Loss 1.2997e-01, Val_Loss 1.1760e-01\n",
            "Epoch [16] Train_Loss 1.1822e-01, Val_Loss 1.0800e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [17] Train_Loss 1.1489e-01, Val_Loss 1.0092e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [18] Train_Loss 1.0411e-01, Val_Loss 9.6277e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [19] Train_Loss 9.6479e-02, Val_Loss 9.2259e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [20] Train_Loss 9.7347e-02, Val_Loss 8.8822e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [21] Train_Loss 8.8425e-02, Val_Loss 8.3064e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [22] Train_Loss 8.3299e-02, Val_Loss 8.2757e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [23] Train_Loss 7.9722e-02, Val_Loss 7.7225e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [24] Train_Loss 7.7022e-02, Val_Loss 7.3657e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [25] Train_Loss 8.2198e-02, Val_Loss 7.1925e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [26] Train_Loss 7.4137e-02, Val_Loss 6.9140e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [27] Train_Loss 7.1154e-02, Val_Loss 6.8350e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [28] Train_Loss 6.8878e-02, Val_Loss 6.6725e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [29] Train_Loss 6.6924e-02, Val_Loss 6.6961e-02\n",
            "Epoch [30] Train_Loss 7.3394e-02, Val_Loss 6.7833e-02\n",
            "Epoch [31] Train_Loss 7.0758e-02, Val_Loss 6.0562e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [32] Train_Loss 7.2338e-02, Val_Loss 6.3563e-02\n",
            "Epoch [33] Train_Loss 6.6767e-02, Val_Loss 5.8683e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [34] Train_Loss 5.7987e-02, Val_Loss 5.6370e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [35] Train_Loss 5.6888e-02, Val_Loss 6.0600e-02\n",
            "Epoch [36] Train_Loss 5.3101e-02, Val_Loss 5.3733e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [37] Train_Loss 5.1450e-02, Val_Loss 5.1691e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [38] Train_Loss 5.0308e-02, Val_Loss 5.8668e-02\n",
            "Epoch [39] Train_Loss 4.9253e-02, Val_Loss 4.6671e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [40] Train_Loss 5.6093e-02, Val_Loss 4.7340e-02\n",
            "Epoch [41] Train_Loss 5.0561e-02, Val_Loss 4.6370e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [42] Train_Loss 4.7017e-02, Val_Loss 4.7311e-02\n",
            "Epoch [43] Train_Loss 4.3927e-02, Val_Loss 4.5198e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [44] Train_Loss 4.2632e-02, Val_Loss 4.4570e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [45] Train_Loss 4.3629e-02, Val_Loss 4.5115e-02\n",
            "Epoch [46] Train_Loss 4.0442e-02, Val_Loss 4.1198e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [47] Train_Loss 4.1008e-02, Val_Loss 4.2149e-02\n",
            "Epoch [48] Train_Loss 3.9696e-02, Val_Loss 3.7946e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [49] Train_Loss 3.7689e-02, Val_Loss 4.0238e-02\n",
            "Epoch [50] Train_Loss 4.2392e-02, Val_Loss 3.7414e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [51] Train_Loss 3.8163e-02, Val_Loss 3.7297e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [52] Train_Loss 3.8134e-02, Val_Loss 3.7330e-02\n",
            "Epoch [53] Train_Loss 3.5683e-02, Val_Loss 3.5804e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [54] Train_Loss 3.4987e-02, Val_Loss 3.5388e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [55] Train_Loss 3.5943e-02, Val_Loss 3.5681e-02\n",
            "Epoch [56] Train_Loss 3.4797e-02, Val_Loss 3.5900e-02\n",
            "Epoch [57] Train_Loss 3.3329e-02, Val_Loss 3.3697e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [58] Train_Loss 3.2724e-02, Val_Loss 3.5096e-02\n",
            "Epoch [59] Train_Loss 3.2595e-02, Val_Loss 3.1517e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [60] Train_Loss 3.9204e-02, Val_Loss 7.8924e-02\n",
            "Epoch [61] Train_Loss 4.6152e-02, Val_Loss 3.2852e-02\n",
            "Epoch [62] Train_Loss 3.7906e-02, Val_Loss 3.2060e-02\n",
            "Epoch [63] Train_Loss 3.3640e-02, Val_Loss 2.9356e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [64] Train_Loss 2.9897e-02, Val_Loss 3.0539e-02\n",
            "Epoch [65] Train_Loss 3.1657e-02, Val_Loss 3.0561e-02\n",
            "Epoch [66] Train_Loss 3.0727e-02, Val_Loss 2.9026e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [67] Train_Loss 4.0577e-02, Val_Loss 3.5022e-02\n",
            "Epoch [68] Train_Loss 3.4886e-02, Val_Loss 3.3973e-02\n",
            "Epoch [69] Train_Loss 3.1076e-02, Val_Loss 3.1900e-02\n",
            "Epoch [70] Train_Loss 3.5264e-02, Val_Loss 3.3848e-02\n",
            "Epoch [71] Train_Loss 3.9957e-02, Val_Loss 4.1832e-02\n",
            "Epoch [72] Train_Loss 3.7729e-02, Val_Loss 2.6682e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [73] Train_Loss 3.6003e-02, Val_Loss 4.2949e-02\n",
            "Epoch [74] Train_Loss 3.3515e-02, Val_Loss 3.4497e-02\n",
            "Epoch [75] Train_Loss 3.1637e-02, Val_Loss 2.7035e-02\n",
            "Epoch [76] Train_Loss 3.3248e-02, Val_Loss 4.5504e-02\n",
            "Epoch [77] Train_Loss 3.0472e-02, Val_Loss 4.0206e-02\n",
            "Epoch [78] Train_Loss 2.6629e-02, Val_Loss 2.9428e-02\n",
            "Epoch [79] Train_Loss 2.5128e-02, Val_Loss 2.9791e-02\n",
            "Epoch [80] Train_Loss 2.7458e-02, Val_Loss 3.1516e-02\n",
            "Epoch [81] Train_Loss 2.7248e-02, Val_Loss 2.3473e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [82] Train_Loss 2.5003e-02, Val_Loss 2.1407e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [83] Train_Loss 2.2295e-02, Val_Loss 2.3527e-02\n",
            "Epoch [84] Train_Loss 2.2296e-02, Val_Loss 2.3295e-02\n",
            "Epoch [85] Train_Loss 2.3077e-02, Val_Loss 2.9130e-02\n",
            "Epoch [86] Train_Loss 2.1880e-02, Val_Loss 2.1213e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [87] Train_Loss 2.0378e-02, Val_Loss 2.0418e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [88] Train_Loss 2.2529e-02, Val_Loss 3.8263e-02\n",
            "Epoch [89] Train_Loss 2.5601e-02, Val_Loss 2.1822e-02\n",
            "Epoch [90] Train_Loss 2.4307e-02, Val_Loss 1.9706e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [91] Train_Loss 2.4272e-02, Val_Loss 2.0582e-02\n",
            "Epoch [92] Train_Loss 2.6698e-02, Val_Loss 2.8514e-02\n",
            "Epoch [93] Train_Loss 2.8311e-02, Val_Loss 2.7194e-02\n",
            "Epoch [94] Train_Loss 2.1662e-02, Val_Loss 3.3063e-02\n",
            "Epoch [95] Train_Loss 2.3753e-02, Val_Loss 2.8311e-02\n",
            "Epoch [96] Train_Loss 2.5667e-02, Val_Loss 3.1123e-02\n",
            "Epoch [97] Train_Loss 3.5891e-02, Val_Loss 5.5690e-02\n",
            "Epoch [98] Train_Loss 2.9054e-02, Val_Loss 2.3268e-02\n",
            "Epoch [99] Train_Loss 2.2898e-02, Val_Loss 2.1175e-02\n",
            "<All keys matched successfully>\n",
            "-------------------------\n",
            "Training Model [ID = 05]\n",
            "-------------------------\n",
            "Epoch [0] Train_Loss 6.8565e+00, Val_Loss 2.6376e+00\n",
            "Saving Model\n",
            "\n",
            "Epoch [1] Train_Loss 1.6490e+00, Val_Loss 9.9987e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [2] Train_Loss 6.6121e-01, Val_Loss 4.5301e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [3] Train_Loss 3.4023e-01, Val_Loss 2.4247e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [4] Train_Loss 2.3921e-01, Val_Loss 2.0952e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [5] Train_Loss 2.1721e-01, Val_Loss 2.4818e-01\n",
            "Epoch [6] Train_Loss 2.0468e-01, Val_Loss 2.0142e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [7] Train_Loss 2.0246e-01, Val_Loss 2.6026e-01\n",
            "Epoch [8] Train_Loss 1.9307e-01, Val_Loss 1.3241e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [9] Train_Loss 1.3970e-01, Val_Loss 1.1538e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [10] Train_Loss 1.3234e-01, Val_Loss 1.0493e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [11] Train_Loss 1.1667e-01, Val_Loss 1.0127e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [12] Train_Loss 1.1061e-01, Val_Loss 9.4919e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [13] Train_Loss 1.0516e-01, Val_Loss 9.0710e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [14] Train_Loss 1.0014e-01, Val_Loss 8.7655e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [15] Train_Loss 1.0826e-01, Val_Loss 9.7138e-02\n",
            "Epoch [16] Train_Loss 9.5009e-02, Val_Loss 7.9292e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [17] Train_Loss 8.8085e-02, Val_Loss 7.6965e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [18] Train_Loss 8.8204e-02, Val_Loss 7.5320e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [19] Train_Loss 8.7180e-02, Val_Loss 7.5848e-02\n",
            "Epoch [20] Train_Loss 8.4071e-02, Val_Loss 7.1346e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [21] Train_Loss 7.8189e-02, Val_Loss 7.3224e-02\n",
            "Epoch [22] Train_Loss 6.8026e-02, Val_Loss 6.4646e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [23] Train_Loss 6.6143e-02, Val_Loss 6.3095e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [24] Train_Loss 6.2887e-02, Val_Loss 7.2846e-02\n",
            "Epoch [25] Train_Loss 6.7942e-02, Val_Loss 6.6614e-02\n",
            "Epoch [26] Train_Loss 6.0341e-02, Val_Loss 7.6796e-02\n",
            "Epoch [27] Train_Loss 5.9674e-02, Val_Loss 7.0383e-02\n",
            "Epoch [28] Train_Loss 5.6680e-02, Val_Loss 6.6036e-02\n",
            "Epoch [29] Train_Loss 5.5053e-02, Val_Loss 6.6785e-02\n",
            "Epoch [30] Train_Loss 5.8957e-02, Val_Loss 6.5955e-02\n",
            "Epoch [31] Train_Loss 5.2545e-02, Val_Loss 6.8965e-02\n",
            "Epoch [32] Train_Loss 5.2281e-02, Val_Loss 5.4659e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [33] Train_Loss 6.8665e-02, Val_Loss 8.7668e-02\n",
            "Epoch [34] Train_Loss 6.9367e-02, Val_Loss 5.0943e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [35] Train_Loss 6.8981e-02, Val_Loss 5.0259e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [36] Train_Loss 4.8616e-02, Val_Loss 4.8844e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [37] Train_Loss 4.7335e-02, Val_Loss 4.1479e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [38] Train_Loss 5.8900e-02, Val_Loss 5.8546e-02\n",
            "Epoch [39] Train_Loss 5.2352e-02, Val_Loss 4.6906e-02\n",
            "Epoch [40] Train_Loss 4.6156e-02, Val_Loss 4.2916e-02\n",
            "Epoch [41] Train_Loss 4.1997e-02, Val_Loss 3.7422e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [42] Train_Loss 4.6386e-02, Val_Loss 4.4964e-02\n",
            "Epoch [43] Train_Loss 4.6264e-02, Val_Loss 4.3219e-02\n",
            "Epoch [44] Train_Loss 4.0341e-02, Val_Loss 3.7160e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [45] Train_Loss 5.1773e-02, Val_Loss 6.1627e-02\n",
            "Epoch [46] Train_Loss 4.3052e-02, Val_Loss 4.1387e-02\n",
            "Epoch [47] Train_Loss 3.8197e-02, Val_Loss 3.3818e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [48] Train_Loss 4.3027e-02, Val_Loss 4.4019e-02\n",
            "Epoch [49] Train_Loss 3.5433e-02, Val_Loss 4.6226e-02\n",
            "Epoch [50] Train_Loss 3.8741e-02, Val_Loss 4.8991e-02\n",
            "Epoch [51] Train_Loss 4.0690e-02, Val_Loss 4.4845e-02\n",
            "Epoch [52] Train_Loss 4.2246e-02, Val_Loss 5.6394e-02\n",
            "Epoch [53] Train_Loss 4.7897e-02, Val_Loss 3.5817e-02\n",
            "Epoch [54] Train_Loss 4.5930e-02, Val_Loss 4.4551e-02\n",
            "Epoch [55] Train_Loss 4.2215e-02, Val_Loss 3.3497e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [56] Train_Loss 3.2542e-02, Val_Loss 2.6779e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [57] Train_Loss 3.6977e-02, Val_Loss 2.9247e-02\n",
            "Epoch [58] Train_Loss 4.1202e-02, Val_Loss 3.3591e-02\n",
            "Epoch [59] Train_Loss 3.2354e-02, Val_Loss 2.5203e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [60] Train_Loss 3.8535e-02, Val_Loss 3.6508e-02\n",
            "Epoch [61] Train_Loss 4.2249e-02, Val_Loss 4.8553e-02\n",
            "Epoch [62] Train_Loss 3.3301e-02, Val_Loss 2.5059e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [63] Train_Loss 2.7955e-02, Val_Loss 2.6213e-02\n",
            "Epoch [64] Train_Loss 2.7214e-02, Val_Loss 3.0145e-02\n",
            "Epoch [65] Train_Loss 3.3844e-02, Val_Loss 3.8411e-02\n",
            "Epoch [66] Train_Loss 2.9567e-02, Val_Loss 2.4096e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [67] Train_Loss 2.7687e-02, Val_Loss 2.7066e-02\n",
            "Epoch [68] Train_Loss 2.6051e-02, Val_Loss 3.3323e-02\n",
            "Epoch [69] Train_Loss 3.2577e-02, Val_Loss 2.8348e-02\n",
            "Epoch [70] Train_Loss 3.0885e-02, Val_Loss 2.3491e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [71] Train_Loss 2.8455e-02, Val_Loss 2.2965e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [72] Train_Loss 2.6829e-02, Val_Loss 2.3707e-02\n",
            "Epoch [73] Train_Loss 2.3889e-02, Val_Loss 2.1003e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [74] Train_Loss 2.4348e-02, Val_Loss 2.8408e-02\n",
            "Epoch [75] Train_Loss 2.6445e-02, Val_Loss 2.1479e-02\n",
            "Epoch [76] Train_Loss 2.6238e-02, Val_Loss 2.6042e-02\n",
            "Epoch [77] Train_Loss 2.9700e-02, Val_Loss 2.5024e-02\n",
            "Epoch [78] Train_Loss 2.3349e-02, Val_Loss 2.5006e-02\n",
            "Epoch [79] Train_Loss 2.4374e-02, Val_Loss 1.9358e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [80] Train_Loss 2.4223e-02, Val_Loss 1.9347e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [81] Train_Loss 2.4022e-02, Val_Loss 2.2018e-02\n",
            "Epoch [82] Train_Loss 2.1228e-02, Val_Loss 2.4760e-02\n",
            "Epoch [83] Train_Loss 2.2509e-02, Val_Loss 2.2630e-02\n",
            "Epoch [84] Train_Loss 2.3497e-02, Val_Loss 1.8837e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [85] Train_Loss 2.5449e-02, Val_Loss 1.9570e-02\n",
            "Epoch [86] Train_Loss 2.2564e-02, Val_Loss 1.8149e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [87] Train_Loss 2.2416e-02, Val_Loss 2.7199e-02\n",
            "Epoch [88] Train_Loss 2.3948e-02, Val_Loss 1.6973e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [89] Train_Loss 2.3441e-02, Val_Loss 1.6836e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [90] Train_Loss 2.1146e-02, Val_Loss 1.8546e-02\n",
            "Epoch [91] Train_Loss 2.5901e-02, Val_Loss 2.5228e-02\n",
            "Epoch [92] Train_Loss 2.2510e-02, Val_Loss 1.7834e-02\n",
            "Epoch [93] Train_Loss 1.9472e-02, Val_Loss 1.8597e-02\n",
            "Epoch [94] Train_Loss 1.8429e-02, Val_Loss 2.1751e-02\n",
            "Epoch [95] Train_Loss 2.1173e-02, Val_Loss 1.6905e-02\n",
            "Epoch [96] Train_Loss 1.7885e-02, Val_Loss 1.7790e-02\n",
            "Epoch [97] Train_Loss 1.7916e-02, Val_Loss 1.4716e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [98] Train_Loss 1.8343e-02, Val_Loss 1.7069e-02\n",
            "Epoch [99] Train_Loss 1.8163e-02, Val_Loss 1.4760e-02\n",
            "<All keys matched successfully>\n",
            "-------------------------\n",
            "Training Model [ID = 06]\n",
            "-------------------------\n",
            "Epoch [0] Train_Loss 8.3501e+00, Val_Loss 4.4707e+00\n",
            "Saving Model\n",
            "\n",
            "Epoch [1] Train_Loss 3.7020e+00, Val_Loss 2.9102e+00\n",
            "Saving Model\n",
            "\n",
            "Epoch [2] Train_Loss 2.4543e+00, Val_Loss 2.1168e+00\n",
            "Saving Model\n",
            "\n",
            "Epoch [3] Train_Loss 1.9832e+00, Val_Loss 1.8613e+00\n",
            "Saving Model\n",
            "\n",
            "Epoch [4] Train_Loss 1.7819e+00, Val_Loss 1.6902e+00\n",
            "Saving Model\n",
            "\n",
            "Epoch [5] Train_Loss 1.8231e-01, Val_Loss 1.5309e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [6] Train_Loss 1.4958e-01, Val_Loss 1.3645e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [7] Train_Loss 1.3587e-01, Val_Loss 1.1930e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [8] Train_Loss 1.2183e-01, Val_Loss 1.0788e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [9] Train_Loss 1.1052e-01, Val_Loss 1.0512e-01\n",
            "Saving Model\n",
            "\n",
            "Epoch [10] Train_Loss 1.1171e-01, Val_Loss 9.8061e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [11] Train_Loss 9.6596e-02, Val_Loss 9.5921e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [12] Train_Loss 9.2519e-02, Val_Loss 8.7995e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [13] Train_Loss 8.6965e-02, Val_Loss 8.1100e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [14] Train_Loss 8.1031e-02, Val_Loss 7.4785e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [15] Train_Loss 8.1572e-02, Val_Loss 7.3664e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [16] Train_Loss 7.3195e-02, Val_Loss 6.9414e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [17] Train_Loss 6.8684e-02, Val_Loss 7.0317e-02\n",
            "Epoch [18] Train_Loss 6.6701e-02, Val_Loss 6.6278e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [19] Train_Loss 6.2739e-02, Val_Loss 6.0487e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [20] Train_Loss 6.2692e-02, Val_Loss 5.8144e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [21] Train_Loss 5.8854e-02, Val_Loss 5.9785e-02\n",
            "Epoch [22] Train_Loss 5.6343e-02, Val_Loss 5.2553e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [23] Train_Loss 5.3488e-02, Val_Loss 5.5188e-02\n",
            "Epoch [24] Train_Loss 5.2797e-02, Val_Loss 5.4778e-02\n",
            "Epoch [25] Train_Loss 5.5377e-02, Val_Loss 5.1581e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [26] Train_Loss 5.2322e-02, Val_Loss 4.3669e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [27] Train_Loss 4.7513e-02, Val_Loss 4.7527e-02\n",
            "Epoch [28] Train_Loss 4.9041e-02, Val_Loss 4.4491e-02\n",
            "Epoch [29] Train_Loss 4.3798e-02, Val_Loss 4.4041e-02\n",
            "Epoch [30] Train_Loss 4.7776e-02, Val_Loss 4.2992e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [31] Train_Loss 4.1605e-02, Val_Loss 4.1409e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [32] Train_Loss 4.1659e-02, Val_Loss 4.1168e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [33] Train_Loss 4.1050e-02, Val_Loss 3.9421e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [34] Train_Loss 3.7699e-02, Val_Loss 3.6366e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [35] Train_Loss 4.2495e-02, Val_Loss 4.8792e-02\n",
            "Epoch [36] Train_Loss 4.7663e-02, Val_Loss 3.5063e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [37] Train_Loss 4.0213e-02, Val_Loss 3.6499e-02\n",
            "Epoch [38] Train_Loss 3.6838e-02, Val_Loss 3.7600e-02\n",
            "Epoch [39] Train_Loss 3.4655e-02, Val_Loss 3.7004e-02\n",
            "Epoch [40] Train_Loss 3.5658e-02, Val_Loss 3.0853e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [41] Train_Loss 3.2209e-02, Val_Loss 2.8656e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [42] Train_Loss 3.2003e-02, Val_Loss 3.2970e-02\n",
            "Epoch [43] Train_Loss 3.1358e-02, Val_Loss 3.1487e-02\n",
            "Epoch [44] Train_Loss 3.3753e-02, Val_Loss 2.7702e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [45] Train_Loss 3.4625e-02, Val_Loss 3.3841e-02\n",
            "Epoch [46] Train_Loss 3.3018e-02, Val_Loss 3.1045e-02\n",
            "Epoch [47] Train_Loss 3.0696e-02, Val_Loss 2.7712e-02\n",
            "Epoch [48] Train_Loss 2.5377e-02, Val_Loss 2.5927e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [49] Train_Loss 2.5759e-02, Val_Loss 2.8345e-02\n",
            "Epoch [50] Train_Loss 2.7838e-02, Val_Loss 2.6330e-02\n",
            "Epoch [51] Train_Loss 2.5250e-02, Val_Loss 2.4988e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [52] Train_Loss 2.4262e-02, Val_Loss 2.5441e-02\n",
            "Epoch [53] Train_Loss 2.4315e-02, Val_Loss 2.7125e-02\n",
            "Epoch [54] Train_Loss 2.3153e-02, Val_Loss 2.4087e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [55] Train_Loss 2.3529e-02, Val_Loss 2.2997e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [56] Train_Loss 3.5749e-02, Val_Loss 5.4398e-02\n",
            "Epoch [57] Train_Loss 3.1096e-02, Val_Loss 2.4414e-02\n",
            "Epoch [58] Train_Loss 2.3952e-02, Val_Loss 2.8631e-02\n",
            "Epoch [59] Train_Loss 2.7290e-02, Val_Loss 2.2924e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [60] Train_Loss 2.5352e-02, Val_Loss 2.3860e-02\n",
            "Epoch [61] Train_Loss 2.2128e-02, Val_Loss 2.1607e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [62] Train_Loss 2.2317e-02, Val_Loss 2.4923e-02\n",
            "Epoch [63] Train_Loss 2.2125e-02, Val_Loss 2.6287e-02\n",
            "Epoch [64] Train_Loss 2.7027e-02, Val_Loss 2.4474e-02\n",
            "Epoch [65] Train_Loss 2.6141e-02, Val_Loss 3.1538e-02\n",
            "Epoch [66] Train_Loss 2.3200e-02, Val_Loss 2.7399e-02\n",
            "Epoch [67] Train_Loss 2.2542e-02, Val_Loss 2.2342e-02\n",
            "Epoch [68] Train_Loss 2.1186e-02, Val_Loss 2.1594e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [69] Train_Loss 2.1260e-02, Val_Loss 2.0103e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [70] Train_Loss 2.0367e-02, Val_Loss 1.9874e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [71] Train_Loss 1.9200e-02, Val_Loss 1.9389e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [72] Train_Loss 1.9403e-02, Val_Loss 1.7750e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [73] Train_Loss 2.0837e-02, Val_Loss 2.1612e-02\n",
            "Epoch [74] Train_Loss 2.1705e-02, Val_Loss 2.0106e-02\n",
            "Epoch [75] Train_Loss 2.1210e-02, Val_Loss 2.1738e-02\n",
            "Epoch [76] Train_Loss 2.2398e-02, Val_Loss 1.8633e-02\n",
            "Epoch [77] Train_Loss 1.9811e-02, Val_Loss 1.7635e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [78] Train_Loss 1.8385e-02, Val_Loss 1.8300e-02\n",
            "Epoch [79] Train_Loss 1.5765e-02, Val_Loss 1.6299e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [80] Train_Loss 1.7286e-02, Val_Loss 1.8099e-02\n",
            "Epoch [81] Train_Loss 1.7178e-02, Val_Loss 1.8844e-02\n",
            "Epoch [82] Train_Loss 2.0256e-02, Val_Loss 2.1639e-02\n",
            "Epoch [83] Train_Loss 2.0793e-02, Val_Loss 1.9043e-02\n",
            "Epoch [84] Train_Loss 1.5742e-02, Val_Loss 1.8142e-02\n",
            "Epoch [85] Train_Loss 1.6847e-02, Val_Loss 1.6170e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [86] Train_Loss 1.5905e-02, Val_Loss 1.5708e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [87] Train_Loss 1.4864e-02, Val_Loss 1.4878e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [88] Train_Loss 1.6039e-02, Val_Loss 1.4723e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [89] Train_Loss 1.3930e-02, Val_Loss 1.3935e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [90] Train_Loss 2.0093e-02, Val_Loss 1.5740e-02\n",
            "Epoch [91] Train_Loss 1.5509e-02, Val_Loss 1.5328e-02\n",
            "Epoch [92] Train_Loss 1.3806e-02, Val_Loss 1.3221e-02\n",
            "Saving Model\n",
            "\n",
            "Epoch [93] Train_Loss 1.3936e-02, Val_Loss 1.5920e-02\n",
            "Epoch [94] Train_Loss 1.4016e-02, Val_Loss 1.5213e-02\n",
            "Epoch [95] Train_Loss 1.4026e-02, Val_Loss 1.3409e-02\n",
            "Epoch [96] Train_Loss 1.3342e-02, Val_Loss 1.9682e-02\n",
            "Epoch [97] Train_Loss 1.4063e-02, Val_Loss 1.3932e-02\n",
            "Epoch [98] Train_Loss 1.2992e-02, Val_Loss 1.4736e-02\n",
            "Epoch [99] Train_Loss 1.3991e-02, Val_Loss 1.3685e-02\n",
            "<All keys matched successfully>\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}